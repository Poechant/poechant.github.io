<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://www.mikecaptain.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.mikecaptain.com/" rel="alternate" type="text/html" /><updated>2023-01-10T21:25:49+00:00</updated><id>https://www.mikecaptain.com/feed.xml</id><title type="html">麦克船长的技术、产品与商业博客</title><subtitle>麦克船长对于技术、产品、商业等领域的分享|AI,A.I.,NLP,神经网络,人工智能,自然语言处理,BERT,GPT,ChatGPT,OpenAI,阿里巴巴,P9,运营,淘宝,天猫,总监,高管</subtitle><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><entry><title type="html">麦克船长 NLP 语言模型技术笔记 5：注意力机制（Attention Mechanism）</title><link href="https://www.mikecaptain.com/2023/01/04/language-model-5/" rel="alternate" type="text/html" title="麦克船长 NLP 语言模型技术笔记 5：注意力机制（Attention Mechanism）" /><published>2023-01-04T18:13:09+00:00</published><updated>2023-01-04T18:13:09+00:00</updated><id>https://www.mikecaptain.com/2023/01/04/language-model-5</id><content type="html" xml:base="https://www.mikecaptain.com/2023/01/04/language-model-5/">&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#一为什么说-rnn-模型没有体现注意力&quot; id=&quot;markdown-toc-一为什么说-rnn-模型没有体现注意力&quot;&gt;一、为什么说 RNN 模型没有体现「注意力」？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#二基于-attention-机制的-encoder-decoder-模型&quot; id=&quot;markdown-toc-二基于-attention-机制的-encoder-decoder-模型&quot;&gt;二、基于 Attention 机制的 Encoder-Decoder 模型&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#三transformer-在-2017-年横空出世&quot; id=&quot;markdown-toc-三transformer-在-2017-年横空出世&quot;&gt;三、Transformer 在 2017 年横空出世&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1自注意力机制self-attention&quot; id=&quot;markdown-toc-1自注意力机制self-attention&quot;&gt;1、自注意力机制（Self-Attention）&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11一段自然语言内容其自身就暗含很多内部关联信息&quot; id=&quot;markdown-toc-11一段自然语言内容其自身就暗含很多内部关联信息&quot;&gt;1.1、一段自然语言内容，其自身就「暗含」很多内部关联信息&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12如何计算-qkv&quot; id=&quot;markdown-toc-12如何计算-qkv&quot;&gt;1.2、如何计算 Q、K、V&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13注意力函数如何通过-qv-得到-z&quot; id=&quot;markdown-toc-13注意力函数如何通过-qv-得到-z&quot;&gt;1.3、注意力函数：如何通过 Q、V 得到 Z&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#14其他注意力函数&quot; id=&quot;markdown-toc-14其他注意力函数&quot;&gt;1.4、其他注意力函数&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2多头注意力&quot; id=&quot;markdown-toc-2多头注意力&quot;&gt;2、多头注意力&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3退化现象残差网络与-short-cut&quot; id=&quot;markdown-toc-3退化现象残差网络与-short-cut&quot;&gt;3、退化现象、残差网络与 Short-Cut&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#31退化现象&quot; id=&quot;markdown-toc-31退化现象&quot;&gt;3.1、退化现象&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#32恒等映射&quot; id=&quot;markdown-toc-32恒等映射&quot;&gt;3.2、恒等映射&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#33残差网络residual-network与捷径short-cut&quot; id=&quot;markdown-toc-33残差网络residual-network与捷径short-cut&quot;&gt;3.3、残差网络（Residual Network）与捷径（Short-Cut）&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4位置编码positional-embedding&quot; id=&quot;markdown-toc-4位置编码positional-embedding&quot;&gt;4、位置编码（Positional Embedding）&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#41transformer-论文中的三角式位置编码sinusoidal-positional-encoding&quot; id=&quot;markdown-toc-41transformer-论文中的三角式位置编码sinusoidal-positional-encoding&quot;&gt;4.1、Transformer 论文中的三角式位置编码（Sinusoidal Positional Encoding）&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#42绝对位置编码&quot; id=&quot;markdown-toc-42绝对位置编码&quot;&gt;4.2、绝对位置编码&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#43相对位置编码&quot; id=&quot;markdown-toc-43相对位置编码&quot;&gt;4.3、相对位置编码&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#44其他位置编码&quot; id=&quot;markdown-toc-44其他位置编码&quot;&gt;4.4、其他位置编码&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5transformer-模型整体&quot; id=&quot;markdown-toc-5transformer-模型整体&quot;&gt;5、Transformer 模型整体&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6来看一段用-pytorch-实现的-transformer-示例&quot; id=&quot;markdown-toc-6来看一段用-pytorch-实现的-transformer-示例&quot;&gt;6、来看一段用 PyTorch 实现的 Transformer 示例&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;一为什么说-rnn-模型没有体现注意力&quot;&gt;一、为什么说 RNN 模型没有体现「注意力」？&lt;/h3&gt;

&lt;p&gt;Encoder-Decoder 的一个非常严重的问题，是依赖中间那个 context 向量，则无法处理特别长的输入序列 —— 记忆力不足，会忘事儿。而忘事儿的根本原因，是没有「注意力」。&lt;/p&gt;

&lt;p&gt;对于一般的 RNN 模型，Encoder-Decoder 结构并没有体现「注意力」—— 这句话怎么理解？当输入序列经过 Encoder 生成的中间结果（上下文 C），被喂给 Decoder 时，这些中间结果对所生成序列里的哪个词，都没有区别（没有特别关照谁）。这相当于在说：输入序列里的每个词，对于生成任何一个输出的词的影响，是一样的，而不是输出某个词时是聚焦特定的一些输入词。这就是模型没有注意力机制。&lt;/p&gt;

&lt;p&gt;人脑的注意力模型，其实是资源分配模型。NLP 领域的注意力模型，是在 2014 年被提出的，后来逐渐成为 NLP 领域的一个广泛应用的机制。可以应用的场景，比如对于一个电商平台中很常见的白底图，其边缘的白色区域都是无用的，那么就不应该被关注（关注权重为 0）。比如机器翻译中，翻译词都是对局部输入重点关注的。&lt;/p&gt;

&lt;p&gt;所以 Attention 机制，就是在 Decoder 时，不是所有输出都依赖相同的「上下文  \(\bm{C}_t\) 」，而是时刻 t 的输出，使用  \(\bm{C}_t\) ，而这个  \(\bm{C}_t\)  来自对每个输入数据项根据「注意力」进行的加权。&lt;/p&gt;

&lt;h3 id=&quot;二基于-attention-机制的-encoder-decoder-模型&quot;&gt;二、基于 Attention 机制的 Encoder-Decoder 模型&lt;/h3&gt;

&lt;p&gt;2015 年 Dzmitry Bahdanau 等人在论文&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;《Neural Machine Translation by Jointly Learning to Align and Translate》&lt;/a&gt; 中提出了「Attention」机制，下面请跟着麦克船长，我会深入浅出地为你解释清楚。&lt;/p&gt;

&lt;p&gt;下图中  \(e_i\)  表示编码器的隐藏层输出， \(d_i\)  表示解码器的隐藏层输出&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-f66c634a9c7c02915e5610af76c3b1b7&quot; width=&quot;436pt&quot; height=&quot;336pt&quot; viewBox=&quot;0.00 0.00 436.00 336.00&quot;&gt;
&lt;title&gt;graphviz-f66c634a9c7c02915e5610af76c3b1b7&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	splines=ortho
	{rank=same e1 e2 eddd en}
	{rank=same d1 d2 dddd dt0 dt dddd2}

	eddd[label=&amp;quot;...&amp;quot;]
	dddd[label=&amp;quot;...&amp;quot;]
	xddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]
	dt[label=&amp;quot;d_t&amp;quot;]
	dt0[label=&amp;quot;d_t-1&amp;quot;]
	yt[label=&amp;quot;y_t&amp;quot;]
	yt0[label=&amp;quot;y_t-1&amp;quot;]
	Ct[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]
	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	dddd2[shape=plaintext, label=&amp;quot;&amp;quot;]
	Ct[label=&amp;quot;C_t&amp;quot;, shape=&amp;quot;square&amp;quot;]

	x1 -&amp;gt; e1
	x2 -&amp;gt; e2
	xddd -&amp;gt; eddd
	xn -&amp;gt; en

	e1 -&amp;gt; e2
	e2 -&amp;gt; eddd
	eddd -&amp;gt; en

	Ct -&amp;gt; dt

	d1 -&amp;gt; y1
	d2 -&amp;gt; y2
	dddd -&amp;gt; yddd
	dt0 -&amp;gt; yt0
	dt -&amp;gt; yt

	d1 -&amp;gt; d2
	d2 -&amp;gt; dddd
	dddd -&amp;gt; dt0
	dt0 -&amp;gt; dt

	e1 -&amp;gt; Ct
	e2 -&amp;gt; Ct
	eddd -&amp;gt; Ct
	en -&amp;gt; Ct

	dt -&amp;gt; dddd2
	dt0 -&amp;gt; Ct
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 332)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-332 432,-332 432,4 -4,4&quot; /&gt;
&lt;!-- e1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;e1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;181&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;181&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;e1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;e2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;253&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;253&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;e2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e1&amp;#45;&amp;gt;e2 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e1&amp;#45;&amp;gt;e2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M208.22,-90C208.22,-90 215.74,-90 215.74,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;215.74,-93.5 225.74,-90 215.74,-86.5 215.74,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- Ct --&gt;
&lt;g id=&quot;node15&quot; class=&quot;node&quot;&gt;
&lt;title&gt;Ct&lt;/title&gt;
&lt;polygon fill=&quot;none&quot; stroke=&quot;black&quot; points=&quot;309,-184 269,-184 269,-144 309,-144 309,-184&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;289&quot; y=&quot;-160.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;C_t&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e1&amp;#45;&amp;gt;Ct --&gt;
&lt;g id=&quot;edge18&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e1&amp;#45;&amp;gt;Ct&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M203,-100.6C203,-121.06 203,-164 203,-164 203,-164 258.62,-164 258.62,-164&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;258.62,-167.5 268.62,-164 258.62,-160.5 258.62,-167.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- eddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;eddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;325&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;325&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e2&amp;#45;&amp;gt;eddd --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e2&amp;#45;&amp;gt;eddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M280.22,-90C280.22,-90 287.74,-90 287.74,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;287.74,-93.5 297.74,-90 287.74,-86.5 287.74,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- e2&amp;#45;&amp;gt;Ct --&gt;
&lt;g id=&quot;edge19&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e2&amp;#45;&amp;gt;Ct&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M274.5,-100.92C274.5,-100.92 274.5,-133.82 274.5,-133.82&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;271,-133.82 274.5,-143.82 278,-133.82 271,-133.82&quot; /&gt;
&lt;/g&gt;
&lt;!-- en --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;en&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;397&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;397&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;en&lt;/text&gt;
&lt;/g&gt;
&lt;!-- eddd&amp;#45;&amp;gt;en --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;eddd&amp;#45;&amp;gt;en&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M352.22,-90C352.22,-90 359.74,-90 359.74,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;359.74,-93.5 369.74,-90 359.74,-86.5 359.74,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- eddd&amp;#45;&amp;gt;Ct --&gt;
&lt;g id=&quot;edge20&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;eddd&amp;#45;&amp;gt;Ct&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M303.5,-100.92C303.5,-100.92 303.5,-133.82 303.5,-133.82&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;300,-133.82 303.5,-143.82 307,-133.82 300,-133.82&quot; /&gt;
&lt;/g&gt;
&lt;!-- en&amp;#45;&amp;gt;Ct --&gt;
&lt;g id=&quot;edge21&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;en&amp;#45;&amp;gt;Ct&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M399,-108.29C399,-130.21 399,-164 399,-164 399,-164 319.18,-164 319.18,-164&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;319.18,-160.5 309.18,-164 319.18,-167.5 319.18,-160.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- d1 --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;d1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-238&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-234.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d2 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;d2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-238&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-234.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d1&amp;#45;&amp;gt;d2 --&gt;
&lt;g id=&quot;edge14&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d1&amp;#45;&amp;gt;d2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M54.22,-238C54.22,-238 61.74,-238 61.74,-238&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;61.74,-241.5 71.74,-238 61.74,-234.5 61.74,-241.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node19&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-306.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d1&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d1&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-256.17C27,-256.17 27,-281.59 27,-281.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-281.59 27,-291.59 30.5,-281.59 23.5,-281.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- dddd --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-238&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-234.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d2&amp;#45;&amp;gt;dddd --&gt;
&lt;g id=&quot;edge15&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d2&amp;#45;&amp;gt;dddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M126.22,-238C126.22,-238 133.74,-238 133.74,-238&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;133.74,-241.5 143.74,-238 133.74,-234.5 133.74,-241.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node20&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-306.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d2&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d2&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-256.17C99,-256.17 99,-281.59 99,-281.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-281.59 99,-291.59 102.5,-281.59 95.5,-281.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- dt0 --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dt0&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;250&quot; cy=&quot;-238&quot; rx=&quot;33.6&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;250&quot; y=&quot;-234.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d_t&amp;#45;1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dddd&amp;#45;&amp;gt;dt0 --&gt;
&lt;g id=&quot;edge16&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dddd&amp;#45;&amp;gt;dt0&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M198.19,-238C198.19,-238 206.2,-238 206.2,-238&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;206.2,-241.5 216.2,-238 206.2,-234.5 206.2,-241.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node12&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-306.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-256.17C171,-256.17 171,-281.59 171,-281.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-281.59 171,-291.59 174.5,-281.59 167.5,-281.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- dt --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dt&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;329&quot; cy=&quot;-238&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;329&quot; y=&quot;-234.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d_t&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dt0&amp;#45;&amp;gt;dt --&gt;
&lt;g id=&quot;edge17&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dt0&amp;#45;&amp;gt;dt&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M283.96,-238C283.96,-238 291.98,-238 291.98,-238&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;291.98,-241.5 301.98,-238 291.98,-234.5 291.98,-241.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yt0 --&gt;
&lt;g id=&quot;node14&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yt0&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;250&quot; cy=&quot;-310&quot; rx=&quot;33.29&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;250&quot; y=&quot;-306.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y_t&amp;#45;1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dt0&amp;#45;&amp;gt;yt0 --&gt;
&lt;g id=&quot;edge12&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dt0&amp;#45;&amp;gt;yt0&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M250,-256.17C250,-256.17 250,-281.59 250,-281.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;246.5,-281.59 250,-291.59 253.5,-281.59 246.5,-281.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- dt0&amp;#45;&amp;gt;Ct --&gt;
&lt;g id=&quot;edge23&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dt0&amp;#45;&amp;gt;Ct&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M276.4,-226.44C276.4,-226.44 276.4,-194.12 276.4,-194.12&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;279.9,-194.12 276.4,-184.12 272.9,-194.12 279.9,-194.12&quot; /&gt;
&lt;/g&gt;
&lt;!-- dddd2 --&gt;
&lt;g id=&quot;node10&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dddd2&lt;/title&gt;
&lt;/g&gt;
&lt;!-- dt&amp;#45;&amp;gt;dddd2 --&gt;
&lt;g id=&quot;edge22&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dt&amp;#45;&amp;gt;dddd2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M356.22,-238C356.22,-238 363.74,-238 363.74,-238&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;363.74,-241.5 373.74,-238 363.74,-234.5 363.74,-241.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yt --&gt;
&lt;g id=&quot;node13&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yt&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;329&quot; cy=&quot;-310&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;329&quot; y=&quot;-306.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y_t&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dt&amp;#45;&amp;gt;yt --&gt;
&lt;g id=&quot;edge13&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dt&amp;#45;&amp;gt;yt&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M329,-256.17C329,-256.17 329,-281.59 329,-281.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;325.5,-281.59 329,-291.59 332.5,-281.59 325.5,-281.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node11&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;325&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;eddd --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;eddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M325,-36.17C325,-36.17 325,-61.59 325,-61.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;321.5,-61.59 325,-71.59 328.5,-61.59 321.5,-61.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- Ct&amp;#45;&amp;gt;dt --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;Ct&amp;#45;&amp;gt;dt&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M305.5,-184.22C305.5,-184.22 305.5,-218.8 305.5,-218.8&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;302,-218.8 305.5,-228.8 309,-218.8 302,-218.8&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node16&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;181&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;e1 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;e1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M181,-36.17C181,-36.17 181,-61.59 181,-61.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;177.5,-61.59 181,-71.59 184.5,-61.59 177.5,-61.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node17&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;253&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;e2 --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;e2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M253,-36.17C253,-36.17 253,-61.59 253,-61.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;249.5,-61.59 253,-71.59 256.5,-61.59 249.5,-61.59&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node18&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;397&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;en --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;en&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M397,-36.17C397,-36.17 397,-61.59 397,-61.59&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;393.5,-61.59 397,-71.59 400.5,-61.59 393.5,-61.59&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;更进一步细化关于  \(\bm{C}_t\)  部分，我们引用《基于深度学习的道路短期交通状态时空序列预测》一书中的图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-captain-nlp-5.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个图里的  \(\widetilde{h}_i\)  与上一个图里的  \(d_i\)  对应， \(h_i\)  与上一个图里的  \(e_i\)  对应。&lt;/p&gt;

&lt;p&gt;针对时刻  \(t\)  要产出的输出，隐藏层每一个隐藏细胞都与  \(\bm{C}_t\)  有一个权重关系  \(\alpha_{t,i}\)  其中  \(1\le i\le n\) ，这个权重值与「输入项经过编码器后隐藏层后的输出 \(e_i（1\le i\le n）\) 、解码器的前一时刻隐藏层输出  \(d_{t-1}\) 」两者有关：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;s_{i,t} = score(\bm{e}_i,\bm{d}_{t-1}) \\
&amp;amp;\alpha_{i,t} = \frac{exp(s_{i,t})}{\textstyle\sum_{j=1}^n exp(s_{j,t})}
\end{aligned}\]

&lt;p&gt;常用的  \(score\)  函数有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;点积（Dot Product）模型： \(s_{i,t} = {\bm{d}_{t-1}}^T \cdot \bm{e}_i\)&lt;/li&gt;
  &lt;li&gt;缩放点积（Scaled Dot-Product）模型： \(s_{i,t} = \frac{{\bm{d}_{t-1}}^T \cdot \bm{e}_i}{\sqrt{\smash[b]{dimensions\:of\:d_{t-1}\:or\:e_i}}}\) ，可避免因为向量维度过大导致点积结果太大&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然后上下文向量就表示成：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{C}_t = \displaystyle\sum_{i=1}^n \alpha_{i,t} \bm{e}_i
\end{aligned}\]

&lt;p&gt;还记得 RNN 那部分里我们讲到的 Encoder-Decoder 模型的公式表示吗？&lt;/p&gt;

\[\begin{aligned}
e_t &amp;amp;= Encoder_{LSTM/GRU}(x_t, e_{t-1}) \\
\bm{C} &amp;amp;= f_1(e_n) \\
d_t &amp;amp;= f_2(d_{t-1}, \bm{C}) \\
y_t &amp;amp;= Decoder_{LSTM/GRU}(y_{t-1}, d_{t-1}, \bm{C})
\end{aligned}\]

&lt;p&gt;加入 Attention 机制的 Encoder-Decoder 模型如下：&lt;/p&gt;

\[\begin{aligned}
e_t &amp;amp;= Encoder_{LSTM/GRU}(x_t, e_{t-1}) \\
\bm{C}_t &amp;amp;= f_1(e_1,e_2...e_n,d_{t-1}) \\
d_t &amp;amp;= f_2(d_{t-1}, \bm{C}_t) \\
y_t &amp;amp;= Decoder_{LSTM/GRU}(y_{t-1}, d_{t-1}, \bm{C}_t)
\end{aligned}\]

&lt;p&gt;可以看到最核心的区别是第二个公式  \(C_t\) 。加入 Attention 后，对所有数据给予不同的注意力分布。具体地，比如我们用如下的函数来定义这个模型：&lt;/p&gt;

\[\begin{aligned}
\bm{e} &amp;amp;= tanh(\bm{W}^{xe} \cdot \bm{x} + \bm{b}^{xe}) \\
s_{i,t} &amp;amp;= score(\bm{e}_i,\bm{d}_{t-1}) \\
\alpha_{i,t} &amp;amp;= \frac{e^{s_{i,t}}}{\textstyle\sum_{j=1}^n e^{s_{j,t}}} \\
\bm{C}_t &amp;amp;= \displaystyle\sum_{i=1}^n \alpha_{i,t} \bm{e}_i \\
\bm{d}_t &amp;amp;= tanh(\bm{W}^{dd} \cdot \bm{d}_{t-1} + \bm{b}^{dd} +
				 \bm{W}^{yd} \cdot \bm{y}_{t-1} + \bm{b}^{yd} +
				 \bm{W}^{cd} \cdot \bm{C}_t + \bm{b}^{cd}) \\
\bm{y} &amp;amp;= Softmax(\bm{W}^{dy} \cdot \bm{d} + \bm{b}^{dy})
\end{aligned}\]

&lt;p&gt;到这里你能发现注意力机制的什么问题不？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这个注意力机制忽略了位置信息。比如 Tigers love rabbits 和 Rabbits love tigers 会产生一样的注意力分数。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三transformer-在-2017-年横空出世&quot;&gt;三、Transformer 在 2017 年横空出世&lt;/h3&gt;

&lt;p&gt;中文网络里找到的解释得比较好的 blogs、answers，几乎都指向了同一篇博客：Jay Alammar 的&lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot;&gt;《The Illustrated Transformer》&lt;/a&gt;，所以建议读者搭配该篇文章阅读。&lt;/p&gt;

&lt;p&gt;Transformer 模型中用到了自注意力（Self-Attention）、多头注意力（Multiple-Head Attention）、残差网络（ResNet）与捷径（Short-Cut）。下面我们先通过第 1 到第 4 小节把几个基本概念讲清楚，然后在第 5 小节讲解整体 Transformer 模型就会好理解很多了。最后第 6 小节我们来一段动手实践。&lt;/p&gt;

&lt;h4 id=&quot;1自注意力机制self-attention&quot;&gt;1、自注意力机制（Self-Attention）&lt;/h4&gt;

&lt;p&gt;自注意力是理解 Transformer 的关键，原作者在论文中限于篇幅，没有给出过多的解释。以下是我自己的理解，能够比较通透、符合常识地去理解 Transformer 中的一些神来之笔的概念。&lt;/p&gt;

&lt;h5 id=&quot;11一段自然语言内容其自身就暗含很多内部关联信息&quot;&gt;1.1、一段自然语言内容，其自身就「暗含」很多内部关联信息&lt;/h5&gt;

&lt;p&gt;在加入了 Attention 的 Encoder-Decoder 模型中，对输出序列 Y 中的一个词的注意力来自于输入序列 X，那么如果 X 和 Y 相等呢？什么场景会有这个需求？因为我们认为一段文字里某些词就是由于另外某些词而决定的，可以粗暴地理解为「完形填空」的原理。那么这样一段文字，其实就存在其中每个词的自注意力，举个例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;老王是我的主管，我很喜欢他的平易近人。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;对这句话里的「他」，如果基于这句话计算自注意力的话，显然应该给予「老王」最多的注意力。受此启发，我们认为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;一段自然语言中，其实暗含了：为了得到关于某方面信息 Q，可以通过关注某些信息 K，进而得到某些信息（V）作为结果。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Q 就是 query 检索/查询，K、V 分别是 key、value。所以类似于我们在图书检索系统里搜索「NLP书籍」（这是 Q），得到了一本叫《自然语言处理实战》的电子书，书名就是 key，这本电子书就是 value。只是对于自然语言的理解，我们认为任何一段内容里，都自身暗含了很多潜在 Q-K-V 的关联。这是整体受到信息检索领域里 query-key-value 的启发的。&lt;/p&gt;

&lt;p&gt;基于这个启发，我们将自注意力的公式表示为：&lt;/p&gt;

\[\begin{aligned}
Z = SelfAttention(X) = Attention(Q,K,V)
\end{aligned}\]

&lt;p&gt;X 经过自注意力计算后，得到的「暗含」了大量原数据内部信息的 Z。然后我们拿着这个带有自注意力信息的 Z 进行后续的操作。这里要强调的是，Z 向量中的每个元素 z_i 都与 X 的所有元素有某种关联，而不是只与 x_i 有关联。&lt;/p&gt;

&lt;h5 id=&quot;12如何计算-qkv&quot;&gt;1.2、如何计算 Q、K、V&lt;/h5&gt;

&lt;p&gt;Q、K、V 全部来自输入 X 的线性变换：&lt;/p&gt;

\[\begin{aligned}
Q &amp;amp;= W^Q \cdot X \\
K &amp;amp;= W^K \cdot X \\
V &amp;amp;= W^V \cdot X
\end{aligned}\]

&lt;p&gt;\(W^Q、W^K、W^V\)  以随机初始化开始，经过训练就会得到非常好的表现。对于  \(X\)  中的每一个词向量  \(x_i\) ，经过这个变换后得到了：&lt;/p&gt;

\[\begin{aligned}
q_i &amp;amp;= W^Q \cdot x_i \\
k_i &amp;amp;= W^K \cdot x_i \\
v_i &amp;amp;= W^V \cdot x_i
\end{aligned}\]

&lt;h5 id=&quot;13注意力函数如何通过-qv-得到-z&quot;&gt;1.3、注意力函数：如何通过 Q、V 得到 Z&lt;/h5&gt;

&lt;p&gt;基于上面的启发，我们认为 X 经过自注意力的挖掘后，得到了：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;暗含信息 1：一组 query 与一组 key 之间的关联，记作 qk（想一下信息检索系统要用 query 先招到 key）&lt;/li&gt;
  &lt;li&gt;暗含信息 2：一组 value&lt;/li&gt;
  &lt;li&gt;暗含信息 3：qk 与 value 的某种关联&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这三组信息，分别如何表示呢？这里又需要一些启发了，因为计算机科学其实是在「模拟还原」现实世界，在 AI 的领域目前的研究方向就是模拟还原人脑的思考。所以这种「模拟还原」都是寻找某一种近似方法，因此不能按照数学、物理的逻辑推理来理解，而应该按照「工程」或者「计算科学」来理解，想想我们大学时学的「计算方法」这门课，因此常需要一些启发来找到某种「表示」。&lt;/p&gt;

&lt;p&gt;这里 Transformer 的作者，认为  \(Q\)  和  \(K\)  两个向量之间的关联，是我们在用  \(Q\)  找其在  \(K\)  上的投影，如果  \(Q\) 、 \(K\)  是单位长度的向量，那么这个投影其实可以理解为找「 \(Q\)  和  \(K\)  向量之间的相似度」：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果  \(Q\)  和  \(K\)  垂直，那么两个向量正交，其点积（Dot Product）为 0；&lt;/li&gt;
  &lt;li&gt;如果  \(Q\)  和  \(K\)  平行，那么两个向量点积为两者模积  \(\|Q\|\|K\|\) ；&lt;/li&gt;
  &lt;li&gt;如果  \(Q\)  和  \(K\)  呈某个夹角，则点积就是  \(Q\)  在  \(K\)  上的投影的模。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此「暗含信息 1」就可以用「 \(Q\cdot K\) 」再经过 Softmax 归一化来表示。这个表示，是一个所有元素都是 0~1 的矩阵，可以理解成对应注意力机制里的「注意力分数」，也就是一个「注意力分数矩阵（Attention Score Matrix）」。&lt;/p&gt;

&lt;p&gt;而「暗含信息 2」则是输入  \(X\)  经过的线性变换后的特征，看做  \(X\)  的另一种表示。然后我们用这个「注意力分数矩阵」来加持一下  \(V\) ，这个点积过程就表示了「暗含信息 3」了。所以我们有了如下公式：&lt;/p&gt;

\[\begin{aligned}
Z = Attention(Q,K,V) = Softmax(Q \cdot K^T) \cdot V
\end{aligned}\]

&lt;p&gt;其实到这里，这个注意力函数已经可以用了。有时候，为了避免因为向量维度过大，导致  \(Q \cdot K^T\)  点积结果过大，我们再加一步处理：&lt;/p&gt;

\[\begin{aligned}
Z = Attention(Q,K,V) = Softmax(\frac{Q \cdot K^T}{\sqrt{\smash[b]{d_k}}}) \cdot V
\end{aligned}\]

&lt;p&gt;这里  \(d_k\)  是 K 矩阵中向量  \(k_i\)  的维度。这一步修正还有进一步的解释，即如果经过 Softmax 归一化后模型稳定性存在问题。怎么理解？如果假设 Q 和 K 中的每个向量的每一维数据都具有零均值、单位方差，这样输入数据是具有稳定性的，那么如何让「暗含信息 1」计算后仍然具有稳定性呢？即运算结果依然保持零均值、单位方差，就是除以「 \(\sqrt{\smash[b]{d_k}}\) 」。&lt;/p&gt;

&lt;h5 id=&quot;14其他注意力函数&quot;&gt;1.4、其他注意力函数&lt;/h5&gt;

&lt;p&gt;为了提醒大家这种暗含信息的表示，都只是计算方法上的一种选择，好坏全靠结果评定，所以包括上面的在内，常见的注意力函数有（甚至你也可以自己定义）：&lt;/p&gt;

\[Z = Attention(Q,K,V) =
\begin{cases}
\begin{aligned}
&amp;amp;= Softmax(Q^T K) V \\
&amp;amp;= Softmax(\frac{Q K^T}{\sqrt{\smash[b]{d_k}}}) V \\
&amp;amp;= Softmax(\omega^T tanh(W[q;k])) V \\
&amp;amp;= Softmax(Q^T W K) V \\
&amp;amp;= cosine[Q^T K] V
\end{aligned}
\end{cases}\]

&lt;p&gt;到这里，我们就从原始的输入  \(X\)  得到了一个包含自注意力信息的  \(Z\)  了，后续就可以用  \(Z\)  了。&lt;/p&gt;

&lt;h4 id=&quot;2多头注意力&quot;&gt;2、多头注意力&lt;/h4&gt;

&lt;p&gt;到这里我们理解了「自注意力」，而 Transformer 这篇论文通过添加「多头」注意力的机制进一步提升了注意力层。我们先看下它是什么，然后看下它的优点。从本小节开始，本文大量插图引用自&lt;a href=&quot;http://jalammar.github.io/illustrated-transformer/&quot;&gt;《The Illustrated Transformer》&lt;/a&gt;，作者 Jay Alammar 写出一篇非常深入浅出的图解文章，被大量引用，非常出色，再次建议大家去阅读。&lt;/p&gt;

&lt;p&gt;Transformer 中用了 8 个头，也就是 8 组不同的 Q-K-V：&lt;/p&gt;

\[\begin{aligned}
Q_0 = W_0^Q \cdot X ;\enspace K_0 = &amp;amp;W_0^K \cdot X ;\enspace V_0 = W_0^V \cdot X \\
Q_1 = W_1^Q \cdot X ;\enspace K_1 = &amp;amp;W_0^K \cdot X ;\enspace V_1 = W_1^V \cdot X \\
&amp;amp;.... \\
Q_7 = W_7^Q \cdot X ;\enspace K_7 = &amp;amp;W_0^K \cdot X ;\enspace V_7 = W_7^V \cdot X
\end{aligned}\]

&lt;p&gt;这样我们就能得到 8 个 Z：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;Z_0 = Attention(Q_0,K_0,V_0) = Softmax(\frac{Q_0 \cdot K_0^T}{\sqrt{\smash[b]{d_k}}}) \cdot V_0 \\
&amp;amp;Z_1 = Attention(Q_1,K_1,V_1) = Softmax(\frac{Q_1 \cdot K_1^T}{\sqrt{\smash[b]{d_k}}}) \cdot V_1 \\
&amp;amp;... \\
&amp;amp;Z_7 = Attention(Q_7,K_7,V_7) = Softmax(\frac{Q_7 \cdot K_7^T}{\sqrt{\smash[b]{d_k}}}) \cdot V_7 \\
\end{aligned}\]

&lt;p&gt;然后我们把  \(Z_0\)  到  \(Z_7\)  沿着行数不变的方向全部连接起来，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-3.png&quot; alt=&quot;image&quot; width=&quot;464&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们再训练一个权重矩阵  \(W^O\) ，然后用上面拼接的  \(Z_{0~7}\)  乘以这个权重矩阵：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-4.png&quot; alt=&quot;image&quot; width=&quot;135&quot; /&gt;&lt;/p&gt;

&lt;p&gt;于是我们会得到一个 Z 矩阵：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-5.png&quot; alt=&quot;image&quot; width=&quot;100&quot; /&gt;&lt;/p&gt;

&lt;p&gt;到这里就是多头注意力机制的全部内容，与单头注意力相比，都是为了得到一个 Z 矩阵，但是多头用了多组 Q-K-V，然后经过拼接、乘以权重矩阵得到最后的 Z。我们总览一下整个过程：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-6.png&quot; alt=&quot;image&quot; width=&quot;935&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过多头注意力，每个头都会关注到不同的信息，可以如下类似表示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-7.png&quot; alt=&quot;image&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这通过两种方式提高了注意力层的性能：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;多头注意力机制，扩展了模型关注不同位置的能力。 \(Z\)  矩阵中的每个向量  \(z_i\)  包含了与  \(X\)  中所有向量  \(x_i\)  有关的一点编码信息。反过来说，不要认为  \(z_i\)  只与  \(x_i\)  有关。&lt;/li&gt;
  &lt;li&gt;多头注意力机制，为注意力层提供了多个「表示子空间 Q-K-V」，以及 Z。这样一个输入矩阵  \(X\) ，就会被表示成 8 种不同的矩阵 Z，都包含了原始数据信息的某种解读暗含其中。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3退化现象残差网络与-short-cut&quot;&gt;3、退化现象、残差网络与 Short-Cut&lt;/h4&gt;

&lt;h5 id=&quot;31退化现象&quot;&gt;3.1、退化现象&lt;/h5&gt;

&lt;p&gt;对于一个 56 层的神经网路，我们很自然地会觉得应该比 20 层的神经网络的效果要好，比如说从误差率（error）的量化角度看。但是华人学者何凯明等人的论文&lt;a href=&quot;https://arxiv.org/pdf/1512.03385.pdf&quot;&gt;《Deep Residual Learning for Image Recognition》&lt;/a&gt;中给我们呈现了相反的结果，而这个问题的原因并不是因为层数多带来的梯度爆炸/梯度消失（毕竟已经用了归一化解决了这个问题），而是因为一种反常的现象，这种现象我们称之为「退化现象」。何凯明等人认为这是因为存在「难以优化好的网络层」。&lt;/p&gt;

&lt;h5 id=&quot;32恒等映射&quot;&gt;3.2、恒等映射&lt;/h5&gt;

&lt;p&gt;如果这 36 层还帮了倒忙，那还不如没有，是不是？所以这多出来的 36 个网络层，如果对于提升性能（例如误差率）毫无影响，甚至更进一步，这 36 层前的输入数据，和经过这 36 层后的输出数据，完全相同，那么如果将这 36 层抽象成一个函数  \(f_{36}\) ，这就是一个恒等映射的函数：&lt;/p&gt;

\[f_{36}(x) = x\]

&lt;p&gt;回到实际应用中。如果我们对于一个神经网络中的连续 N 层是提升性能，还是降低性能，是未知的，那么则可以建立一个跳过这些层的连接，实现：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果这 N 层可以提升性能，则采用这 N 层；否则就跳过。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这就像给了这 N 层神经网络一个试错的空间，待我们确认它们的性能后再决定是否采用它们。同时也可以理解成，这些层可以去单独优化，如果性能提升，则不被跳过。&lt;/p&gt;

&lt;h5 id=&quot;33残差网络residual-network与捷径short-cut&quot;&gt;3.3、残差网络（Residual Network）与捷径（Short-Cut）&lt;/h5&gt;

&lt;p&gt;如果前面 20 层已经可以实现 99% 的准确率，那么引入了这 36 层能否再提升「残差剩余那 1%」的准确率从而达到 100% 呢？所以这 36 层的网络，就被称为「残差网络（Residual Network，常简称为 ResNet）」，这个叫法非常形象。&lt;/p&gt;

&lt;p&gt;而那个可以跳过 N 层残差网络的捷径，则常被称为 Short-Cut，也会被叫做跳跃链接（Skip Conntection），这就解决了上述深度学习中的「退化现象」。&lt;/p&gt;

&lt;h4 id=&quot;4位置编码positional-embedding&quot;&gt;4、位置编码（Positional Embedding）&lt;/h4&gt;

&lt;p&gt;还记得我在第二部分最后提到的吗：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;这个注意力机制忽略了位置信息。比如 Tigers love rabbits 和 Rabbits love tigers 会产生一样的注意力分数。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;41transformer-论文中的三角式位置编码sinusoidal-positional-encoding&quot;&gt;4.1、Transformer 论文中的三角式位置编码（Sinusoidal Positional Encoding）&lt;/h5&gt;

&lt;p&gt;现在我们来解决这个问题，为每一个输入向量  \(x_i\)  生成一个位置编码向量  \(t_i\) ，这个位置编码向量的维度，与输入向量（词的嵌入式向量表示）的维度是相同的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2023-01-04-language-model-5-8.png&quot; alt=&quot;image&quot; width=&quot;500&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Transformer 论文中给出了如下的公式，来计算位置编码向量的每一位的值：&lt;/p&gt;

\[\begin{aligned}
P_{pos,2i} &amp;amp;= sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}}) \\
P_{pos,2i+1} &amp;amp;= cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})
\end{aligned}\]

&lt;p&gt;这样对于一个 embedding，如果它在输入内容中的位置是 pos，那么其编码向量就表示为：&lt;/p&gt;

\[\begin{aligned}
[P_{pos,0}, P_{pos,1}, ... , P_{pos,d_x-1}]
\end{aligned}\]

&lt;p&gt;延展开的话，位置编码其实还分为绝对位置编码（Absolute Positional Encoding）、相对位置编码（Relative Positional Encoding）。前者是专门生成位置编码，并想办法融入到输入中，我们上面看到的就是一种。后者是微调 Attention 结构，使得它可以分辨不同位置的数据。另外其实还有一些无法分类到这两种的位置编码方法。&lt;/p&gt;

&lt;h5 id=&quot;42绝对位置编码&quot;&gt;4.2、绝对位置编码&lt;/h5&gt;

&lt;p&gt;绝对位置编码，如上面提到的，就是定义一个位置编码向量  \(t_i\) ，通过  \(x_i + t_i\)  就得到了一个含有位置信息的向量。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;习得式位置编码（Learned Positional Encoding）：将位置编码当做训练参数，生成一个「最大长度 x 编码维度」的位置编码矩阵，随着训练进行更新。目前 Google BERT、OpenAI GPT 模型都是用的这种位置编码。缺点是「外推性」差，如果文本长度超过之前训练时用的「最大长度」则无法处理。目前有一些给出优化方案的论文，比如「&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;amp;mid=2247515573&amp;amp;idx=1&amp;amp;sn=2d719108244ada7db3a535a435631210&amp;amp;chksm=96ea6235a19deb23babde5eaac484d69e4c2f53bab72d2e350f75bed18323eea3cf9be30615b#rd&quot;&gt;层次分解位置编码&lt;/a&gt;」。&lt;/li&gt;
  &lt;li&gt;三角式位置编码（Sinusoidal Positional Encodign）：上面提过了。&lt;/li&gt;
  &lt;li&gt;循环式位置编码（Recurrent Positional Encoding）：通过一个 RNN 再接一个 Transformer，那么 RNN 暗含的「顺序」就导致不再需要额外编码了。但这样牺牲了并行性，毕竟 RNN 的两大缺点之一就有这个。&lt;/li&gt;
  &lt;li&gt;相乘式位置编码（Product Positional Encoding）：用「 \(x_i \odot t_i\) 」代替「 \(x_i + t_i\) 」。&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;43相对位置编码&quot;&gt;4.3、相对位置编码&lt;/h5&gt;

&lt;p&gt;最早来自于 Google 的论文&lt;a href=&quot;https://arxiv.org/abs/1803.02155&quot;&gt;《Self-Attention with Relative Position Representations》&lt;/a&gt;相对位置编码，考虑的是当前 position 与被 attention 的 position 之前的相对位置。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;经典式&lt;/li&gt;
  &lt;li&gt;XLNET 式&lt;/li&gt;
  &lt;li&gt;T5 式&lt;/li&gt;
  &lt;li&gt;DeBERTa 式&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;44其他位置编码&quot;&gt;4.4、其他位置编码&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;CNN 式&lt;/li&gt;
  &lt;li&gt;复数式&lt;/li&gt;
  &lt;li&gt;融合式&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5transformer-模型整体&quot;&gt;5、Transformer 模型整体&lt;/h4&gt;

&lt;p&gt;——&amp;gt; 未完待续&lt;/p&gt;

&lt;p&gt;最后我们再来整体看一下 Transformer：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先输入数据生成词的 Embedding、位置编码&lt;/li&gt;
  &lt;li&gt;在 Encoder 里，先进入 N 层 Attention 的处理，最后进入一个全连接层，期间可能有 Short-Cut&lt;/li&gt;
  &lt;li&gt;然后经过 Normalization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;——&amp;gt; 未完待续&lt;/p&gt;

&lt;h4 id=&quot;6来看一段用-pytorch-实现的-transformer-示例&quot;&gt;6、来看一段用 PyTorch 实现的 Transformer 示例&lt;/h4&gt;

&lt;h3 id=&quot;参考&quot;&gt;参考&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;http://jalammar.github.io/illustrated-transformer/&lt;/li&gt;
  &lt;li&gt;《自然语言处理：基于预训练模型的方法》车万翔 等&lt;/li&gt;
  &lt;li&gt;《自然语言处理实战：预训练模型应用及其产品化》安库·A·帕特尔 等&lt;/li&gt;
  &lt;li&gt;https://lilianweng.github.io/posts/2018-06-24-attention/&lt;/li&gt;
  &lt;li&gt;《基于深度学习的道路短期交通状态时空序列预测》&lt;/li&gt;
  &lt;li&gt;https://www.zhihu.com/question/325839123&lt;/li&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/410776234&lt;/li&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/48508221&lt;/li&gt;
  &lt;li&gt;https://luweikxy.gitbook.io/machine-learning-notes/self-attention-and-transformer&lt;/li&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/352898810&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="AI" /><category term="人工智能" /><category term="NLP" /><category term="自然语言处理" /><category term="神经网络" /><category term="Attention" /><category term="注意力" /><category term="AIGC" /><category term="Transformer" /><category term="自注意力" /><category term="Self-Attention" /><category term="多头注意力" /><category term="Multiple Head Attention" /><category term="残差网络" /><category term="Short-Cut" /><category term="位置编码" /><category term="Bahdanau" /><category term="Encoder-Decoder" /><summary type="html">基于 RNN 的 Encoder-Decoder 模型存在无法处理过长文本、并行性差的两大痛点。2015 年 Bahdanau 等人在其论文中提出 Attention 机制，再到 2017 年 Transformer 模型的论文《Attention is All You Need》横空出世，其并行速度极快，而且每两个词之间的词间距都是 1。此后 NLP 领域 Transformer 彻底成为主流。如果你已经了解 Encoder-Decoder 模型，本文将基于此带你深入浅出的搞清楚 Attention、Transformer。</summary></entry><entry><title type="html">麦克船长 NLP 语言模型技术笔记 4：循环神经网络（RNN）</title><link href="https://www.mikecaptain.com/2023/01/01/language-model-4/" rel="alternate" type="text/html" title="麦克船长 NLP 语言模型技术笔记 4：循环神经网络（RNN）" /><published>2023-01-01T21:01:31+00:00</published><updated>2023-01-01T21:01:31+00:00</updated><id>https://www.mikecaptain.com/2023/01/01/language-model-4</id><content type="html" xml:base="https://www.mikecaptain.com/2023/01/01/language-model-4/">&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#1经典结构的-rnn&quot; id=&quot;markdown-toc-1经典结构的-rnn&quot;&gt;1、经典结构的 RNN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2n-vs1-的-rnn&quot; id=&quot;markdown-toc-2n-vs1-的-rnn&quot;&gt;2、N vs.1 的 RNN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#31-vs-n-的-rnn&quot; id=&quot;markdown-toc-31-vs-n-的-rnn&quot;&gt;3、1 vs. N 的 RNN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4lstmlong-short-term-memory长短时记忆网络&quot; id=&quot;markdown-toc-4lstmlong-short-term-memory长短时记忆网络&quot;&gt;4、LSTM（Long Short-Term Memory）长短时记忆网络&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#41如何理解这个-short-term-呢&quot; id=&quot;markdown-toc-41如何理解这个-short-term-呢&quot;&gt;4.1、如何理解这个 Short-Term 呢？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#42引入遗忘门-f输入门-i输出门-o记忆细胞-c&quot; id=&quot;markdown-toc-42引入遗忘门-f输入门-i输出门-o记忆细胞-c&quot;&gt;4.2、引入遗忘门 f、输入门 i、输出门 o、记忆细胞 c&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5双向循环神经网络双向-lstm&quot; id=&quot;markdown-toc-5双向循环神经网络双向-lstm&quot;&gt;5、双向循环神经网络、双向 LSTM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6堆叠循环神经网络堆叠-lstm&quot; id=&quot;markdown-toc-6堆叠循环神经网络堆叠-lstm&quot;&gt;6、堆叠循环神经网络、堆叠 LSTM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7n-vs-m-的-rnn&quot; id=&quot;markdown-toc-7n-vs-m-的-rnn&quot;&gt;7、N vs. M 的 RNN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果您喜欢机器学习，那么您一定会喜欢这篇文章。在这篇文章中，我们将深入探讨 RNN（循环神经网络），这是一种强大的神经网络模型，能够预测序列数据，例如文本、语音和时间序列。我们将通过生动的代码示例和实际案例来演示如何使用 RNN，并在日常生活中真实地体验它的功能。您将学习到如何使用 RNN 解决各种机器学习问题，并动手尝试运用 RNN 解决实际问题。这篇文章将为您提供一个完整的 RNN 入门指南，并使您对 RNN 有更深入的了解。&lt;/p&gt;

&lt;p&gt;RNN（Recurrent Neural Network）的 R 是 Recurrent 的意思，所以这是一个贷循环的神经网络。首先要明白一点，你并不需要搞懂 CNN 后才能学习 RNN 模型。你只要了解了 MLP 就可以学习 RNN 了。&lt;/p&gt;

&lt;h3 id=&quot;1经典结构的-rnn&quot;&gt;1、经典结构的 RNN&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-19-language-model-1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图这是一个经典结构的 RNN 示意图，Unfold 箭头右侧是展开示意。输入序列（这里用 x 表示）传递给隐藏层（hidden layer，这里用 h 表示），处理完生成输出序列（这里用 o 表示）。序列的下一个词输入时的、上一步隐藏层会一起影响这一步的输出。U、V、W 都表示权重。在这个经典结构理，你可以看到非常重要的一点，就是输入序列长度与输出序列长度是相同的。&lt;/p&gt;

&lt;p&gt;这种经典结构的应用场景，比如对一段普通话输入它的四川话版本，比如对视频的每一帧进行处理并输出，等等。&lt;/p&gt;

&lt;p&gt;我们知道 RNN 是一个一个序列处理的，每个序列中的数据项都是有序的，所以对于计算一个序列内的所有数据项是无法并行的。但是计算不同序列时，不同序列各自的计算则是可以并行的。如果我们把上一个时刻 t 隐藏层输出的结果（ \(h_{t-1}\) ）传给一个激活函数（比如说用正切函数 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tanh&lt;/code&gt; 函数），然后和当下时刻 t 的这个输入（ \(x_{t}\) ）一起，处理后产生一个时刻 t 的输出（ \(h_t\) ）。然后把隐藏层的输出通过多项逻辑回归（Softmax）生成最终的输出值（ \(\bm{y}\) ），我们可以如下表示这个模型：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{h}_t = tanh(\bm{W}^{xh} \cdot \bm{x}_t + \bm{b}^{xh} + \bm{W}^{hh} \cdot \bm{h}_{t-1} + \bm{b}^{hh}) \\
&amp;amp;\bm{y}_t = Softmax(\bm{W}^{hy} \cdot \bm{h_t} + \bm{b}^{hy})
\end{aligned}\]

&lt;p&gt;对应的示意图如下：&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-34cd77ba92d6e898bab41a54b23f2324&quot; width=&quot;278pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 278.00 188.00&quot;&gt;
&lt;title&gt;graphviz-34cd77ba92d6e898bab41a54b23f2324&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same h1 h2 hddd hn}
	{rank=same x1 x2 xddd xn}
	{rank=same y1 y2 yddd yn}
	xddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]
	hddd[label=&amp;quot;...&amp;quot;]

	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	yn[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]

	h1 -&amp;gt; h2
	h2 -&amp;gt; hddd
	hddd -&amp;gt; hn

	x1 -&amp;gt; h1
	x2 -&amp;gt; h2
	xddd -&amp;gt; hddd
	xn -&amp;gt; hn

	h1 -&amp;gt; y1
	h2 -&amp;gt; y2
	hddd -&amp;gt; yddd
	hn -&amp;gt; yn
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 274,-184 274,4 -4,4&quot; /&gt;
&lt;!-- h1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M54,-90C56.61,-90 59.23,-90 61.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;61.93,-93.5 71.93,-90 61.93,-86.5 61.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-108.3C27,-116.02 27,-125.29 27,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-133.9 27,-143.9 30.5,-133.9 23.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M126,-90C128.61,-90 131.23,-90 133.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;133.93,-93.5 143.93,-90 133.93,-86.5 133.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node10&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-108.3C99,-116.02 99,-125.29 99,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-133.9 99,-143.9 102.5,-133.9 95.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hn --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hn&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;243&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;hn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M198,-90C200.61,-90 203.23,-90 205.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;205.93,-93.5 215.93,-90 205.93,-86.5 205.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node11&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-108.3C171,-116.02 171,-125.29 171,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-133.9 171,-143.9 174.5,-133.9 167.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- yn --&gt;
&lt;g id=&quot;node12&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;yn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hn&amp;#45;&amp;gt;yn --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hn&amp;#45;&amp;gt;yn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-108.3C243,-116.02 243,-125.29 243,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-133.9 243,-143.9 246.5,-133.9 239.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;h1 --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;h1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-36.3C27,-44.02 27,-53.29 27,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-61.9 27,-71.9 30.5,-61.9 23.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-36.3C99,-44.02 99,-53.29 99,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-61.9 99,-71.9 102.5,-61.9 95.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-36.3C171,-44.02 171,-53.29 171,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-61.9 171,-71.9 174.5,-61.9 167.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-36.3C243,-44.02 243,-53.29 243,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-61.9 243,-71.9 246.5,-61.9 239.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;这种输入和输出数据项数一致的 RNN，一般叫做 N vs. N 的 RNN。如果我们用 PyTorch 来实现一个非常简单的经典 RNN 则如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 创建一个 RNN 实例
# 第一个参数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 实例化一个单向单层RNN
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 输入是一个形状为 (5, 3, 10) 的张量
# 5 个输入数据项（也可以说是样本）
# 3 个数据项是一个序列，有 3 个 steps
# 每个 step 有 10 个特征
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 隐藏层是一个 (1, 5, 20) 的张量
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 调用 rnn 函数后，返回输出、最终的隐藏状态
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;我们来解读一下这段代码：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;这段代码实例化了一个带有 1 个隐藏层的 RNN 网络。&lt;/li&gt;
  &lt;li&gt;它的输入是一个形状为 (5, 3, 10) 的张量，表示有 5 个样本，每个样本有 3 个时间步，每个时间步的特征维度是 10。&lt;/li&gt;
  &lt;li&gt;初始隐藏状态是一个形状为 (1, 5, 20) 的张量。&lt;/li&gt;
  &lt;li&gt;调用 rnn 函数后，会返回输出和最终的隐藏状态。&lt;/li&gt;
  &lt;li&gt;输出的形状是 (5, 3, 20)，表示有 5 个样本，每个样本有 3 个时间步，每个时间步的输出维度是 20。&lt;/li&gt;
  &lt;li&gt;最终的隐藏状态的形状是 (1, 5, 20)，表示最后的隐藏状态是 5&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但是上面的代码示例，并没有自己编写一个具体的 RNN，而是用了默认的 PyTorch 的 RNN，那么下面我们就自己编写一个：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MikeCaptainRNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 对于 RNN，输入维度就是序列数
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 隐藏层有多少个节点/神经元，经常将 hidden_size 设置为与序列长度相同
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 输入层到隐藏层的 W^{xh} 权重、bias^{xh} 偏置项
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_xh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias_xh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 隐藏层到隐藏层的 W^{hh} 权重、bias^{hh} 偏置项
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_hh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias_hh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 前向传播
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    	&lt;span class=&quot;c1&quot;&gt;# 取出这个张量的形状
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 初始化一个全零张量
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 处理每个时刻的输入特征
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        	&lt;span class=&quot;c1&quot;&gt;# 获得当前时刻的输入特征，[N, input_size, 1]。unsqueeze(n)，在第 n 维上增加一维
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
            &lt;span class=&quot;n&quot;&gt;w_xh_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_xh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [N, hidden_size, input_size]
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;w_hh_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_hh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [N, hidden_size, hidden_size]
&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# bmm 是矩阵乘法函数
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;w_times_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bmm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_xh_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [N, hidden_size]。squeeze(n)，在第n维上减小一维
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;w_times_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bmm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_hh_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [N, hidden_size]
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_times_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias_ih&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_times_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias_hh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上述代码中 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;weight_xh&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bias_xh&lt;/code&gt;。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;weighthh&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;2n-vs1-的-rnn&quot;&gt;2、N vs.1 的 RNN&lt;/h3&gt;

&lt;p&gt;上面那个图里，如果只保留最后一个输出，那就是一个 N vs. 1 的 RNN 了。这种的应用场景，比如说判断一个文本序列是英语还是德语，比如根据一个输入序列来判断是一个正向情绪内容还是负向或者中性，或者比如根据一段语音输入序列来判断是哪一首曲子（听歌识曲）。&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{h}_t = tanh(\bm{W^{xh}} \cdot \bm{x}_t + \bm{b^{xh}} + \bm{W^{hh}} \cdot \bm{h}_{t-1} + \bm{b^{hh}}) \\
&amp;amp;\bm{y} = Softmax(\bm{W^{hy}} \cdot \bm{h}_n + \bm{b^{hy}})
\end{aligned}\]

&lt;p&gt;即这个模型里，每个序列只有隐藏层对最后一个数据项进行处理时才产生输出  \(h_n\)  如果用示意图表示，则是如下结构：&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-99506286249ff03a109fde8e4294e12c&quot; width=&quot;278pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 278.00 188.00&quot;&gt;
&lt;title&gt;graphviz-99506286249ff03a109fde8e4294e12c&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same h1 h2 hddd hn}
	hddd[label=&amp;quot;...&amp;quot;]
	xddd[label=&amp;quot;...&amp;quot;]

	y[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]

	h1 -&amp;gt; h2
	h2 -&amp;gt; hddd
	hddd -&amp;gt; hn

	x1 -&amp;gt; h1
	x2 -&amp;gt; h2
	xn -&amp;gt; hn
	xddd -&amp;gt; hddd

	hn -&amp;gt; y
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 274,-184 274,4 -4,4&quot; /&gt;
&lt;!-- h1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M54,-90C56.61,-90 59.23,-90 61.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;61.93,-93.5 71.93,-90 61.93,-86.5 61.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- hddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M126,-90C128.61,-90 131.23,-90 133.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;133.93,-93.5 143.93,-90 133.93,-86.5 133.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- hn --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hn&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;243&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;hn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M198,-90C200.61,-90 203.23,-90 205.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;205.93,-93.5 215.93,-90 205.93,-86.5 205.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hn&amp;#45;&amp;gt;y --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hn&amp;#45;&amp;gt;y&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-108.3C243,-116.02 243,-125.29 243,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-133.9 243,-143.9 246.5,-133.9 239.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-36.3C171,-44.02 171,-53.29 171,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-61.9 171,-71.9 174.5,-61.9 167.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;h1 --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;h1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-36.3C27,-44.02 27,-53.29 27,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-61.9 27,-71.9 30.5,-61.9 23.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-36.3C99,-44.02 99,-53.29 99,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-61.9 99,-71.9 102.5,-61.9 95.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-36.3C243,-44.02 243,-53.29 243,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-61.9 243,-71.9 246.5,-61.9 239.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;31-vs-n-的-rnn&quot;&gt;3、1 vs. N 的 RNN&lt;/h3&gt;

&lt;p&gt;反过来，上面那个图里，如果只保留一个 x，那么就是一个 1 vs. N 的 RNN 了。这种场景的应用，比如 AI 创作音乐，还有通过一个 image 提炼或识别某些文本内容输出。&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{h}_t = \begin{cases} tanh(\bm{W^{xh}} \cdot \bm{x} + \bm{b^{xh}} + 0 + \bm{b^{hh}}) &amp;amp; (t=1) \\
tanh(0 + \bm{b^{xh}} + \bm{W^{hh}} \cdot \bm{h}_{t-1} + \bm{b^{hh}}) &amp;amp; (t&amp;gt;1) \end{cases} \\
&amp;amp;\bm{y}_t = Softmax(\bm{W^{hy}} \cdot \bm{h}_t + \bm{b^{hy}})
\end{aligned}\]

&lt;p&gt;示意图如下：&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-aecb5ea5cd91fc1106b18c3c4059fa0a&quot; width=&quot;278pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 278.00 188.00&quot;&gt;
&lt;title&gt;graphviz-aecb5ea5cd91fc1106b18c3c4059fa0a&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same h1 h2 hddd hn}
	{rank=same y1 y2 yddd yn}
	hddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]

	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	yn[shape=plaintext]
	x[shape=plaintext]

	h1 -&amp;gt; h2
	h2 -&amp;gt; hddd
	hddd -&amp;gt; hn

	x -&amp;gt; h1

	h1 -&amp;gt; y1
	h2 -&amp;gt; y2
	hddd -&amp;gt; yddd
	hn -&amp;gt; yn
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 274,-184 274,4 -4,4&quot; /&gt;
&lt;!-- h1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M54,-90C56.61,-90 59.23,-90 61.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;61.93,-93.5 71.93,-90 61.93,-86.5 61.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-108.3C27,-116.02 27,-125.29 27,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-133.9 27,-143.9 30.5,-133.9 23.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M126,-90C128.61,-90 131.23,-90 133.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;133.93,-93.5 143.93,-90 133.93,-86.5 133.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-108.3C99,-116.02 99,-125.29 99,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-133.9 99,-143.9 102.5,-133.9 95.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hn --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hn&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;243&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;hn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M198,-90C200.61,-90 203.23,-90 205.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;205.93,-93.5 215.93,-90 205.93,-86.5 205.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-108.3C171,-116.02 171,-125.29 171,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-133.9 171,-143.9 174.5,-133.9 167.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- yn --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;yn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hn&amp;#45;&amp;gt;yn --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hn&amp;#45;&amp;gt;yn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-108.3C243,-116.02 243,-125.29 243,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-133.9 243,-143.9 246.5,-133.9 239.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x&amp;#45;&amp;gt;h1 --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x&amp;#45;&amp;gt;h1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-36.3C27,-44.02 27,-53.29 27,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-61.9 27,-71.9 30.5,-61.9 23.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;到这里我们可以看到，在 RNN 的隐藏层是能够存储一些有关于输入数据的一些相关内容的，所以也常把 RNN 的隐藏层叫做记忆单元。&lt;/p&gt;

&lt;h3 id=&quot;4lstmlong-short-term-memory长短时记忆网络&quot;&gt;4、LSTM（Long Short-Term Memory）长短时记忆网络&lt;/h3&gt;

&lt;h4 id=&quot;41如何理解这个-short-term-呢&quot;&gt;4.1、如何理解这个 Short-Term 呢？&lt;/h4&gt;

&lt;p&gt;1997 年论文《Long Short-Term Memory》中提出 LSTM 模型。我们先从模型的定义，精确地来理解一下：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{h}_t = \bm{h}_{t-1} + tanh(\bm{W}^{xh} \cdot \bm{x}_t + \bm{b}^{xh} + \bm{W}^{hh} \cdot \bm{h}_{t-1} + \bm{b}^{hh}) \\
&amp;amp;\bm{y}_t = Softmax(\bm{W}^{hy} \cdot \bm{h_t} + \bm{b}^{hy})
\end{aligned}\]

&lt;p&gt;上式中与经典结构的 RNN（输入与输出是 N vs. N）相比，唯一的区别是第一个式子中多了一个「 \(\bm{h}_{t-1}\) 」。如果我们把第一个式子的  \(tanh\)  部分记作  \(u_t\) ：&lt;/p&gt;

\[\bm{u}_t = tanh(\bm{W}^{xh} \cdot \bm{x}_t + \bm{b}^{xh} + \bm{W}^{hh} \cdot \bm{h}_{t-1} + \bm{b}^{hh})\]

&lt;p&gt;所以：&lt;/p&gt;

\[\bm{h}_t = \bm{h}_{t-1} + \bm{u}_t\]

&lt;p&gt;那么可以展开出如下一组式子：&lt;/p&gt;

\[\begin{aligned}
\bm{h}_{k+1} &amp;amp;= \bm{h}_k + \bm{u}_{k+1} \\
\bm{h}_{k+2} &amp;amp;= \bm{h}_{k+1} + \bm{u}_{k+2} \\
&amp;amp;...... \\
\bm{h}_{t-1} &amp;amp;= \bm{h}_{t-2} + \bm{u}_{t-1} \\
\bm{h}_t &amp;amp;= \bm{h}_{t-1} + \bm{u}_t
\end{aligned}\]

&lt;p&gt;如果我们从  \(h_{k+1}\)  到  \(h_n\)  的所有式子左侧相加、右侧相加，我们就得到如下式子：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{h}_{k+1} + ... + \bm{h}_{t-1} + \bm{h}_t \\
= &amp;amp;\bm{h}_k + \bm{h}_{k+1} + ... + \bm{h}_{t-2} + \bm{h}_{t-1} \\+ &amp;amp;\bm{u}_{k+1} + \bm{u}_{k+2} + ... + \bm{u}_{t-1} + \bm{u}_t
\end{aligned}\]

&lt;p&gt;进而推导出：&lt;/p&gt;

\[\bm{h}_t = \bm{h}_k + \bm{u}_{k+1} + \bm{u}_{k+2} + ... + \bm{u}_{t-1} + \bm{u}_t\]

&lt;p&gt;从这里我们就可以看到，第 t 时刻的隐藏层输出，直接关联到第 k 时刻的输出，t 到 k 时刻的相关性则用  \(\bm{u}_{k+1}\)  到  \(\bm{u}_t\)  相加表示。也就是有 t-k 的短期（Short Term）记忆。&lt;/p&gt;

&lt;h4 id=&quot;42引入遗忘门-f输入门-i输出门-o记忆细胞-c&quot;&gt;4.2、引入遗忘门 f、输入门 i、输出门 o、记忆细胞 c&lt;/h4&gt;

&lt;p&gt;如果我们为式子  \(\bm{h}_t = \bm{h}_{t-1} + \bm{u}_t\)  右侧两项分配一个权重呢？就是隐藏层对上一个数据项本身被上一个数据项经过隐藏层计算的结果，这两者做一对权重考虑配比，如下：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{f}_t = sigmoid(\bm{W}^{f,xh} \cdot \bm{x}_t + \bm{b}^{f,xh} + \bm{W}^{f,hh} \cdot \bm{x}_{t-1} + \bm{b}^{f,hh}) \\
&amp;amp;\bm{h}_t = \bm{f}_t \odot \bm{h}_{t-1} + (1 - \bm{f}_t) \odot \bm{u}_t
\end{aligned}\]

&lt;p&gt;其中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\odot\)  是 Hardamard 乘积，即张量的对应元素相乘。&lt;/li&gt;
  &lt;li&gt;\(\bm{f}_t\)  是「遗忘门（Forget Gate）」，该值很小时 t-1 时刻的权重就很小，也就是「此刻遗忘上一刻」。该值应根据 t 时刻的输入数据、t-1 时刻数据在隐藏层的输出计算，而且其每个元素必须是 (0, 1) 之间的值，所以可以用 sigmoid 函数来得到该值：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;但这种方式，对于过去  \(\bm{h}_{t-1}\)  和当下  \(\bm{u}_t\)  形成了互斥，只能此消彼长。但其实过去和当下可能都很重要，有可能都恨不重要，所以我们对过去继续采用  \(\bm{f}_t\)  遗忘门，对当下采用  \(\bm{i}_t\)  输入门（Input Gate）：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{f}_t = sigmoid(\bm{W}^{f,xh} \cdot \bm{x}_t + \bm{b}^{f,xh} + \bm{W}^{f,hh} \cdot \bm{x}_{t-1} + \bm{b}^{f,hh}) \\
&amp;amp;\bm{i}_t = sigmoid(\bm{W}^{i,xh} \cdot \bm{x}_t + \bm{b}^{i,xh} + \bm{W}^{i,hh} \cdot \bm{h}_{t-1} + \bm{b}^{i,hh}) \\
&amp;amp;\bm{h}_t = \bm{f}_t \odot \bm{h}_{t-1} + \bm{i}_t \odot \bm{u}_t
\end{aligned}\]

&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;与  \(\bm{f}_t\)  类似地，定义输入门  \(\bm{i}_t\)  ，但是注意  \(\bm{f}_t\)  与  \(\bm{h}_{t-1}\)  而非  \(\bm{x}_{t-1}\)  有关。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再引入一个输出门：&lt;/p&gt;

\[\bm{o}_t = sigmoid(\bm{W}^{o,xh} \cdot \bm{x}_t + \bm{b}^{o,xh} + \bm{W}^{o,hh} \cdot \bm{x}_{t-1} + \bm{b}^{o,hh})\]

&lt;p&gt;再引入记忆细胞  \(\bm{c}_t\) ，它是原来  \(\bm{h}_t\)  的变体，与 t-1 时刻的记忆细胞有遗忘关系（通过遗忘门），与当下时刻有输入门的关系：&lt;/p&gt;

\[\bm{c}_t = \bm{f}_t \odot \bm{c}_{t-1} + \bm{i}_t \odot \bm{u}_t\]

&lt;p&gt;那么此时  \(\bm{h}_t\)  ，我们可以把  \(\bm{h}_t\)  变成：&lt;/p&gt;

\[\bm{h}_t = \bm{o}_t \odot tanh(\bm{c}_t)\]

&lt;p&gt;记忆细胞这个概念还有有一点点形象的，它存储了过去的一些信息。OK，到此我们整体的 LSTM 模型就变成了这个样子：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{f}_t = sigmoid(\bm{W}^{f,xh} \cdot \bm{x}_t + \bm{b}^{f,xh} + \bm{W}^{f,hh} \cdot \bm{x}_{t-1} + \bm{b}^{f,hh}) \\
&amp;amp;\bm{i}_t = sigmoid(\bm{W}^{i,xh} \cdot \bm{x}_t + \bm{b}^{i,xh} + \bm{W}^{i,hh} \cdot \bm{h}_{t-1} + \bm{b}^{i,hh}) \\
&amp;amp;\bm{o}_t = sigmoid(\bm{W}^{o,xh} \cdot \bm{x}_t + \bm{b}^{o,xh} + \bm{W}^{o,hh} \cdot \bm{x}_{t-1} + \bm{b}^{o,hh}) \\
&amp;amp;\bm{u}_t = tanh(\bm{W}^{xh} \cdot \bm{x}_t + \bm{b}^{xh} + \bm{W}^{hh} \cdot \bm{h}_{t-1} + \bm{b}^{hh}) \\
&amp;amp;\bm{c}_t = \bm{f}_t \odot \bm{c}_{t-1} + \bm{i}_t \odot \bm{u}_t \\
&amp;amp;\bm{h}_t = \bm{o}_t \odot tanh(\bm{c}_t) \\
&amp;amp;\bm{y}_t = Softmax(\bm{W}^{hy} \cdot \bm{h_t} + \bm{b}^{hy})
\end{aligned}\]

&lt;h3 id=&quot;5双向循环神经网络双向-lstm&quot;&gt;5、双向循环神经网络、双向 LSTM&lt;/h3&gt;

&lt;p&gt;双向循环神经网络很好理解，就是两个方向都有，例如下图：&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-5d130f67fc1bf07abc38d62da6ddb01a&quot; width=&quot;278pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 278.00 188.00&quot;&gt;
&lt;title&gt;graphviz-5d130f67fc1bf07abc38d62da6ddb01a&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same h1 h2 hddd hn}

	hddd[label=&amp;quot;...&amp;quot;]
	xddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]

	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	yn[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]

	h1 -&amp;gt; y1
	h2 -&amp;gt; y2
	hddd -&amp;gt; yddd
	hn -&amp;gt; yn

	h1 -&amp;gt; h2
	h2 -&amp;gt; hddd
	hddd -&amp;gt; hn

	hn -&amp;gt; hddd
	hddd -&amp;gt; h2
	h2 -&amp;gt; h1

	x1 -&amp;gt; h1
	x2 -&amp;gt; h2
	xddd -&amp;gt; hddd
	xn -&amp;gt; hn
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 274,-184 274,4 -4,4&quot; /&gt;
&lt;!-- h1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M48.38,-101.27C54.78,-103.22 61.18,-103.89 67.58,-103.28&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;68.52,-106.66 77.64,-101.27 67.15,-99.8 68.52,-106.66&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-108.3C27,-116.02 27,-125.29 27,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-133.9 27,-143.9 30.5,-133.9 23.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;h1 --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;h1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M77.64,-78.73C71.24,-76.78 64.84,-76.11 58.44,-76.72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;57.49,-73.34 48.38,-78.73 58.87,-80.2 57.49,-73.34&quot; /&gt;
&lt;/g&gt;
&lt;!-- hddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M120.38,-101.27C126.78,-103.22 133.18,-103.89 139.58,-103.28&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;140.52,-106.66 149.64,-101.27 139.15,-99.8 140.52,-106.66&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-108.3C99,-116.02 99,-125.29 99,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-133.9 99,-143.9 102.5,-133.9 95.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M149.64,-78.73C143.24,-76.78 136.84,-76.11 130.44,-76.72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;129.49,-73.34 120.38,-78.73 130.87,-80.2 129.49,-73.34&quot; /&gt;
&lt;/g&gt;
&lt;!-- hn --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;hn&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;243&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;hn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M192.38,-101.27C198.78,-103.22 205.18,-103.89 211.58,-103.28&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;212.52,-106.66 221.64,-101.27 211.15,-99.8 212.52,-106.66&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-108.3C171,-116.02 171,-125.29 171,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-133.9 171,-143.9 174.5,-133.9 167.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- hn&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hn&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M221.64,-78.73C215.24,-76.78 208.84,-76.11 202.44,-76.72&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;201.49,-73.34 192.38,-78.73 202.87,-80.2 201.49,-73.34&quot; /&gt;
&lt;/g&gt;
&lt;!-- yn --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;yn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- hn&amp;#45;&amp;gt;yn --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;hn&amp;#45;&amp;gt;yn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-108.3C243,-116.02 243,-125.29 243,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-133.9 243,-143.9 246.5,-133.9 239.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;hddd --&gt;
&lt;g id=&quot;edge13&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;hddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-36.3C171,-44.02 171,-53.29 171,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-61.9 171,-71.9 174.5,-61.9 167.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node10&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;h1 --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;h1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-36.3C27,-44.02 27,-53.29 27,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-61.9 27,-71.9 30.5,-61.9 23.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node11&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;h2 --&gt;
&lt;g id=&quot;edge12&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;h2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-36.3C99,-44.02 99,-53.29 99,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-61.9 99,-71.9 102.5,-61.9 95.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node12&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;hn --&gt;
&lt;g id=&quot;edge14&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;hn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-36.3C243,-44.02 243,-53.29 243,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-61.9 243,-71.9 246.5,-61.9 239.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;在 PyTorch 中使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.RNN&lt;/code&gt; 就有参数表示双向：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bidirectional&lt;/code&gt; – If True, becomes a bidirectional RNN. Default: False&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bidirectional&lt;/code&gt;：默认设置为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;False&lt;/code&gt;。若为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;True&lt;/code&gt;，即为双向 RNN。&lt;/p&gt;

&lt;h3 id=&quot;6堆叠循环神经网络堆叠-lstm&quot;&gt;6、堆叠循环神经网络、堆叠 LSTM&lt;/h3&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-79478ee70f94925103b38a21c70c2539&quot; width=&quot;288pt&quot; height=&quot;260pt&quot; viewBox=&quot;0.00 0.00 288.19 260.00&quot;&gt;
&lt;title&gt;graphviz-79478ee70f94925103b38a21c70c2539&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same h11 h12 h1ddd h1n}
	{rank=same h21 h22 h2ddd h2n}

	h1ddd[label=&amp;quot;...&amp;quot;]
	h2ddd[label=&amp;quot;...&amp;quot;]
	xddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]

	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	yn[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]

	h11 -&amp;gt; y1
	h12 -&amp;gt; y2
	h1ddd -&amp;gt; yddd
	h1n -&amp;gt; yn

	h11 -&amp;gt; h12
	h12 -&amp;gt; h1ddd
	h1ddd -&amp;gt; h1n

	h21 -&amp;gt; h22
	h22 -&amp;gt; h2ddd
	h2ddd -&amp;gt; h2n

	h21 -&amp;gt; h11
	h22 -&amp;gt; h12
	h2ddd -&amp;gt; h1ddd
	h2n -&amp;gt; h1n

	x1 -&amp;gt; h21
	x2 -&amp;gt; h22
	xddd -&amp;gt; h2ddd
	xn -&amp;gt; h2n
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 256)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-256 284.19,-256 284.19,4 -4,4&quot; /&gt;
&lt;!-- h11 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h11&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;28.6&quot; cy=&quot;-162&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;28.6&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h11&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h12 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h12&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;103.6&quot; cy=&quot;-162&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;103.6&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h12&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h11&amp;#45;&amp;gt;h12 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h11&amp;#45;&amp;gt;h12&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M57.31,-162C59.75,-162 62.19,-162 64.63,-162&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;64.67,-165.5 74.67,-162 64.67,-158.5 64.67,-165.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node11&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;28.6&quot; y=&quot;-230.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h11&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h11&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M28.6,-180.3C28.6,-188.02 28.6,-197.29 28.6,-205.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;25.1,-205.9 28.6,-215.9 32.1,-205.9 25.1,-205.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h1ddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1ddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;177.6&quot; cy=&quot;-162&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;177.6&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h12&amp;#45;&amp;gt;h1ddd --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h12&amp;#45;&amp;gt;h1ddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M132.21,-162C134.85,-162 137.49,-162 140.13,-162&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;140.3,-165.5 150.3,-162 140.3,-158.5 140.3,-165.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node12&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;103.6&quot; y=&quot;-230.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h12&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h12&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M103.6,-180.3C103.6,-188.02 103.6,-197.29 103.6,-205.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;100.1,-205.9 103.6,-215.9 107.1,-205.9 100.1,-205.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h1n --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h1n&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;251.6&quot; cy=&quot;-162&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;251.6&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h1n&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1ddd&amp;#45;&amp;gt;h1n --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1ddd&amp;#45;&amp;gt;h1n&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M204.77,-162C207.38,-162 210,-162 212.61,-162&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;212.7,-165.5 222.7,-162 212.7,-158.5 212.7,-165.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node10&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;177.6&quot; y=&quot;-230.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1ddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1ddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M177.6,-180.3C177.6,-188.02 177.6,-197.29 177.6,-205.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;174.1,-205.9 177.6,-215.9 181.1,-205.9 174.1,-205.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- yn --&gt;
&lt;g id=&quot;node13&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;251.6&quot; y=&quot;-230.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;yn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h1n&amp;#45;&amp;gt;yn --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h1n&amp;#45;&amp;gt;yn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M251.6,-180.3C251.6,-188.02 251.6,-197.29 251.6,-205.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;248.1,-205.9 251.6,-215.9 255.1,-205.9 248.1,-205.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h21 --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h21&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;28.6&quot; cy=&quot;-90&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;28.6&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h21&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h21&amp;#45;&amp;gt;h11 --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h21&amp;#45;&amp;gt;h11&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M28.6,-108.3C28.6,-116.02 28.6,-125.29 28.6,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;25.1,-133.9 28.6,-143.9 32.1,-133.9 25.1,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h22 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h22&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;103.6&quot; cy=&quot;-90&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;103.6&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h22&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h21&amp;#45;&amp;gt;h22 --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h21&amp;#45;&amp;gt;h22&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M57.31,-90C59.75,-90 62.19,-90 64.63,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;64.67,-93.5 74.67,-90 64.67,-86.5 64.67,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- h22&amp;#45;&amp;gt;h12 --&gt;
&lt;g id=&quot;edge12&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h22&amp;#45;&amp;gt;h12&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M103.6,-108.3C103.6,-116.02 103.6,-125.29 103.6,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;100.1,-133.9 103.6,-143.9 107.1,-133.9 100.1,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h2ddd --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2ddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;177.6&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;177.6&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h22&amp;#45;&amp;gt;h2ddd --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h22&amp;#45;&amp;gt;h2ddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M132.21,-90C134.85,-90 137.49,-90 140.13,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;140.3,-93.5 150.3,-90 140.3,-86.5 140.3,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- h2ddd&amp;#45;&amp;gt;h1ddd --&gt;
&lt;g id=&quot;edge13&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2ddd&amp;#45;&amp;gt;h1ddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M177.6,-108.3C177.6,-116.02 177.6,-125.29 177.6,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;174.1,-133.9 177.6,-143.9 181.1,-133.9 174.1,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- h2n --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h2n&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;251.6&quot; cy=&quot;-90&quot; rx=&quot;28.7&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;251.6&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h2n&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h2ddd&amp;#45;&amp;gt;h2n --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2ddd&amp;#45;&amp;gt;h2n&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M204.77,-90C207.38,-90 210,-90 212.61,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;212.7,-93.5 222.7,-90 212.7,-86.5 212.7,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- h2n&amp;#45;&amp;gt;h1n --&gt;
&lt;g id=&quot;edge14&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h2n&amp;#45;&amp;gt;h1n&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M251.6,-108.3C251.6,-116.02 251.6,-125.29 251.6,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;248.1,-133.9 251.6,-143.9 255.1,-133.9 248.1,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;177.6&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;h2ddd --&gt;
&lt;g id=&quot;edge17&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;h2ddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M177.6,-36.3C177.6,-44.02 177.6,-53.29 177.6,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;174.1,-61.9 177.6,-71.9 181.1,-61.9 174.1,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node14&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;28.6&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;h21 --&gt;
&lt;g id=&quot;edge15&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;h21&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M28.6,-36.3C28.6,-44.02 28.6,-53.29 28.6,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;25.1,-61.9 28.6,-71.9 32.1,-61.9 25.1,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node15&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;103.6&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;h22 --&gt;
&lt;g id=&quot;edge16&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;h22&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M103.6,-36.3C103.6,-44.02 103.6,-53.29 103.6,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;100.1,-61.9 103.6,-71.9 107.1,-61.9 100.1,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node16&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;251.6&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;h2n --&gt;
&lt;g id=&quot;edge18&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;h2n&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M251.6,-36.3C251.6,-44.02 251.6,-53.29 251.6,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;248.1,-61.9 251.6,-71.9 255.1,-61.9 248.1,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;在 PyTorch 中使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.RNN&lt;/code&gt; 就有参数表示双向：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;num_layers – Number of recurrent layers. E.g., setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_layers&lt;/code&gt;：隐藏层层数，默认设置为 1 层。当 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_layers&lt;/code&gt; &amp;gt;= 2 时，就是一个 stacked RNN 了。&lt;/p&gt;

&lt;h3 id=&quot;7n-vs-m-的-rnn&quot;&gt;7、N vs. M 的 RNN&lt;/h3&gt;

&lt;p&gt;对于输入序列长度（长度 N）和输出序列长度（长度 M）不一样的 RNN 模型结构，也可以叫做 Encoder-Decoder 模型，也可以叫 Seq2Seq 模型。首先接收输入序列的 Encoder 先将输入序列转成一个隐藏态的上下文表示 C。C 可以只与最后一个隐藏层有关，甚至可以是最后一个隐藏层生成的隐藏态直接设置为 C，C 还可以与所有隐藏层有关。&lt;/p&gt;

&lt;p&gt;有了这个 C 之后，再用 Decoder 进行解码，也就是从把 C 作为输入状态开始，生成输出序列。&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-094de5e41d0af67d4c5617e0f04d7b57&quot; width=&quot;638pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 638.00 188.00&quot;&gt;
&lt;title&gt;graphviz-094de5e41d0af67d4c5617e0f04d7b57&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=BT
	{rank=same e1 e2 eddd en C d1 d2 dddd dm}

	eddd[label=&amp;quot;...&amp;quot;]
	dddd[label=&amp;quot;...&amp;quot;]
	xddd[label=&amp;quot;...&amp;quot;]
	yddd[label=&amp;quot;...&amp;quot;]
	C[shape=plaintext]
	x1[shape=plaintext]
	x2[shape=plaintext]
	xddd[shape=plaintext]
	xn[shape=plaintext]
	y1[shape=plaintext]
	y2[shape=plaintext]
	yddd[shape=plaintext]
	yn[shape=plaintext]

	x1 -&amp;gt; e1
	x2 -&amp;gt; e2
	xddd -&amp;gt; eddd
	xn -&amp;gt; en

	e1 -&amp;gt; e2
	e2 -&amp;gt; eddd
	eddd -&amp;gt; en

	en -&amp;gt; C
	C -&amp;gt; d1

	d1 -&amp;gt; y1
	d2 -&amp;gt; y2
	dddd -&amp;gt; yddd
	dm -&amp;gt; yn

	d1 -&amp;gt; d2
	d2 -&amp;gt; dddd
	dddd -&amp;gt; dm
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 634,-184 634,4 -4,4&quot; /&gt;
&lt;!-- e1 --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;e1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;e1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e2 --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;e2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;99&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;e2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e1&amp;#45;&amp;gt;e2 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e1&amp;#45;&amp;gt;e2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M54,-90C56.61,-90 59.23,-90 61.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;61.93,-93.5 71.93,-90 61.93,-86.5 61.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- eddd --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;eddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;171&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- e2&amp;#45;&amp;gt;eddd --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;e2&amp;#45;&amp;gt;eddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M126,-90C128.61,-90 131.23,-90 133.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;133.93,-93.5 143.93,-90 133.93,-86.5 133.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- en --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;en&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;243&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;en&lt;/text&gt;
&lt;/g&gt;
&lt;!-- eddd&amp;#45;&amp;gt;en --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;eddd&amp;#45;&amp;gt;en&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M198,-90C200.61,-90 203.23,-90 205.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;205.93,-93.5 215.93,-90 205.93,-86.5 205.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- C --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;C&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;315&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;C&lt;/text&gt;
&lt;/g&gt;
&lt;!-- en&amp;#45;&amp;gt;C --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;en&amp;#45;&amp;gt;C&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M270,-90C272.61,-90 275.23,-90 277.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;277.93,-93.5 287.93,-90 277.93,-86.5 277.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- d1 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;d1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;387&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;387&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- C&amp;#45;&amp;gt;d1 --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;C&amp;#45;&amp;gt;d1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M342.28,-90C344.74,-90 347.19,-90 349.65,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;349.75,-93.5 359.75,-90 349.75,-86.5 349.75,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- d2 --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;d2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;459&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;459&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;d2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d1&amp;#45;&amp;gt;d2 --&gt;
&lt;g id=&quot;edge14&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d1&amp;#45;&amp;gt;d2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M414,-90C416.61,-90 419.23,-90 421.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;421.93,-93.5 431.93,-90 421.93,-86.5 421.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y1 --&gt;
&lt;g id=&quot;node15&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;387&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d1&amp;#45;&amp;gt;y1 --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d1&amp;#45;&amp;gt;y1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M387,-108.3C387,-116.02 387,-125.29 387,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;383.5,-133.9 387,-143.9 390.5,-133.9 383.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- dddd --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dddd&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;531&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;531&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d2&amp;#45;&amp;gt;dddd --&gt;
&lt;g id=&quot;edge15&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d2&amp;#45;&amp;gt;dddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M486,-90C488.61,-90 491.23,-90 493.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;493.93,-93.5 503.93,-90 493.93,-86.5 493.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- y2 --&gt;
&lt;g id=&quot;node16&quot; class=&quot;node&quot;&gt;
&lt;title&gt;y2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;459&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;y2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- d2&amp;#45;&amp;gt;y2 --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;d2&amp;#45;&amp;gt;y2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M459,-108.3C459,-116.02 459,-125.29 459,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;455.5,-133.9 459,-143.9 462.5,-133.9 455.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- dm --&gt;
&lt;g id=&quot;node9&quot; class=&quot;node&quot;&gt;
&lt;title&gt;dm&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;603&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;603&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;dm&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dddd&amp;#45;&amp;gt;dm --&gt;
&lt;g id=&quot;edge16&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dddd&amp;#45;&amp;gt;dm&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M558,-90C560.61,-90 563.23,-90 565.84,-90&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;565.93,-93.5 575.93,-90 565.93,-86.5 565.93,-93.5&quot; /&gt;
&lt;/g&gt;
&lt;!-- yddd --&gt;
&lt;g id=&quot;node11&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;531&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dddd&amp;#45;&amp;gt;yddd --&gt;
&lt;g id=&quot;edge12&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dddd&amp;#45;&amp;gt;yddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M531,-108.3C531,-116.02 531,-125.29 531,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;527.5,-133.9 531,-143.9 534.5,-133.9 527.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- yn --&gt;
&lt;g id=&quot;node17&quot; class=&quot;node&quot;&gt;
&lt;title&gt;yn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;603&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;yn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- dm&amp;#45;&amp;gt;yn --&gt;
&lt;g id=&quot;edge13&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;dm&amp;#45;&amp;gt;yn&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M603,-108.3C603,-116.02 603,-125.29 603,-133.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;599.5,-133.9 603,-143.9 606.5,-133.9 599.5,-133.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xddd --&gt;
&lt;g id=&quot;node10&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xddd&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;171&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xddd&amp;#45;&amp;gt;eddd --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xddd&amp;#45;&amp;gt;eddd&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M171,-36.3C171,-44.02 171,-53.29 171,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;167.5,-61.9 171,-71.9 174.5,-61.9 167.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x1 --&gt;
&lt;g id=&quot;node12&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x1&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x1&amp;#45;&amp;gt;e1 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x1&amp;#45;&amp;gt;e1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M27,-36.3C27,-44.02 27,-53.29 27,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;23.5,-61.9 27,-71.9 30.5,-61.9 23.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- x2 --&gt;
&lt;g id=&quot;node13&quot; class=&quot;node&quot;&gt;
&lt;title&gt;x2&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;99&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;x2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- x2&amp;#45;&amp;gt;e2 --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;x2&amp;#45;&amp;gt;e2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M99,-36.3C99,-44.02 99,-53.29 99,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;95.5,-61.9 99,-71.9 102.5,-61.9 95.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;!-- xn --&gt;
&lt;g id=&quot;node14&quot; class=&quot;node&quot;&gt;
&lt;title&gt;xn&lt;/title&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;243&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;xn&lt;/text&gt;
&lt;/g&gt;
&lt;!-- xn&amp;#45;&amp;gt;en --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;xn&amp;#45;&amp;gt;en&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M243,-36.3C243,-44.02 243,-53.29 243,-61.89&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;239.5,-61.9 243,-71.9 246.5,-61.9 239.5,-61.9&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;具体地，可以如下表示：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bm{C} = Encoder(\bm{X}) \\
&amp;amp;\bm{Y} = Decoder(\bm{C}) \\
\end{aligned}\]

&lt;p&gt;进一步展开：&lt;/p&gt;

\[\begin{aligned}
e_t &amp;amp;= Encoder_{LSTM/GRU}(x_t, e_{t-1}) \\
\bm{C} &amp;amp;= f_1(e_n) \\
d_t &amp;amp;= f_2(d_{t-1}, \bm{C}) \\
y_t &amp;amp;= Decoder_{LSTM/GRU}(y_{t-1}, d_{t-1}, \bm{C})
\end{aligned}\]

&lt;p&gt;这种的应用就非常广了，因为大多数时候输入序列与输出序列的长度都是不同的，比如最常见的应用「翻译」，从一个语言翻译成另一个语言；再比如 AI 的一个领域「语音识别」，将语音序列输入后生成所识别的文本内容；还有比如 ChatGPT 这种问答应用等等。&lt;/p&gt;

&lt;p&gt;Seq2Seq 模型非常出色，一直到 2018 年之前 NLP 领域里该模型已成为主流。但是它有很显著的问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当输入序列很长时，Encoder 生成的 Context 可能就会出现所捕捉的信息不充分的情况，导致 Decoder 最终的输出是不尽如人意的。具体地，毕竟还是 RNN 模型，其词间距过长时还是会有梯度消失问题，根本原因在于用到了「递归」。当递归作用在同一个 weight matrix 上时，使得如果这个矩阵满足条件的话，其最大的特征值要是小于 1 的话，就一定出现梯度消失问题。后来的 LSTM 和 GRU 也仅仅能缓解问题，并不能根本解决。&lt;/li&gt;
  &lt;li&gt;并行效果差：每个时刻的结果依赖前一时刻。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;《自然语言处理：基于预训练模型的方法》车万翔 等&lt;/li&gt;
  &lt;li&gt;《自然语言处理实战：预训练模型应用及其产品化》安库·A·帕特尔 等&lt;/li&gt;
  &lt;li&gt;https://www.cnblogs.com/engpj/p/16906911.html&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="AI" /><category term="人工智能" /><category term="RNN" /><category term="循环神经网络" /><category term="LSTM" /><category term="NLP" /><category term="自然语言处理" /><category term="Encoder-Decoder" /><category term="解码器" /><category term="编码器" /><category term="神经网络" /><category term="深度学习" /><summary type="html">如果您喜欢机器学习，那么您一定会喜欢这篇文章。在这篇文章中，我们将深入探讨 RNN（循环神经网络），这是一种强大的神经网络模型，能够预测序列数据，例如文本、语音和时间序列。我们将通过生动的代码示例和实际案例来演示如何使用 RNN，并在日常生活中真实地体验它的功能。您将学习到如何使用 RNN 解决各种机器学习问题，并动手尝试运用 RNN 解决实际问题。这篇文章将为您提供一个完整的 RNN 入门指南，并使您对 RNN 有更深入的了解。</summary></entry><entry><title type="html">麦克船长 NLP 语言模型技术笔记 2：多层感知器（MLP）</title><link href="https://www.mikecaptain.com/2022/12/30/language-model-2/" rel="alternate" type="text/html" title="麦克船长 NLP 语言模型技术笔记 2：多层感知器（MLP）" /><published>2022-12-30T19:44:09+00:00</published><updated>2022-12-30T19:44:09+00:00</updated><id>https://www.mikecaptain.com/2022/12/30/language-model-2</id><content type="html" xml:base="https://www.mikecaptain.com/2022/12/30/language-model-2/">&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#1感知器perceptron解决二元分类任务的前馈神经网络&quot; id=&quot;markdown-toc-1感知器perceptron解决二元分类任务的前馈神经网络&quot;&gt;1、感知器（Perceptron）：解决二元分类任务的前馈神经网络&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2线性回归linear-regression从离散值的感知器解决类问题到连续值的线性回归解决回归问题&quot; id=&quot;markdown-toc-2线性回归linear-regression从离散值的感知器解决类问题到连续值的线性回归解决回归问题&quot;&gt;2、线性回归（Linear Regression）：从离散值的感知器（解决类问题），到连续值的线性回归（解决回归问题）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3逻辑回归logistic-regression没有值域约束的线性回归到限定在一个范围内的逻辑回归常用于分类问题&quot; id=&quot;markdown-toc-3逻辑回归logistic-regression没有值域约束的线性回归到限定在一个范围内的逻辑回归常用于分类问题&quot;&gt;3、逻辑回归（Logistic Regression）：没有值域约束的线性回归，到限定在一个范围内的逻辑回归（常用于分类问题）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4sigmoid-回归sigmoid-regression归一化的逻辑回归一般用于二元分类任务&quot; id=&quot;markdown-toc-4sigmoid-回归sigmoid-regression归一化的逻辑回归一般用于二元分类任务&quot;&gt;4、Sigmoid 回归（Sigmoid Regression）：归一化的逻辑回归，一般用于二元分类任务&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5softmax-回归softmax-regression从解决二元任务的-sigmoid到解决多元分类任务的-softmax&quot; id=&quot;markdown-toc-5softmax-回归softmax-regression从解决二元任务的-sigmoid到解决多元分类任务的-softmax&quot;&gt;5、Softmax 回归（Softmax Regression）：从解决二元任务的 sigmoid，到解决多元分类任务的 Softmax&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6多层感知器multi-layer-perceptron&quot; id=&quot;markdown-toc-6多层感知器multi-layer-perceptron&quot;&gt;6、多层感知器（Multi-Layer Perceptron）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7mlp-的一个显著问题帮我们引出-cnn-模型&quot; id=&quot;markdown-toc-7mlp-的一个显著问题帮我们引出-cnn-模型&quot;&gt;7、MLP 的一个显著问题，帮我们引出 CNN 模型&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文关键词：感知器、线性回归、逻辑回归、激活函数、Sigmoid 函数/归一化/回归、Softmax 回归。&lt;/p&gt;

&lt;p&gt;1957 年感知机（Perceptron）模型被提出，1959 年多层感知机（MLP）模型被提出。MLP 有时候也被称为 ANN，即 Artificial Neural Network，接下来我们来深入浅出地了解一下，并有一些动手的练习。&lt;/p&gt;

&lt;h3 id=&quot;1感知器perceptron解决二元分类任务的前馈神经网络&quot;&gt;1、感知器（Perceptron）：解决二元分类任务的前馈神经网络&lt;/h3&gt;

&lt;p&gt;\(x\) 是一个输入向量，\(\omega\) 是一个权重向量（对输入向量里的而每个值分配一个权重值所组成的向量）。举一个具体任务例子，比如如果这两个响亮的内积超过某个值，则判断为 1，否则为 0，这其实就是一个分类任务。那么这个最终输出值可以如下表示：&lt;/p&gt;

\[y = \begin{cases} 1 &amp;amp; (\omega \cdot x \geq 0) \\ 0 &amp;amp; (\omega \cdot x \lt 0) \end{cases}\]

&lt;p&gt;这就是一个典型的感知器（Perceptron，一般用来解决分类问题。还可以再增加一个偏差项（bias），如下：&lt;/p&gt;

\[y = \begin{cases} 1 &amp;amp; (\omega \cdot x + b \geq 0) \\ 0 &amp;amp; (\omega \cdot x + b \lt 0) \end{cases}\]

&lt;p&gt;感知器其实就是一个前馈神经网络，由输入层、输出层组成，没有隐藏层。而且输出是一个二元函数，用于解决二元分类问题。&lt;/p&gt;

&lt;h3 id=&quot;2线性回归linear-regression从离散值的感知器解决类问题到连续值的线性回归解决回归问题&quot;&gt;2、线性回归（Linear Regression）：从离散值的感知器（解决类问题），到连续值的线性回归（解决回归问题）&lt;/h3&gt;

&lt;p&gt;一般来说，我们认为感知器的输出结果，是离散值。一般来说，我们认为离散值作为输出解决的问题，是分类问题；相应地，连续值解决的问题是回归（Regression）。比如对于上面的感知器，如果我们直接将 \(\omega \cdot x + b\) 作为输出值，则就变成了一个线性回归问题的模型了。&lt;/p&gt;

&lt;p&gt;下面我们用 PyTorch 来实现一个线性回归的代码示例，首先我们要了解在 PyTorch 库里有一个非常常用的函数：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这个函数在创建时会自动初始化权值和偏置，并且可以通过调用它的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward&lt;/code&gt; 函数来计算输入数据的线性变换。具体来说，当输入为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; 时，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward&lt;/code&gt; 函数会计算 \(y = \omega \cdot x + b\)，其中  \(W\)  和  \(b\)  分别是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.Linear&lt;/code&gt; 图层的权值和偏置。&lt;/p&gt;

&lt;p&gt;我们来一个完整的代码示例：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义模型
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 初始化模型
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义损失函数和优化器
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 创建输入特征 X 和标签 y
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 训练模型
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 前向传播
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 反向传播
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 创建测试数据 X_test 和标签 y_test
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 测试模型
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Test loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上述代码，一开始先创建一个 LinearRegression 线性回归模型的类，其中有一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward&lt;/code&gt; 前向传播函数，调用时其实就是计算一下输出值 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;主程序，一开始创建一个线性回归模型实例，然后定义一个用于评价模型效果的损失函数评价器，和用随机梯度下降（Stochastic Gradient Descent）作为优化器。&lt;/p&gt;

&lt;p&gt;然后创建一个输入特征张量，和标签张量。用这组特征和标签进行训练，训练的过程就是根据 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt; 计算与测试 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predictions&lt;/code&gt; 向量，再把它和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt; 一起给评价器算出损失 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss&lt;/code&gt;，然后进行反向传播。注意反向传播的三行代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如此训练 100 次（每一次都会黑盒化地更新模型的参数，一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;epoch&lt;/code&gt; 就是一次训练过程，有时也称为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;iteration&lt;/code&gt; 或者 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;step&lt;/code&gt;，不断根据 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss&lt;/code&gt; 训练优化模型参数。&lt;/p&gt;

&lt;p&gt;然后我们创建了一组测试特征值张量 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X_test&lt;/code&gt;，和测试标签张量 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_test&lt;/code&gt;，然后用它们测试模型性能，把测试特征得到的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;predictions&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_test&lt;/code&gt; 共同传给评价器，得到 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss&lt;/code&gt;。在这个例子中我们会得到如下结果：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Test&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0034&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3逻辑回归logistic-regression没有值域约束的线性回归到限定在一个范围内的逻辑回归常用于分类问题&quot;&gt;3、逻辑回归（Logistic Regression）：没有值域约束的线性回归，到限定在一个范围内的逻辑回归（常用于分类问题）&lt;/h3&gt;

&lt;p&gt;可以看到线性回归问题，输出值是没有范围限定的。如果限定（limit）在特定的  \((0, L)\)  范围内，则就叫做逻辑回归了。那么如何将一个线性回归变成逻辑回归呢？一般通过如下公式变换：&lt;/p&gt;

\[y = \frac{L}{1 + e^{-k(z-z_0)}}\]

&lt;p&gt;这样原来的  \(z \in (-\infty, +\infty)\)  就被变换成了  \(y \in (0, L)\)  了。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;激活函数&lt;/strong&gt;：这种把输出值限定在一个目标范围内的函数，被叫做 &lt;strong&gt;激活函数（Activation Function）&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;函数的陡峭程度&lt;/strong&gt; 由  \(k\)  控制，越大越陡。&lt;/li&gt;
  &lt;li&gt;当  \(z = z_0\)  时， \(y = \frac{L}{2}\) 。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面给出一个基于 Python 的 scikit-learn 库的示例代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.linear_model&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;这是&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scikit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;库里的一个简单的数据集&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;把&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;数据集拆分成训练集和测试集两部分&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;用&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scikit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;库创建一个逻辑回归模型的实例&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LogisticRegression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;用上边&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;出来的训练集数据&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;训练&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;模型实例&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;用训练过的模型&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;拿测试集的输入数据做测试&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;用测试集的数据验证精确性&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4sigmoid-回归sigmoid-regression归一化的逻辑回归一般用于二元分类任务&quot;&gt;4、Sigmoid 回归（Sigmoid Regression）：归一化的逻辑回归，一般用于二元分类任务&lt;/h3&gt;

&lt;p&gt;当  \(L = 1, k = 1, z_0 = 0\) ，此时的激活函数就是 &lt;strong&gt;Sigmoid&lt;/strong&gt; 函数，也常表示为  \(\sigma\)  函数，如下：&lt;/p&gt;

\[y = \frac{1}{1 + e^{-z}}\]

&lt;p&gt;Sigmoid 回归的值域，恰好在 (0, 1) 之间，所以常备作为用来归一化的激活函数。而一个线性回归模型，再用 sigmoid 函数归一化，这种也常被称为「Sigmoid 回归」。Sigmoid 这个单词的意思也就是 S 形，我们可以看下它的函数图像如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-19-language-model-2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因为归一化，所以也可以把输出值理解为一个概率。比如我们面对一个二元分类问题，那么输出结果就对应属于这个类别的概率。&lt;/p&gt;

&lt;p&gt;这样一个 sigmoid 模型可以表示为：&lt;/p&gt;

\[\bold{y} = Sigmoid(\bold{W} \cdot \bold{x} + \bold{b})\]

&lt;p&gt;另外 sigmoid 函数的导数（即梯度）是很好算的： \(y&apos; = y \cdot (1-y)\) 。这非常方便用于「梯度下降算法」根据 loss 对模型参数进行优化。Sigmoid 回归，一般用于二元分类任务。那么对于超过二元的情况怎么办呢？这就引出了下面的 Softmax 回归。&lt;/p&gt;

&lt;h3 id=&quot;5softmax-回归softmax-regression从解决二元任务的-sigmoid到解决多元分类任务的-softmax&quot;&gt;5、Softmax 回归（Softmax Regression）：从解决二元任务的 sigmoid，到解决多元分类任务的 Softmax&lt;/h3&gt;

&lt;p&gt;相对逻辑回归，Softmax 也称为多项逻辑回归。上面说 Sigmoid 一般用于解决二元分类问题，那么多元问题就要用 Softmax 回归了。我们来拿一个具体问题来解释，比如问题是对于任意输入的一个电商商品的图片，来判断这个图片所代表的的商品，属于哪个商品类目。假设我们一共有 100 个类目。那么一个图片比如说其所有像素值作为输入特征值，输出就是一个 100 维的向量 ** \(z\) **，输出向量中的每个值  \(z_i\)  表示属于相对应类目的概率  \(y_i\)  ：&lt;/p&gt;

\[y_i = Softmax(\bold{z})_i = \frac{e^{z_i}}{e^{z_1} + e^{z_2} + ... + e^{z_100}}\]

&lt;p&gt;那么最后得到的  \(y\)  向量中的每一项就对应这个输入  \(z\)  属于这 100 个类目的各自概率了。所以如果回归到一般问题，这个 Softmax 回归的模型就如下：&lt;/p&gt;

\[\bold{y} = Softmax(\bold{W} \cdot \bold{x} + \bold{b})\]

&lt;p&gt;对于上面电商商品图片的例子，假设每个图片的尺寸是 512x512，这个模型展开式如下：&lt;/p&gt;

\[\begin{bmatrix} y_1 \\ y_2 \\ ... \\ y_{100} \end{bmatrix} = Softmax(\begin{bmatrix} w_{1,1}, &amp;amp; w_{1,2}, &amp;amp; ... &amp;amp; w_{1, 512} \\ w_{2,1}, &amp;amp; w_{2,2}, &amp;amp; ... &amp;amp; w_{2, 512} \\ ... &amp;amp; ... &amp;amp; ... &amp;amp; ... \\ w_{100,1}, &amp;amp; w_{100,2}, &amp;amp; ... &amp;amp; w_{100, 512} \end{bmatrix} \cdot \begin{bmatrix} x_1 \\ x_2 \\ ... \\ x_{512} \end{bmatrix} + \begin{bmatrix} b_1 \\ b_2 \\ ... \\ b_{512} \end{bmatrix})\]

&lt;p&gt;这个对输入向量  \(x\)  执行  \(w \cdot x + b\)  运算，一般也常称为「线性映射/线性变化」。&lt;/p&gt;

&lt;h3 id=&quot;6多层感知器multi-layer-perceptron&quot;&gt;6、多层感知器（Multi-Layer Perceptron）&lt;/h3&gt;

&lt;p&gt;上面我们遇到的所有任务，都是用线性模型（Linear Models）解决的。有时候问题复杂起来，我们就要引入非线性模型了。&lt;/p&gt;

&lt;p&gt;这里我们要介绍一个新的激活函数 —— ReLU（Rectified Linear Unit）—— 一个非线性激活函数，其定义如下：&lt;/p&gt;

\[ReLU(\bold{z}) = max(0, \bold{z})\]

&lt;p&gt;比如对于 MNIST 数据集的手写数字分类问题，就是一个典型的非线性的分类任务，下面给出一个示例代码：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义多层感知器模型
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MLP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 超参数
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 加载 MNIST 数据集
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;../../data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                               &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;../../data&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 数据加载器
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                           &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                           &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                          &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                          &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义损失函数和优化器
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 训练模型
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 前向传播
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 反向传播
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 输出训练损失
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Training Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这段代码里，我们能看到 MLP 的模型定义是：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;与前面的模型示例代码类似，也都用到了反向传播、损失函数评价器、优化器。如果用公式表示的话，就是如下的模型定义：&lt;/p&gt;

\[\begin{aligned}
&amp;amp;\bold{z} = \bold{W}_1 \cdot \bold{x} + \bold{b}_1 \\
&amp;amp;\bold{h} = ReLU(\bold{z}) \\
&amp;amp;\bold{y} = \bold{W}_2 \cdot \bold{h} + \bold{b}_2
\end{aligned}\]

&lt;p&gt;我们知道 MLP 通常是一个输入和输出长度相同的模型，但少数情况下也可以构建输入和输出长度不同的 MLP 模型，比如输入一组序列后，输出是一个离散的分类结果。&lt;/p&gt;

&lt;h3 id=&quot;7mlp-的一个显著问题帮我们引出-cnn-模型&quot;&gt;7、MLP 的一个显著问题，帮我们引出 CNN 模型&lt;/h3&gt;

&lt;p&gt;我们可以看到，在 MLP 中，不论有多少层，某一层的输出向量  \(h_n\)  中的每个值，都会在下一层计算输出向量  \(h_{n+1}\)  的每个值时用到。具体来说，如果对于某一层的输出值如下：&lt;/p&gt;

\[\bold{h}_{n+1} = Softmax(\bold{W}_{n+1} \cdot \bold{h}_n + \bold{b}_{n+1})\]

&lt;p&gt;上一段话里所谓的「用到」，其实就是要针对  \(h_n\)  生成相应的特征值  \(W_{n+1}\)  权重矩阵中的每个行列里的数值和  \(b_{n+1}\) 偏差向量 里的每个值。如果用图画出来，就是：&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;graphviz-1b1299448dc08c90d29bebf8b1f045c1&quot; width=&quot;428pt&quot; height=&quot;116pt&quot; viewBox=&quot;0.00 0.00 427.64 116.00&quot;&gt;
&lt;title&gt;graphviz-1b1299448dc08c90d29bebf8b1f045c1&lt;/title&gt;
&lt;desc&gt;
digraph G {
	rankdir=TB
	a[label=&amp;quot;...&amp;quot;]
	b[label=&amp;quot;...&amp;quot;]
	h_2_1[label=&amp;quot;h_n+1_1&amp;quot;]
	h_2_2[label=&amp;quot;h_n+1_2&amp;quot;]
	h_2_m[label=&amp;quot;h_n+1_m&amp;quot;]

	{rank=same h_n_1 h_n_2 b h_n_m}
	{rank=same h_2_1 h_2_2 a h_2_m}

	h_n_1 -&amp;gt; h_2_1
	h_n_1 -&amp;gt; h_2_2
	h_n_1 -&amp;gt; a
	h_n_1 -&amp;gt; h_2_m

	h_n_1 -&amp;gt; h_2_1
	h_n_2 -&amp;gt; h_2_2
	h_n_2 -&amp;gt; a
	h_n_2 -&amp;gt; h_2_m

	b -&amp;gt; h_2_1
	b -&amp;gt; h_2_2
	b -&amp;gt; a
	b -&amp;gt; h_2_m

	h_n_m -&amp;gt; h_2_1
	h_n_m -&amp;gt; h_2_2
	h_n_m -&amp;gt; a
	h_n_m -&amp;gt; h_2_m
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 112)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-112 423.64,-112 423.64,4 -4,4&quot; /&gt;
&lt;!-- a --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;a&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;146.7&quot; cy=&quot;-18&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;146.7&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;b&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;151.7&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;151.7&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;...&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b&amp;#45;&amp;gt;a --&gt;
&lt;g id=&quot;edge11&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;b&amp;#45;&amp;gt;a&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M150.46,-71.7C149.91,-63.98 149.25,-54.71 148.63,-46.11&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;152.12,-45.83 147.92,-36.1 145.14,-46.33 152.12,-45.83&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_2_1 --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_2_1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;50.7&quot; cy=&quot;-18&quot; rx=&quot;50.89&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;50.7&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n+1_1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b&amp;#45;&amp;gt;h_2_1 --&gt;
&lt;g id=&quot;edge9&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;b&amp;#45;&amp;gt;h_2_1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M133.64,-76.49C119.14,-66.44 98.46,-52.11 81.38,-40.27&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;83.04,-37.16 72.83,-34.34 79.05,-42.91 83.04,-37.16&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_2_2 --&gt;
&lt;g id=&quot;node4&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_2_2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;242.7&quot; cy=&quot;-18&quot; rx=&quot;50.89&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;242.7&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n+1_2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b&amp;#45;&amp;gt;h_2_2 --&gt;
&lt;g id=&quot;edge10&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;b&amp;#45;&amp;gt;h_2_2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M168.81,-75.83C181.67,-65.94 199.56,-52.18 214.52,-40.67&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;216.69,-43.42 222.48,-34.55 212.42,-37.87 216.69,-43.42&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_2_m --&gt;
&lt;g id=&quot;node5&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_2_m&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;365.7&quot; cy=&quot;-18&quot; rx=&quot;53.89&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;365.7&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n+1_m&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b&amp;#45;&amp;gt;h_2_m --&gt;
&lt;g id=&quot;edge12&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;b&amp;#45;&amp;gt;h_2_m&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M172.78,-78.39C177.62,-76.14 182.79,-73.88 187.7,-72 211.14,-63.03 271.93,-45.36 315.95,-32.9&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;316.96,-36.25 325.63,-30.16 315.05,-29.51 316.96,-36.25&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_1 --&gt;
&lt;g id=&quot;node6&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_n_1&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;69.7&quot; cy=&quot;-90&quot; rx=&quot;37.09&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;69.7&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n_1&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h_n_1&amp;#45;&amp;gt;a --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_1&amp;#45;&amp;gt;a&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M86.4,-73.81C97.36,-63.85 111.83,-50.7 123.85,-39.77&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;126.28,-42.29 131.33,-32.97 121.57,-37.11 126.28,-42.29&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_1&amp;#45;&amp;gt;h_2_1 --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_1&amp;#45;&amp;gt;h_2_1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M59.35,-72.41C56.39,-64.62 53.56,-55.14 51.51,-46.33&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;54.92,-45.55 49.5,-36.45 48.06,-46.94 54.92,-45.55&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_1&amp;#45;&amp;gt;h_2_1 --&gt;
&lt;g id=&quot;edge5&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_1&amp;#45;&amp;gt;h_2_1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M70.91,-71.7C69.57,-63.7 67.15,-54.02 64.35,-45.15&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;67.63,-43.93 61.05,-35.62 61.01,-46.22 67.63,-43.93&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_1&amp;#45;&amp;gt;h_2_2 --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_1&amp;#45;&amp;gt;h_2_2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M97.49,-77.75C125.45,-66.44 168.9,-48.86 200.99,-35.87&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;202.6,-39 210.56,-32 199.97,-32.51 202.6,-39&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_1&amp;#45;&amp;gt;h_2_m --&gt;
&lt;g id=&quot;edge4&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_1&amp;#45;&amp;gt;h_2_m&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M97.68,-77.83C103.57,-75.71 109.79,-73.65 115.7,-72 197.22,-49.25 220.23,-55.04 302.7,-36 307.03,-35 311.53,-33.9 316.02,-32.77&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;317.01,-36.13 325.81,-30.24 315.26,-29.35 317.01,-36.13&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_2 --&gt;
&lt;g id=&quot;node7&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_n_2&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;331.7&quot; cy=&quot;-90&quot; rx=&quot;37.09&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;331.7&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n_2&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h_n_2&amp;#45;&amp;gt;a --&gt;
&lt;g id=&quot;edge7&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_2&amp;#45;&amp;gt;a&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M303.01,-78.31C297.28,-76.2 291.3,-74.02 285.7,-72 240.06,-55.59 227.57,-54.38 182.7,-36 180.87,-35.25 179.01,-34.46 177.14,-33.65&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;178.4,-30.38 167.85,-29.44 175.52,-36.75 178.4,-30.38&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_2&amp;#45;&amp;gt;h_2_2 --&gt;
&lt;g id=&quot;edge6&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_2&amp;#45;&amp;gt;h_2_2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M312.82,-74.15C300.65,-64.58 284.6,-51.96 270.93,-41.21&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;272.8,-38.23 262.78,-34.8 268.48,-43.73 272.8,-38.23&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_2&amp;#45;&amp;gt;h_2_m --&gt;
&lt;g id=&quot;edge8&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_2&amp;#45;&amp;gt;h_2_m&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M339.75,-72.41C343.72,-64.25 348.59,-54.22 353.04,-45.07&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;356.24,-46.48 357.46,-35.96 349.94,-43.42 356.24,-46.48&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_m --&gt;
&lt;g id=&quot;node8&quot; class=&quot;node&quot;&gt;
&lt;title&gt;h_n_m&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;236.7&quot; cy=&quot;-90&quot; rx=&quot;40.09&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;236.7&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;h_n_m&lt;/text&gt;
&lt;/g&gt;
&lt;!-- h_n_m&amp;#45;&amp;gt;a --&gt;
&lt;g id=&quot;edge15&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_m&amp;#45;&amp;gt;a&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M217.17,-73.81C203.86,-63.46 186.11,-49.66 171.76,-38.49&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;173.8,-35.65 163.76,-32.27 169.5,-41.17 173.8,-35.65&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_m&amp;#45;&amp;gt;h_2_1 --&gt;
&lt;g id=&quot;edge13&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_m&amp;#45;&amp;gt;h_2_1&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M206.81,-77.75C176.21,-66.24 128.35,-48.22 93.68,-35.18&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;94.87,-31.89 84.28,-31.64 92.41,-38.44 94.87,-31.89&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_m&amp;#45;&amp;gt;h_2_2 --&gt;
&lt;g id=&quot;edge14&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_m&amp;#45;&amp;gt;h_2_2&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M238.18,-71.7C238.84,-63.98 239.63,-54.71 240.37,-46.11&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;243.86,-46.37 241.23,-36.1 236.89,-45.77 243.86,-46.37&quot; /&gt;
&lt;/g&gt;
&lt;!-- h_n_m&amp;#45;&amp;gt;h_2_m --&gt;
&lt;g id=&quot;edge16&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;h_n_m&amp;#45;&amp;gt;h_2_m&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M261.26,-75.67C280.58,-65.19 307.78,-50.43 329.57,-38.6&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;331.42,-41.58 338.54,-33.73 328.08,-35.43 331.42,-41.58&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;可以看到，输入的所有元素都被连接，即被分配权重 w 和偏差项 b，所以这被称为一个「全连接层（&lt;strong&gt;Fully Connected Layer&lt;/strong&gt;）」或者「&lt;strong&gt;稠密层（Dense Layer）&lt;/strong&gt;」。但是对于一些任务这样做是很蠢的，会付出大量无效的计算。&lt;/p&gt;

&lt;p&gt;因此我们需要 focus 在更少量计算成本的模型，于是有了卷积神经网络（CNN）。关于 CNN 请看本系列博客的第「3」篇。&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;《自然语言处理：基于预训练模型的方法》车万翔 等&lt;/li&gt;
  &lt;li&gt;《自然语言处理实战：预训练模型应用及其产品化》安库·A·帕特尔 等&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="NLP" /><category term="感知器" /><category term="AI" /><category term="人工智能" /><category term="自然语言处理" /><category term="神经网络" /><category term="语言模型" /><category term="多层感知器" /><category term="ANN" /><category term="Perceptron" /><category term="激活后函数" /><category term="逻辑回归" /><category term="线性回归" /><category term="Softmax" /><category term="Sigmoid" /><category term="ReLU" /><category term="PyTorch" /><summary type="html">1957 年感知机（Perceptron）模型被提出，1959 年多层感知机（MLP）模型被提出。MLP 有时候也被称为 ANN，即 Artificial Neural Network，接下来我们来深入浅出地了解一下，并有一些动手的练习。</summary></entry><entry><title type="html">自然语言处理 AIGC 近年的发展脉络、关键论文、技术里程碑和商业应用</title><link href="https://www.mikecaptain.com/2022/12/24/captain-nlp-1/" rel="alternate" type="text/html" title="自然语言处理 AIGC 近年的发展脉络、关键论文、技术里程碑和商业应用" /><published>2022-12-24T15:08:01+00:00</published><updated>2022-12-24T15:08:01+00:00</updated><id>https://www.mikecaptain.com/2022/12/24/captain-nlp-1</id><content type="html" xml:base="https://www.mikecaptain.com/2022/12/24/captain-nlp-1/">&lt;ul&gt;
  &lt;li&gt;作者：麦克船长（钟超）&lt;/li&gt;
  &lt;li&gt;微信：sinosuperman&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#一自然语言处理领域近年的发展关键节点&quot; id=&quot;markdown-toc-一自然语言处理领域近年的发展关键节点&quot;&gt;一、自然语言处理领域近年的发展关键节点&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1从理性主义到经验主义&quot; id=&quot;markdown-toc-1从理性主义到经验主义&quot;&gt;1、从理性主义到经验主义&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2经验主义的早期还不是深度学习&quot; id=&quot;markdown-toc-2经验主义的早期还不是深度学习&quot;&gt;2、经验主义的早期，还不是深度学习&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3撇开特征让机器囫囵吞枣地学吧&quot; id=&quot;markdown-toc-3撇开特征让机器囫囵吞枣地学吧&quot;&gt;3、撇开特征，让机器「囫囵吞枣」地学吧&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4囫囵个儿地学习省去特征工程的人工但也少不了标注的人工&quot; id=&quot;markdown-toc-4囫囵个儿地学习省去特征工程的人工但也少不了标注的人工&quot;&gt;4、囫囵个儿地学习，省去特征工程的人工，但也少不了标注的人工&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5自监督学习法让我们省去人工标注&quot; id=&quot;markdown-toc-5自监督学习法让我们省去人工标注&quot;&gt;5、自监督学习法，让我们省去人工标注&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6用原始的任务训练出来的模型能迁移去解决新任务吗&quot; id=&quot;markdown-toc-6用原始的任务训练出来的模型能迁移去解决新任务吗&quot;&gt;6、用原始的任务训练出来的模型，能迁移去解决新任务吗？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#7从理解到生成nlp-是最直面-aigc-最硬核难题的领域&quot; id=&quot;markdown-toc-7从理解到生成nlp-是最直面-aigc-最硬核难题的领域&quot;&gt;7、从理解到生成，NLP 是最直面 AIGC 最硬核难题的领域&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#8数据和算力有了还不够&quot; id=&quot;markdown-toc-8数据和算力有了还不够&quot;&gt;8、数据和算力有了，还不够&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#二学术里程碑几篇重量级论文&quot; id=&quot;markdown-toc-二学术里程碑几篇重量级论文&quot;&gt;二、学术里程碑：几篇重量级论文&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#0提出-attention-机制的neural-machine-translation-by-jointly-learning-to-align-and-translate2015&quot; id=&quot;markdown-toc-0提出-attention-机制的neural-machine-translation-by-jointly-learning-to-align-and-translate2015&quot;&gt;0、提出 Attention 机制的《Neural Machine Translation by Jointly Learning to Align and Translate》（2015）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1提出-transformer-的attention-is-all-you-need2017&quot; id=&quot;markdown-toc-1提出-transformer-的attention-is-all-you-need2017&quot;&gt;1、提出 Transformer 的《Attention is All You Need》（2017）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2elmo-deep-contextualized-word-representations&quot; id=&quot;markdown-toc-2elmo-deep-contextualized-word-representations&quot;&gt;2、ELMo: Deep contextualized word representations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding2018&quot; id=&quot;markdown-toc-3bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding2018&quot;&gt;3、BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding（2018）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4gpt-3-language-models-are-few-shot-learners2020&quot; id=&quot;markdown-toc-4gpt-3-language-models-are-few-shot-learners2020&quot;&gt;4、GPT-3: Language Models are Few-Shot Learners（2020）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#其他的重量级论文&quot; id=&quot;markdown-toc-其他的重量级论文&quot;&gt;其他的重量级论文&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#三行业里程碑&quot; id=&quot;markdown-toc-三行业里程碑&quot;&gt;三、行业里程碑&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#四成本&quot; id=&quot;markdown-toc-四成本&quot;&gt;四、成本&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#五业内应用&quot; id=&quot;markdown-toc-五业内应用&quot;&gt;五、业内应用&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#五行业内哪些人的言论值得我们日常重点关注&quot; id=&quot;markdown-toc-五行业内哪些人的言论值得我们日常重点关注&quot;&gt;五、行业内哪些人的言论值得我们日常重点关注&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;一自然语言处理领域近年的发展关键节点&quot;&gt;一、自然语言处理领域近年的发展关键节点&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-17-ai-bert-1-1.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;1从理性主义到经验主义&quot;&gt;1、从理性主义到经验主义&lt;/h4&gt;

&lt;p&gt;自然语言处理（Natural Language Processing，简称 NLP），一开始走的是专家路线，也就是想「白盒化」来解构对自然语言的理解，这被称为「符号主义（Symbolism）」。符号主义的背后，是人类对自己用符号系统基于逻辑来完全数字化自然语言的自信。反正这条路目前是没走出来，你要非说「这其实是自负」，暂时人工智能专家们也无可辩驳。沿着这个路径的研究一直占据人工智能主流到 20 世纪 90 年代。&lt;/p&gt;

&lt;p&gt;这里我们想想，自然语言处理，其实是两个过程，一个是输入，即对自然语言的理解，一个是输出，即近期有点火的概念 AIGC（Artificial Intelligence Generated Content）。我们这里说说前者，人类学习语言的过程，哪有什么符号系统，哪有什么逻辑，就是被疯狂输入，然后经过很多个月之后，一个小 baby 就学会说话了，这个过程没有「理性主义」的痕迹，只有「经验主义」的胜利。那么 AI 学人话，能这样吗？&lt;/p&gt;

&lt;p&gt;于是就有了所谓「联结主义（Connectionism）」：你知道人的神经元网络吧？这个是一个个神经元，相互联结组成一个网络，通过这个网络来非常「黑盒化」地学习自然语言。至于这个网络里的每一个细节，我们不甚清楚，但就是可以通过这个网络模型学会自然语言，这就是一种「经验主义」。从 20 世纪 90 年代，人工智能领域就是沿着这个方向取得了巨大进展的。要注意一点，经验主义地路径解决 NLP 问题，并不等同于神经网络，但它是目前最有效的。&lt;/p&gt;

&lt;h4 id=&quot;2经验主义的早期还不是深度学习&quot;&gt;2、经验主义的早期，还不是深度学习&lt;/h4&gt;

&lt;p&gt;最初的经验主义，还是主要通过人工对特征进行「经验性地」提取，对计算机来说不要让它求甚解，直接给它喂这些梳理好的「特征」就好了。而这个需要一定的专业领域知识储备，加上人工地提取特征的操作过程，被称为「特征工程」。&lt;/p&gt;

&lt;p&gt;可以看出来，「特征工程」的人工工作量非常大，可以说是名副其实的「人工」智能了（此处捂脸）。但这已经比此前的、有点理想的那种构建符号系统的想法，要务实多了，也确实在解决问题的实用主义上也好得多。以这个为主流的研究，大概持续到 2010 年代。&lt;/p&gt;

&lt;h4 id=&quot;3撇开特征让机器囫囵吞枣地学吧&quot;&gt;3、撇开特征，让机器「囫囵吞枣」地学吧&lt;/h4&gt;

&lt;p&gt;要经过「人工」对特征进行研究、提取，实在是太难了，你说是「经验主义」，其实我个人认为有点介于「理性主义」与「经验主义」之间。毕竟还是非常需要人进行非常专家级地梳理的。于是，更囫囵个儿地给机器喂数据，让机器学会的方向，逐渐成为主流。能这样的前提，是牛逼算力的大发展，以及海量数据集的大规模沉淀，所以才会在 2010 年代爆发。&lt;/p&gt;

&lt;p&gt;这囫囵吞枣的学法，目前主要都是基于深度神经网路的表示学习方法实现的。为啥说「深度神经网络」，因为「从输入到输出」是有一层又一层的神经网络，第一层接收原始的自然语言输入，这么多层的神经网络就被称为深度神经网络。这个过程显著地避免了「特征工程」的人工高成本。&lt;/p&gt;

&lt;h4 id=&quot;4囫囵个儿地学习省去特征工程的人工但也少不了标注的人工&quot;&gt;4、囫囵个儿地学习，省去特征工程的人工，但也少不了标注的人工&lt;/h4&gt;

&lt;p&gt;虽然省去了需要专家的「特征工程」，但是这个「囫囵个儿学习法」还是需要依赖标注数据的，也就是「监督学习」。通过先学习大量有人工标注地数据，构建好深度神经网络后，再对测试数据进行验证，最后再用于使用。能不能把人工标注也给省了？或者至少不需要海量标注吧。&lt;/p&gt;

&lt;h4 id=&quot;5自监督学习法让我们省去人工标注&quot;&gt;5、自监督学习法，让我们省去人工标注&lt;/h4&gt;

&lt;p&gt;大家上中学的时候做过英语试卷里的「完形填空」吗？为什么我们根据一个填空的上下文，能推测出这个空应该填什么词？那我们是不是可以根据这个原理，把一段段完整的文字内容挖词进行训练学习？没错，这个挖掉的词，就可以当做曾经的「人工标注」，上年文就是训练数据。但是需要海量的数据，怎么办？&lt;/p&gt;

&lt;p&gt;好在书籍、互联网网页是我们最好的数据来源，而且数据量极其巨大，于是这就解决了人工个标注问题。由此衍生出来的方法，就被成为「自监督学习（Self-Supervised Learning）」。&lt;/p&gt;

&lt;h4 id=&quot;6用原始的任务训练出来的模型能迁移去解决新任务吗&quot;&gt;6、用原始的任务训练出来的模型，能迁移去解决新任务吗？&lt;/h4&gt;

&lt;p&gt;这是一个迁移学习问题，这也就引出了「预训练（Pre-Training）」，最近火到出圈的「ChatGPT」最后两个字母「PT」就是「预训练」。正如「预训练」这个名字，我们先对一些原始任务用大量数据对一个模型进行训练（这个过程其实就叫预训练），然后对于实际要解决的各种任务，再使用少量数据对模型进行精调（Fine-Tune），从而得到一个解决具体问题的模型。&lt;/p&gt;

&lt;p&gt;这样的方式，让面对具体任务（可以叫下游任务，或者目标任务）时可以省去很多训练，所以对这种模型叫做「预训练模型」。因此上游任务的训练，就变得非常有复用性、通用性价值，而不是每次面对新任务构建新模型来训练。沿着预训练模型，NLP 取得了非常多的突破。这个技术趋势，是从 2017 年 Transformer 模型在论文《Attention is All You Need》被提出后开始的，在论文中作者使用了大量的未标记的语言数据进行自监督学习，以学习 Transformer 模型的语言表示。然后，在这个自监督学习的模型的基础上，再使用少量的标记数据进行进一步训练，以解决具体的目标任务。&lt;/p&gt;

&lt;h4 id=&quot;7从理解到生成nlp-是最直面-aigc-最硬核难题的领域&quot;&gt;7、从理解到生成，NLP 是最直面 AIGC 最硬核难题的领域&lt;/h4&gt;

&lt;p&gt;我们再说回到前面提到的人工标注，从这点来理解所谓「任务」。人工标注，是主观性很强的。在图像处理、语音识别两个领域，标注数据的复用性很强，所以可以积累大的数据标注集，这是有积累沉淀价值的，比如 CV 领域鼎鼎大名的 ImageNet 图像数据集。但是 NLP 领域的任务复杂、多样，很难像图像处理、语音识别那样单纯地得到大量有价值标注。什么意思呢？这与我们在不同领域面对的任务有关。&lt;/p&gt;

&lt;p&gt;比如给一副画，对于绝大多数需要输入这幅画的任务来说，标注出它是一副油画、作者梵高、画中有星空等等，都是必须的。比如对于一个人脸识别，哪里是眼睛、鼻子、嘴巴，也是从任务层面非常通用的。语音识别就更有通用性了。但是对于一句自然语言，一个随机的任务需要什么信息，这非常难以沉淀通用。&lt;/p&gt;

&lt;p&gt;从这个角度说，一个「图像处理」任务一般是要输出这个图像里有什么内容，一个「语音识别」任务一般是要输出这段语音的文字内容是什么。但是一个「自然语言处理」任务一般是要干嘛？鬼知道要干嘛，但肯定大多数时候是要先生成一段话作为回应，这也就是「自然语言生成」。&lt;/p&gt;

&lt;p&gt;所以 NLP 领域的 NLG（Natural Language Generation）面对着最多可能性的任务，也就是最直面 AIGC 核心问题的领域。&lt;/p&gt;

&lt;h4 id=&quot;8数据和算力有了还不够&quot;&gt;8、数据和算力有了，还不够&lt;/h4&gt;

&lt;p&gt;我个人认为，预训练这个方向之所以正确，就是因为它在推动 AGI（Artificial General Intelligent）。这背后是一个基本哲学问题：我们应该把劲儿使在推动 AGI，还是应该认为每个领域都应该有自己独有的模型？&lt;/p&gt;

&lt;p&gt;这个问题的答案，在我看来是笃定的。AI 目前面对的还是人类思考的问题，而人面对的问题去构建的人脑学习模型，并没有呈现出在不同领域里人脑的学习方式有显著差异，更何况计算机能容纳的学习能力显然更广、更深。因此我很笃定，我们一定是要构建 AGI，为什么 AGI 将解决我们方方面面的问题。&lt;/p&gt;

&lt;p&gt;那么一个预训练模型，在下游能解决的问题越广，越说明这是在构建 AGI。但是反过来对上游的预训练模型的要求，就是它最好模型参数越多越好，这样能容纳的下游任务也就可能越多样。因此我们现在知道的 ChatGPT 背后的 OpenAI 公司此前研发的 GPT-3 已经有 1750 亿个参数了，这就是 —— 大模型。&lt;/p&gt;

&lt;p&gt;所以目前沿着预训练方向发展的自然语言处理领域，已经进入了「大模型、大数据、大算力」时代。&lt;/p&gt;

&lt;h3 id=&quot;二学术里程碑几篇重量级论文&quot;&gt;二、学术里程碑：几篇重量级论文&lt;/h3&gt;

&lt;p&gt;以下重量级的论文，每一篇都不短，B 站上有一些二手解读，虽然二手但是也值得高效地看下，这些论文我罗列如下。我的理解也不深，欢迎随时交流。&lt;/p&gt;

&lt;h4 id=&quot;0提出-attention-机制的neural-machine-translation-by-jointly-learning-to-align-and-translate2015&quot;&gt;0、提出 Attention 机制的《Neural Machine Translation by Jointly Learning to Align and Translate》（2015）&lt;/h4&gt;

&lt;p&gt;Bahdanau 等人在 2015 年提出了 Attention 机制，论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1409.0473.pdf&quot;&gt;https://arxiv.org/pdf/1409.0473.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;1提出-transformer-的attention-is-all-you-need2017&quot;&gt;1、提出 Transformer 的《Attention is All You Need》（2017）&lt;/h4&gt;

&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot;&gt;https://arxiv.org/pdf/1706.03762.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Google 的 Lamda、BERT，OpenAI 的 GPT-3 都是基于 Transformer 的。&lt;/p&gt;

&lt;p&gt;《Attention is all you need》是一篇颇具影响力的自然语言处理（NLP）论文，由 Google 在 2017 年发表。这篇论文提出了一种叫做 Transformer 的模型架构，这种模型架构不依赖于递归神经网络（RNN）或卷积神经网络（CNN）等传统的深度学习架构，而是使用了注意力机制（attention mechanism）和多头注意力（multi-head attention）来捕捉序列间的依赖关系。&lt;/p&gt;

&lt;p&gt;看到有人说「&lt;strong&gt;Transformer 基本宣告了 LSTM 在 NLP 领域的终结&lt;/strong&gt;」。Transformer 模型在 NLP 领域内获得了广泛的应用，并且因为其较好的并行化能力，在计算资源有限的情况下也能够获得较好的性能。Transformer 模型也被广泛应用于其他领域，如计算机视觉、音频处理等。&lt;/p&gt;

&lt;h4 id=&quot;2elmo-deep-contextualized-word-representations&quot;&gt;2、ELMo: Deep contextualized word representations&lt;/h4&gt;

&lt;p&gt;ELMo 是 Embeddings from Language Models 的缩写，刚好是《芝麻街》中一个角色的名字，是在 Peters 等人于 2018 年在 ACL（美国计算机学会计算语言学会议，NLP 领域顶级会议之一）上发表的论文《Deep contextualized word representations》中被提出来的。&lt;/p&gt;

&lt;p&gt;ELMo 是一种预训练模型，基于深度双向递归神经网络（biLSTM），可以用来生成词嵌入（word embeddings）。ELMo 使用了大量未标记的文本数据训练，并使用了多层双向递归神经网络来学习。&lt;/p&gt;

&lt;h4 id=&quot;3bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding2018&quot;&gt;3、BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding（2018）&lt;/h4&gt;

&lt;p&gt;BERT 模型是在一篇于 2018 年发表的叫做《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》的论文中被提出来的，BERT 是 Bidirectional Encoder Representations from Transformers 的缩写。我觉得这个名字有点硬凑出来的意思，BERT 也是《芝麻街》里一个角色的名字，我想就是为了跟 ELMo 凑一块儿怕它孤单吧。这篇论文带来的最大突破性变化有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在语言模型预训练中引入双向信息：传统的预训练语言模型（比如 word2vec、GloVe）通常只考虑了单向的信息（前面的词语）。BERT 模型则同时考虑了前后的词语，从而更好地捕捉句子的上下文信息。&lt;/li&gt;
  &lt;li&gt;在预训练中引入自监督学习任务。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;关于 BERT，我这里写了一篇背景介绍、用例试跑、优劣势分析：&lt;a href=&quot;https://www.mikecaptain.com/2022/12/17/ai-bert-1/&quot;&gt;《你可能已经听说 GPT-3，但是你也不能不知道 BERT —— 跟我一起用 BERT 跑个小用例》&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;4gpt-3-language-models-are-few-shot-learners2020&quot;&gt;4、GPT-3: Language Models are Few-Shot Learners（2020）&lt;/h4&gt;

&lt;p&gt;这篇来自 OpenAI 的论文，提出了「小样本学习（Few-Shot Learning，FSL）」的新训练方法，可以在小样本的情况下取得优秀的表现。&lt;/p&gt;

&lt;h4 id=&quot;其他的重量级论文&quot;&gt;其他的重量级论文&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context（2019）&lt;/li&gt;
  &lt;li&gt;RoBERTa: A Robustly Optimized BERT Pretraining Approach（2019）&lt;/li&gt;
  &lt;li&gt;T5: Exploring the Limits of Transfer Learning witha Unified Text-to-Text Transformer（2020）&lt;/li&gt;
  &lt;li&gt;ViT: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale（2021）&lt;/li&gt;
  &lt;li&gt;ERNIE-ViL: Vision and Language Pre-training for Image Captioning and VQA（2021）&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;三行业里程碑&quot;&gt;三、行业里程碑&lt;/h3&gt;

&lt;p&gt;2017 年 8 月，Andrej Karpathy 在其 Twitter 上发文称「很遗憾，梯度下降（实现的 AI 模型）代码写得比你好」。同年 11 月 Andrej 在博客上表示，软件 2.0 将会区别于软件 1.0 时代，程序将由更抽象的、基于神经网络权重的程序语言编写。&lt;/p&gt;

&lt;p&gt;2018 年 OpenAI 推出了无监督的、基于强化学习的第一代 GPT。&lt;/p&gt;

&lt;p&gt;2019 年情人节，OpenAI 发布 GPT-2，当时被称为史上最强的「通用」自然语言处理模型，基于 Transformer，拥有 15 亿个参数，使用含有 800 万网页内容的数据集训练。&lt;/p&gt;

&lt;p&gt;2020 年 6 月，拥有 1750 亿个参数的 GPT-3 面世，这个模型的训练量是 GPT-2 的十倍不止，并开放了商业化 API 共使用，不到一年时间发展出约 300 家企业客户。&lt;/p&gt;

&lt;p&gt;2021 年 6 月，微软与 OpenAI 共同推出代码辅助生成 AI 工具 GitHub Copilot.&lt;/p&gt;

&lt;p&gt;2022 年 1 月，OpenAI 发布基于 GPT-3 微调的模型 InstructGPT（包括 text-davinci-001、text-davinci-002、text-davinci-003），微调主要来自于 RLHF（Reinforcement Learning via Human Feedback）。&lt;/p&gt;

&lt;p&gt;2022 年 5 月，杭州 AI 领域初创公司「感知阶跃（ZMO.ai）」宣布完成由高瓴资本领投、GGV Capital 和 GSR Ventures 跟投的 800 万美元 A 轮融资。&lt;/p&gt;

&lt;p&gt;2022 年 10 月 19 日，Jasper.ai 宣布完成由 Insight Partner 领投，Coatue、（BVP）Bessemer 以及 IVP 等机构跟投的 1.25 亿美元 A 轮融资，估值达到了 15 亿美元，Jasper AI 从产品上线至今仅 18 个月。&lt;/p&gt;

&lt;p&gt;2022 年 11 月底，OpenAI 推出基于 GPT-3.5 的 ChatGPT 对话系统，震惊全球。项目地址：https://chat.openai.com 。&lt;/p&gt;

&lt;p&gt;2022 年 12 月底，专注于各 AI 闭源项目的逆向工程的 Philip Wang 发布了 PaLM+RLHF 的文本生成开源模型，类似于 ChatGPT。该项目基于 Google 的大型语言模型 PaLM 和带有人类反馈的强化学习（RLHF），拥有 5400 亿个参数。项目地址：https://github.com/lucidrains/PaLM-rlhf-pytorch 。&lt;/p&gt;

&lt;h3 id=&quot;四成本&quot;&gt;四、成本&lt;/h3&gt;

&lt;p&gt;目前成本主要有三方面：大模型、大数据、大算力。这其中最昂贵的成本首先是算力。下面有几个数据可以作为参照：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2020 年的一项研究表明，开发一个只有 15 亿个参数的文本生成模型的费用高达 160 万美元。&lt;/li&gt;
  &lt;li&gt;2022 年 7 月，为了训练拥有 1760 亿个参数的开源模型 Bloom，Hugging Face 的研究人员耗时三个月，使用了 384 个英伟达 A100 GPU。&lt;/li&gt;
  &lt;li&gt;OpenAI 的文本生成 GPT-3（具有大约 1750 亿个参数）的运行成本约为每年 87,000 美元。&lt;/li&gt;
  &lt;li&gt;Hugging Face 训练 Bloom 花了三个月的时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;五业内应用&quot;&gt;五、业内应用&lt;/h3&gt;

&lt;p&gt;因为图片生成的容错率非常高，也就是在应用上的包容度更高，相比之下文本或语音的生成，是对结果容错非常低的，比如不容许事实错误、逻辑错误等等。这类的应用，我们能想到：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;虚拟客服（可以乱真的）&lt;/li&gt;
  &lt;li&gt;智能助理：AI 家庭教师、AI 非诉律师、AI 医生助手、AI 新闻编辑、AI 设计助理&lt;/li&gt;
  &lt;li&gt;智能翻译&lt;/li&gt;
  &lt;li&gt;智能导购员：如果叠加虚拟人技术、语音合成技术，可以应用于电商&lt;/li&gt;
  &lt;li&gt;AI 广告公司：替代传统广告公司&lt;/li&gt;
  &lt;li&gt;AI 程序员助手：更高智能的辅助代码生成&lt;/li&gt;
  &lt;li&gt;部分场景下的美术工作者：游戏素材生成、海报生成&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们可以看到，AI 带来的这一波机会，都是曾经常说的「人不会被 AI 替代」的领域，也就是一些创作创意创新型工作，其中的中低端部分会因为成本因素而极力推动 AI 应用的发展。&lt;/p&gt;

&lt;p&gt;所以下面除了大家耳熟能详的 CV 领域的 AIGC 产品 Disco Diffusion、MidJourney、DALL·E 2、Stable Diffusion 之外，我们重点关注非图片生成类的应用。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用于营销场景的 AI 写手与图像生成工具「&lt;strong&gt;Jasper.ai&lt;/strong&gt;」，常被用于生成互联网营销文案（比如用于 Instagram、Tik Tok、Facebook、博客、email、论坛帖子 等等）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-24-captain-nlp-7.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2021 年 6 月，微软与 OpenAI 共同推出的的代码辅助生成 AI 工具「&lt;a href=&quot;https://github.com/features/copilot&quot;&gt;GitHub Copilot&lt;/a&gt;」发布。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-24-captain-nlp-2.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;文案神器「&lt;strong&gt;Copy.ai&lt;/strong&gt;」：&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-24-captain-nlp-9.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;虚拟客服「&lt;strong&gt;DialogFlow&lt;/strong&gt;」，能理解电话、语音内容等输入，并且给出文本或语音合成的输出。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-24-captain-nlp-8.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2021 年年底，西湖心辰公司发布「&lt;a href=&quot;https://www.heyfriday.cn/&quot;&gt;Friday AI 智能协作系统&lt;/a&gt;」，并且目前也做了商业化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-24-captain-nlp-1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;五行业内哪些人的言论值得我们日常重点关注&quot;&gt;五、行业内哪些人的言论值得我们日常重点关注&lt;/h3&gt;

&lt;p&gt;这些人的言论都值得我们关注：Sam Altman、Andrej Karpathy、Elon Musk。&lt;/p&gt;

&lt;p&gt;Andrej Karpathy 在其 Medium 博客上提到：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们都熟悉的软件 1.0 的「经典堆栈」（The classical stack）是由 Python、C++ 等语言编写的，它由程序员编写的明确的计算机指令组成。通过编写每一行代码，程序员标识了程序空间中具有某些期望行为的特定点。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;相比之下，软件 2.0 是用更抽象、不友好的人类语言（如神经网络的权重）编写的，没有人参与编写这些代码，因为权重数量很多（典型的网络可能有数百万个），并且直接用权重编写代码有一定困难（我尝试过）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不过打那之后 Andrej 在其博客上就再未说过一句话。&lt;/p&gt;

&lt;p&gt;OpenAI 创始人兼 CEO Sam Altman 曾表示：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;十年前的传统观点认为，人工智能首先会影响体力劳动，然后是认知劳动，再然后，也许有一天可以做创造性工作。现在看起来，它会以相反的顺序进行。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;通用人工智能的建成会比大多数人想象得更快，并且它会改变大多数人想象中的一切。」&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;另外还有一个喜欢写博客的 AI 从业者，其博客值得我们学习与了解，就是 OpenAI 应用人工智能研究负责人 Lilian Weng，主要从事机器学习、深度学习和网络科学研究。她本科毕业于香港大学，硕士就读于北京大学信息系统与计算机科学系，之后前往印度安纳大学布鲁顿分校攻读博士。&lt;/p&gt;

&lt;p&gt;她的 Blog：&lt;a href=&quot;https://lilianweng.github.io/&quot;&gt;https://lilianweng.github.io/&lt;/a&gt;
她的 Twitter：&lt;a href=&quot;https://twitter.com/lilianweng&quot;&gt;https://twitter.com/lilianweng&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;https://beta.openai.com/docs/models&lt;/li&gt;
  &lt;li&gt;https://karpathy.medium.com/software-2-0-a64152b37c35&lt;/li&gt;
  &lt;li&gt;https://hub.baai.ac.cn/view/21726&lt;/li&gt;
  &lt;li&gt;https://www.reddit.com/r/OpenAI/comments/zdrnsf/comment/iz3kfui/?context=3&lt;/li&gt;
  &lt;li&gt;https://www.sohu.com/a/615541698_121255906&lt;/li&gt;
  &lt;li&gt;http://blog.itpub.net/29829936/viewspace-2654536/&lt;/li&gt;
  &lt;li&gt;http://tech.sina.com.cn/csj/2018-10-13/doc-ihmhafir3634167.shtml&lt;/li&gt;
  &lt;li&gt;https://colab.research.google.com/github/alembics/disco-diffusion/blob/main/Disco_Diffusion.ipynb#scrollTo=DefMidasFns&lt;/li&gt;
  &lt;li&gt;https://en.wikipedia.org/wiki/BERT_(language_model)&lt;/li&gt;
  &lt;li&gt;https://www.mikecaptain.com/2022/12/17/ai-bert-1/&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="AI" /><category term="人工智能" /><category term="NLP" /><category term="自然语言处理" /><summary type="html">火出圈的 ChatGPT，背后是自然语言处理领域近几年发展的成果。本文从近几年自然语言处理的关键发展脉络，过程中关键的几篇学术论文，这几年的所有重要行业里程碑，以及目前为止业内已经诞生的应用。</summary></entry><entry><title type="html">你可能已经听说 GPT-3，但是你也不能不知道 BERT —— 跟我一起用 BERT 跑个小用例</title><link href="https://www.mikecaptain.com/2022/12/17/ai-bert-1/" rel="alternate" type="text/html" title="你可能已经听说 GPT-3，但是你也不能不知道 BERT —— 跟我一起用 BERT 跑个小用例" /><published>2022-12-17T15:08:01+00:00</published><updated>2022-12-17T15:08:01+00:00</updated><id>https://www.mikecaptain.com/2022/12/17/ai-bert-1</id><content type="html" xml:base="https://www.mikecaptain.com/2022/12/17/ai-bert-1/">&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#一关于-bert-的一些背景&quot; id=&quot;markdown-toc-一关于-bert-的一些背景&quot;&gt;一、关于 BERT 的一些背景&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#二开始一个-bert-的动手小试验&quot; id=&quot;markdown-toc-二开始一个-bert-的动手小试验&quot;&gt;二、开始一个 BERT 的动手小试验&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1安装-anaconda-来为部署-bert-做环境准备&quot; id=&quot;markdown-toc-1安装-anaconda-来为部署-bert-做环境准备&quot;&gt;1、安装 Anaconda 来为部署 BERT 做环境准备&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2安装-bert-所需要的各种依赖&quot; id=&quot;markdown-toc-2安装-bert-所需要的各种依赖&quot;&gt;2、安装 BERT 所需要的各种依赖&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3下载一个预训练pre-train过的-bert-模型&quot; id=&quot;markdown-toc-3下载一个预训练pre-train过的-bert-模型&quot;&gt;3、下载一个预训练（Pre-Train）过的 BERT 模型&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5启动-bert-服务端&quot; id=&quot;markdown-toc-5启动-bert-服务端&quot;&gt;5、启动 BERT 服务端&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6在-pycharm-中使用-conda-的环境&quot; id=&quot;markdown-toc-6在-pycharm-中使用-conda-的环境&quot;&gt;6、在 PyCharm 中使用 Conda 的环境&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#7编写程序实现-bert-客户端&quot; id=&quot;markdown-toc-7编写程序实现-bert-客户端&quot;&gt;7、编写程序实现 BERT 客户端&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#三bert-模型的优劣势及其原因&quot; id=&quot;markdown-toc-三bert-模型的优劣势及其原因&quot;&gt;三、BERT 模型的优劣势及其原因&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1bert-的优势是很明显的&quot; id=&quot;markdown-toc-1bert-的优势是很明显的&quot;&gt;1、BERT 的优势是很明显的&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#11mlm-和-nsp-预训练能够捕捉到自然语言中的各种复杂细节&quot; id=&quot;markdown-toc-11mlm-和-nsp-预训练能够捕捉到自然语言中的各种复杂细节&quot;&gt;1.1、MLM 和 NSP 预训练能够捕捉到自然语言中的各种复杂细节&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#12识别并专注于较重要的部分进行文本处理&quot; id=&quot;markdown-toc-12识别并专注于较重要的部分进行文本处理&quot;&gt;1.2、识别并专注于较重要的部分进行文本处理&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#13快速构建针对具体任务的-nlp-系统&quot; id=&quot;markdown-toc-13快速构建针对具体任务的-nlp-系统&quot;&gt;1.3、快速构建针对具体任务的 NLP 系统&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2bert-模型的劣势及其原因&quot; id=&quot;markdown-toc-2bert-模型的劣势及其原因&quot;&gt;2、BERT 模型的劣势及其原因&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#21随机挖-mask-的完形填空题是有隐患的&quot; id=&quot;markdown-toc-21随机挖-mask-的完形填空题是有隐患的&quot;&gt;2.1、随机挖 MASK 的完形填空题是有隐患的&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#22nsp-任务有必要吗&quot; id=&quot;markdown-toc-22nsp-任务有必要吗&quot;&gt;2.2、NSP 任务有必要吗？&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#23针对两个或以上词组成的连续词的词义被丢失&quot; id=&quot;markdown-toc-23针对两个或以上词组成的连续词的词义被丢失&quot;&gt;2.3、针对两个或以上词组成的连续词的词义被丢失&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#24需要的算力高&quot; id=&quot;markdown-toc-24需要的算力高&quot;&gt;2.4、需要的算力高&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#25需要的模型大&quot; id=&quot;markdown-toc-25需要的模型大&quot;&gt;2.5、需要的模型大&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#四一些关于-bert-的问题&quot; id=&quot;markdown-toc-四一些关于-bert-的问题&quot;&gt;四、一些关于 BERT 的问题&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#1bert-模型的所谓双向与-bilstm-的双向是啥区别&quot; id=&quot;markdown-toc-1bert-模型的所谓双向与-bilstm-的双向是啥区别&quot;&gt;1、BERT 模型的所谓「双向」与 BiLSTM 的「双向」是啥区别？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2为什么-bert-可以比-rnn-更好地并行化&quot; id=&quot;markdown-toc-2为什么-bert-可以比-rnn-更好地并行化&quot;&gt;2、为什么 BERT 可以比 RNN 更好地并行化&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;一关于-bert-的一些背景&quot;&gt;一、关于 BERT 的一些背景&lt;/h3&gt;

&lt;p&gt;2018 年 Google 发布 BERT 后迅速在 NLP 领域引起广泛关注。BERT（Bidirectional Encoder Representations from Transformers）是一种自然语言处理（NLP）的深度学习模型，它可以进行语言模型预测、序列标注和问答等任务。BERT 采用双向的 Transformer 编码器架构，使用了大量的数据和计算资源进行训练，因此具有较强的泛化能力。&lt;/p&gt;

&lt;p&gt;BERT 的训练方法是通过让模型对给定的输入文本进行自监督学习，即使用未标记的语料进行训练。BERT 可以在很多 NLP 任务中获得较好的性能，并且由于其双向的编码方式，能够更好地理解语境信息。&lt;/p&gt;

&lt;p&gt;BERT 的训练需要大量的计算资源，因此它常常被用来作为解决 NLP 问题的预训练模型，可以用来初始化其他模型的权重，使得这些模型能够更快速地收敛。&lt;/p&gt;

&lt;h3 id=&quot;二开始一个-bert-的动手小试验&quot;&gt;二、开始一个 BERT 的动手小试验&lt;/h3&gt;

&lt;p&gt;为了让 conda 使用 Python 3.7，你可以按照这些步骤来操作。&lt;/p&gt;

&lt;h4 id=&quot;1安装-anaconda-来为部署-bert-做环境准备&quot;&gt;1、安装 Anaconda 来为部署 BERT 做环境准备&lt;/h4&gt;

&lt;p&gt;先了解几个概念：Anaconda 是一个软件包管理系统，其中包含了 conda 和许多其他的工具。Conda 是 Anaconda 中的一个组件，用于安装和管理软件包。
我们需要用 conda 创建一个环境，在这个环境里去启用我们想要使用的 BERT 所需要的各种依赖。&lt;/p&gt;

&lt;p&gt;更新 conda 到最新版本：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; base conda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 Python 3.7 创建一个新的环境：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda create &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; py37 &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3.7
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;激活这个新环境：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda activate py37
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;验证正在使用的是正确版本的 Python&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python &lt;span class=&quot;nt&quot;&gt;--version&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;另外你可能还会用到的 conda 命令有：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 你之后一定会需要 deactivate 一个环境，命令如下：&lt;/span&gt;
conda deactivate py37

&lt;span class=&quot;c&quot;&gt;# 查看 conda 当前安装的所有库&lt;/span&gt;
conda list
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;2安装-bert-所需要的各种依赖&quot;&gt;2、安装 BERT 所需要的各种依赖&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;tensorflow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;1.14.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;验证 tensorflow 是否安装正确：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__version__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;3下载一个预训练pre-train过的-bert-模型&quot;&gt;3、下载一个预训练（Pre-Train）过的 BERT 模型&lt;/h4&gt;

&lt;p&gt;官方的模型在这里浏览：https://github.com/google-research/bert#pre-trained-models&lt;/p&gt;

&lt;p&gt;也有一些中文的模型，以下是 ChatGPT 推荐的三个：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BERT-Base, Chinese：这是 Google 官方提供的中文 BERT 模型，在中文 NLP 任务中表现良好。你可以从 这里下载这个模型。&lt;/li&gt;
  &lt;li&gt;ERNIE：这是由中科院自然语言所提供的中文 BERT 模型，包含了额外的语义信息。你可以从 这里下载这个模型。&lt;/li&gt;
  &lt;li&gt;RoBERTa-wwm-ext：这是由清华大学自然语言处理实验室提供的中文 BERT 模型，在多种中文 NLP 任务中表现良好。你可以从 这里下载这个模型。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4、安装 BERT 的服务端和客户端&lt;/p&gt;

&lt;p&gt;这里我们使用 bert-as-service，bert-as-service 是一种将 BERT 模型部署为服务的方式。该工具使用 TensorFlow Serving 来运行 BERT 模型，并允许通过 REST API 进行调用。根据 bert-as-service 的文档，它已经在 TensorFlow 1.14.0 上测试过。&lt;/p&gt;

&lt;p&gt;在你激活的环境里，安装 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bert-as-service&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 安装服务端和客户端&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 更多关于 bert-serving-server 的信息可以参考：https://bert-serving.readthedocs.io/en/latest/index.html&lt;/span&gt;
conda &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;bert-serving-server bert-serving-client 
验证 bert-as-service 是否安装成功
bert-serving-start &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;5启动-bert-服务端&quot;&gt;5、启动 BERT 服务端&lt;/h4&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# 命令行下启动BERT服务&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# -num_worker 表示启动几个worker服务，即可以处理几个并发请求，超过这个数字的请求将会在LBS（负载均衡器）中排队等待&lt;/span&gt;
bert-serving-start &lt;span class=&quot;nt&quot;&gt;-model_dir&lt;/span&gt; /模型/的/绝对/路径 &lt;span class=&quot;nt&quot;&gt;-num_worker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;6在-pycharm-中使用-conda-的环境&quot;&gt;6、在 PyCharm 中使用 Conda 的环境&lt;/h4&gt;

&lt;p&gt;在 PyCharm 中启用 Interpreter 为 Anaconda，macOS 上具体地是在「Preference - Project - Python Interpreter - Add Interpreter - Add Local Interpreter - Conda Environment」。&lt;/p&gt;

&lt;p&gt;接下来还有一项重要的步骤就是选择该 project 要加载包文件的路径。如果不进行这一步，那该 project 还是从系统环境变量中的路径来搜索你要加载的包，这样在你用 Anaconda 新建的这个环境中所特有的包就会出现无法加载的问题。单击菜单栏 Run 选择 Edit Configuration。在Environment variables中添加一个新的 Path。新的路径为你用 Anaconda 新建的环境的文件夹中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;「/Users/captain/opt/anaconda3/bin/python」&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;配置 PyCharm 这里参考：https://docs.anaconda.com/anaconda/user-guide/tasks/pycharm/&lt;/p&gt;

&lt;h4 id=&quot;7编写程序实现-bert-客户端&quot;&gt;7、编写程序实现 BERT 客户端&lt;/h4&gt;

&lt;p&gt;这里有一些客户端例子可以参考：https://blog.csdn.net/qq_18256855/article/details/123860126&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bert_serving.client&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BertClient&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 定义类
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BertModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bert_client&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BertClient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;127.0.0.1&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5555&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port_out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5556&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 创建客户端对象
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 注意：可以参考API，查看其它参数的设置
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 127.0.0.1 表示本机IP，也可以用localhost
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;cannot create BertClient&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;close_bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bert_client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 关闭服务
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sentence_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;对输入文本进行embedding
          Args:
            text: str, 输入文本
          Returns:
            text_vector: float, 返回一个列表，包含text的embedding编码值
        &apos;&apos;&apos;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text_vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bert_client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_vector&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 获取输出结果
&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;caculate_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&apos;&apos;&apos;根据两个语句的vector，计算它们的相似性
          Args:
            vec_1: float, 语句1的vector
            vec_2: float, 语句2的vector
          Returns:
            sim_value: float, 返回相似性的计算值
        &apos;&apos;&apos;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 根据cosine的计算公式
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;__main__&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 创建bert对象
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;bert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BertModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# --- 输入语句 ----
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;input_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;请输入语句1: &apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;N&quot;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close_bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 关闭服务
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;input_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;请输入语句2: &apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# --- 对输入语句进行embedding ---
&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;a_vec shape : &apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;b_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;b_vec shape : &apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 计算两个语句的相似性
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;caculate_similarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;cosine value : &apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 如果相似性值大于0.85，则输出相似，否则，输出不同
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2个语句的含义相似&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;不相似&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bert-serving-client&lt;/code&gt; 连接 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bert-serving-server&lt;/code&gt; 时，你需要确保 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bert-serving-server&lt;/code&gt; 使用的模型和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bert-serving-client&lt;/code&gt; 使用的模型是匹配的，否则会出现错误。&lt;/p&gt;

&lt;p&gt;程序正常运行后，将要求你输入两句话，然后 BERT 计算两句话的相似性。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;请输入语句1: 
请输入语句2: 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;两句输入好确认后，得到如下形式的结果：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a_vec shape :  (768,)
b_vec shape :  (768,)
cosine value :  0.8691698561422959
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其实这个小试验蛮没意思的，而且准确性也比较令人质疑。&lt;/p&gt;

&lt;h3 id=&quot;三bert-模型的优劣势及其原因&quot;&gt;三、BERT 模型的优劣势及其原因&lt;/h3&gt;

&lt;p&gt;论文地址：&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;《BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding》&lt;/a&gt; 。&lt;/p&gt;

&lt;h4 id=&quot;1bert-的优势是很明显的&quot;&gt;1、BERT 的优势是很明显的&lt;/h4&gt;

&lt;p&gt;复旦大学的邱锡鹏教授层评价 BERT 的「里程碑意义」在于：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;证明了一个非常深的模型可以显著提高 NLP 任务的准确率，而这个模型可以从无标记数据集中预训练得到。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;11mlm-和-nsp-预训练能够捕捉到自然语言中的各种复杂细节&quot;&gt;1.1、MLM 和 NSP 预训练能够捕捉到自然语言中的各种复杂细节&lt;/h5&gt;

&lt;p&gt;因为 BERT 采用了双向的自注意力机制，这里的「双向」意味着 BERT 模型可以同时利用输入文本的前后文信息来预测下一个词是什么、下一句是什么。这样 BERT 模型就可以捕捉到自然语言中的各种隐藏的细节，比如语义关系、语法结构、语义暗示等等。&lt;/p&gt;

&lt;p&gt;具体地，BERT 采用了 Masked Language Model（MLM）来做「下一个词是什么」的预训练，采用了 Next Sentence Prediction（NSP）来做「下一句是什么」的预训练。MLM 的方式其实就很像英语考试里的「完形填空」，而 NSP 的方式，就像整句的完形填空。&lt;/p&gt;

&lt;h5 id=&quot;12识别并专注于较重要的部分进行文本处理&quot;&gt;1.2、识别并专注于较重要的部分进行文本处理&lt;/h5&gt;

&lt;p&gt;这要得益于因为 BERT 采用了自注意力机制。自注意力机制，通过计算输入单元的权重值，来确定在一个输入序列中哪些输入单元是重要的。具体地，一个输入单元与其他单元的相似性越高，按照我们自然语言的逻辑，那么这部分是在被重复、强调、翻来覆去用不同的方式在解释，那么这部分就是重要的，权重值就更高。&lt;/p&gt;

&lt;h5 id=&quot;13快速构建针对具体任务的-nlp-系统&quot;&gt;1.3、快速构建针对具体任务的 NLP 系统&lt;/h5&gt;

&lt;p&gt;因为 BERT 采用了预训练模型，能够在没有监督标注数据的情况下从大量文本中学习语言模型。因为我们认为上下文信息本身就能推测出某个词，所以大量的文本数据本身就是一种「自带标注」的数据，所以 BERT 能够无监督学习。&lt;/p&gt;

&lt;h4 id=&quot;2bert-模型的劣势及其原因&quot;&gt;2、BERT 模型的劣势及其原因&lt;/h4&gt;

&lt;h5 id=&quot;21随机挖-mask-的完形填空题是有隐患的&quot;&gt;2.1、随机挖 MASK 的完形填空题是有隐患的&lt;/h5&gt;

&lt;p&gt;对于上面提到的 MLM、NSP 方法做预训练，那么问题也就显而易见了，如果我们挖掉的一组 MASK 完形填空词，是强关联的（非条件独立），那么这一组词的预测就都会出现问题。&lt;/p&gt;

&lt;h5 id=&quot;22nsp-任务有必要吗&quot;&gt;2.2、NSP 任务有必要吗？&lt;/h5&gt;

&lt;p&gt;论文《Crosslingual language model pretraining》中提到 BERT 的 NSP 可能是非必要的，针对这个问题，后续出现的模型都移除了 NSP 任务，比如 RoBERTa、spanBERT、ALBERT。&lt;/p&gt;

&lt;h5 id=&quot;23针对两个或以上词组成的连续词的词义被丢失&quot;&gt;2.3、针对两个或以上词组成的连续词的词义被丢失&lt;/h5&gt;

&lt;p&gt;比如 cutting-edge，MLM 的方式可能会割裂这两个子词的相关性，导致模型丢失这个词的词义，针对这个问题 Google 后来发表了 BERT-WWM，WWM 即 Whole Word Masking，从字面就能理解针对的问题。哈尔滨工业大学的科大讯飞联合实验室后来推出了 Chinese-BERT-WWM 专门针对中文解决了这个问题。&lt;/p&gt;

&lt;h5 id=&quot;24需要的算力高&quot;&gt;2.4、需要的算力高&lt;/h5&gt;

&lt;p&gt;算力高，自然需要的计算成本运行更高。不过算力成本高这种问题总有办法优化，通常来说不是模型本身所处理问题的局限性和先决条件的局限性（比如依赖大量人工工作）就非常好了。&lt;/p&gt;

&lt;h5 id=&quot;25需要的模型大&quot;&gt;2.5、需要的模型大&lt;/h5&gt;

&lt;p&gt;模型大，自然存储成本也就高了。这也类似于上一点，而且算力、存储成本高，可以在大型应用中把成本均摊下来，比如 BERT 如果支持的某个 AGI 应用得到广泛普及。&lt;/p&gt;

&lt;h3 id=&quot;四一些关于-bert-的问题&quot;&gt;四、一些关于 BERT 的问题&lt;/h3&gt;

&lt;h4 id=&quot;1bert-模型的所谓双向与-bilstm-的双向是啥区别&quot;&gt;1、BERT 模型的所谓「双向」与 BiLSTM 的「双向」是啥区别？&lt;/h4&gt;

&lt;p&gt;BiLSTM 是把句子再倒序一遍，而 BERT 的双向是指在 Encoder 的自注意力机制下编码一个 token 时「同时利用上下文」的 token。&lt;/p&gt;

&lt;h4 id=&quot;2为什么-bert-可以比-rnn-更好地并行化&quot;&gt;2、为什么 BERT 可以比 RNN 更好地并行化&lt;/h4&gt;

&lt;p&gt;RNN 因为有时序概念，即后面的特征计算，依赖于前面计算的结果，所以就形成了循环（Recurrent）。而 BERT 采用了自注意力机制则没有时序概念，每个词特征都依赖其上下文独立计算，因此更容易并行化。&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;https://arxiv.org/abs/1810.04805&lt;/li&gt;
  &lt;li&gt;https://github.com/google-research/bert&lt;/li&gt;
  &lt;li&gt;https://github.com/ymcui/Chinese-BERT-wwm&lt;/li&gt;
  &lt;li&gt;https://zhuanlan.zhihu.com/p/195723105&lt;/li&gt;
  &lt;li&gt;https://www.jiqizhixin.com/articles/2018-10-24-13&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="BERT" /><category term="AI" /><category term="人工智能" /><summary type="html">2018 年 Google 发布了 BERT 模型后迅速席卷 NLP 领域，这家伙可是比 ChatGPT 背后的 GPT 还要早的。本文简单介绍了 BERT 后主要是希望大家都手试一下，所以文中提到了一个小的中文模型供大家练手，以及一个小用例。</summary></entry><entry><title type="html">动动手，让你和你的朋友们，在微信上跟 ChatGPT 聊聊天</title><link href="https://www.mikecaptain.com/2022/12/11/wechat-chatgpt/" rel="alternate" type="text/html" title="动动手，让你和你的朋友们，在微信上跟 ChatGPT 聊聊天" /><published>2022-12-11T15:59:57+00:00</published><updated>2022-12-11T15:59:57+00:00</updated><id>https://www.mikecaptain.com/2022/12/11/wechat-chatgpt</id><content type="html" xml:base="https://www.mikecaptain.com/2022/12/11/wechat-chatgpt/">&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-11-wechat-chatgpt-3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;写在前面&quot;&gt;写在前面&lt;/h3&gt;
&lt;p&gt;最近 OpenAI 的 ChatGPT 非常地出圈，ChatGPT 是一个由 OpenAI 训练的大型语言模型，被设计用来回答用户的问题并提供信息。官方的 Slogan 是 &lt;strong&gt;「Optimizing Language Models for Dialogue」&lt;/strong&gt;，所以非常适合做到 IM 里聊天。那么我在想如果用一个微信号，背后是 ChatGPT，是不是很有趣？正当我准备利用 WeChaty 开发一个服务端程序来连接 ChatGPT 时，发现目前 Github 上已经有人做了，刚好可以省去很多工程的工作。&lt;/p&gt;

&lt;h3 id=&quot;stepbystep&quot;&gt;Step by step&lt;/h3&gt;

&lt;p&gt;本实践依赖：CLI、Docker、npm、Github、fuergaosi233/wechat-chatgpt、git、YAML、Chrome 的使用。以下将简洁地 Step by step 列出步骤。&lt;/p&gt;

&lt;p&gt;第一步，你要现有一个 OpenAI 的账号，注意注册时手机号不能是中国大陆或香港的，IP 地址和 GPS 也不能暴露你是中国大陆或者香港的。&lt;/p&gt;

&lt;p&gt;第二步，准备一台服务器（否则个人电脑要一直处于开机运行状态），由于后面将用到 Session Token 来登录，因此 IP 地址是香港也没关系，于是我是在我的香港服务器上部署 wechat-chatgpt&lt;/p&gt;

&lt;p&gt;第三步，在服务器上安装 Docker，不赘述。&lt;/p&gt;

&lt;p&gt;第四步，从 Github 上拉取项目项目到服务器上。&lt;/p&gt;

&lt;p&gt;第五步，任何设备上登录 ChatGPT，用 Chrome 的 Inspect 来查看并复制 session token 到剪贴板。&lt;/p&gt;

&lt;p&gt;第六步，编辑 wechat-chatgpt 的 config.yaml，填写 session token；设置 private trigger keywords（可选）。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;chatGPTAccountPool&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;your email&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;your password&amp;gt;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# if you hope only some keywords can trigger chatgpt on private chat, you can set it like this:&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;chatPrivateTiggerKeyword&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第七步，用 docker 来拉取 wechat-chatgpt&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull holegots/wechat-chatgpt:latest。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;第八步，启动 wechat-chatgpt：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker run &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt; wechat-chatgpt &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/config.yaml:/app/config.yaml holegots/wechat-chatgpt:latest
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意，如果手动模式下也可以用npm run dev启动。如果提示系统不认识 npm 则可以运行 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;npm install &amp;amp;&amp;amp; poetry install&lt;/code&gt; 来解决。到此你就可以在微信上跟这个打通了 ChatGPT 的账号聊天了。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;img src=&quot;/img/src/2022-12-11-wechat-chatgpt-1.png&quot; alt=&quot;image&quot; style=&quot;width:100%&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img src=&quot;/img/src/2022-12-11-wechat-chatgpt-2.png&quot; alt=&quot;image&quot; style=&quot;width:100%&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;其实可以看到这个 AI 船长不管是专业性问题（计算机相关）还是非专业问题，都回答的很不错。&lt;/p&gt;

&lt;p&gt;如何停止、重启、查看日志呢？首先停止的命令是docker stop wechat-chatgpt，登录时需要扫码登录微信并追踪 logs，因为这其实是用了微信在桌面端的接口。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker logs &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; wechat-chatgpt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;会在 Terminal 里显示一个文字阵列组成的桌面端微信登录二维码，用你打算做成微信 AI 机器人那个微信号扫一下，相关信息都填完。另外，这样最好别用自己的微信大号，而是用一个小号。微信不让聊这些，小号注意要完成实名认证。&lt;/p&gt;

&lt;p&gt;如果要停止运行，用如下命令：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker stop wechat-chatgpt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;参考&quot;&gt;参考&lt;/h3&gt;

&lt;p&gt;1、&lt;a href=&quot;https://github.com/fuergaosi233/wechat-chatgpt/tree/main&quot;&gt;https://github.com/fuergaosi233/wechat-chatgpt/tree/main&lt;/a&gt;&lt;/p&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="人工智能" /><category term="AI" /><category term="ChatGPT" /><category term="OpenAI" /><category term="微信" /><summary type="html">最近 OpenAI 的 ChatGPT 非常地出圈，ChatGPT 是一个由 OpenAI 训练的大型语言模型，被设计用来回答用户的问题并提供信息。官方的 Slogan 是「Optimizing Language Models for Dialogue」，所以非常适合做到 IM 里聊天。那么我在想如果用一个微信号，背后是 ChatGPT，是不是很有趣？正当我准备利用 WeChaty 开发一个服务端程序来连接 ChatGPT 时，发现目前 Github 上已经有人做了，刚好可以省去很多工程的工作 ……</summary></entry><entry><title type="html">确实惊艳！用 MidJourney 三分钟生成了两张 CG 级高清机甲特写</title><link href="https://www.mikecaptain.com/2022/11/30/midjourney-first-test/" rel="alternate" type="text/html" title="确实惊艳！用 MidJourney 三分钟生成了两张 CG 级高清机甲特写" /><published>2022-11-30T15:12:03+00:00</published><updated>2022-11-30T15:12:03+00:00</updated><id>https://www.mikecaptain.com/2022/11/30/midjourney-first-test</id><content type="html" xml:base="https://www.mikecaptain.com/2022/11/30/midjourney-first-test/">&lt;p&gt;因为 Diffusion 模型在计算机视觉领域的发展，最近文生图（Text2Image）很火，花了三分钟时间用 MidJourney 做了一组机甲图，确实非常惊艳，直接看图：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;img src=&quot;/img/src/2022-12-16-midjourney-first-test-1.png&quot; alt=&quot;image&quot; /&gt;&lt;/th&gt;
      &lt;th&gt;&lt;img src=&quot;/img/src/2022-12-16-midjourney-first-test-2.png&quot; alt=&quot;image&quot; /&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;今年人工智能在 CV 领域的发展非常的精彩，目前市面上看到的主要应用，都是这种松散式的、对结果容错率很高图像生成，基于一段 prompt 生成一张或一组图片，甚至已经有了 avatarai.me 这种帮你打造全套的 photorealistic 层次质感的全套图片和视频商业化产品。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-16-midjourney-first-test-3.png&quot; alt=&quot;image&quot; /&gt;
（&lt;em&gt;注：MidJourney 官网&lt;/em&gt;）&lt;/p&gt;

&lt;p&gt;未来很快，我们将看到一些更精准满足图像生成需求的应用出现，比如生成游戏素材（其实现在已经有了，比如 Scenario.gg）、AI 替身生成等等。&lt;/p&gt;

&lt;p&gt;相应的，对抗性的防御技术也会很快发展。&lt;/p&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="ai" /><category term="AI" /><category term="人工智能" /><category term="diffusion" /><category term="MidJourney" /><category term="Text2Image" /><category term="文生图" /><category term="AIGC" /><summary type="html">因为 Diffusion 模型在计算机视觉领域的发展，可以说今年人工智能在计算机视觉领域大放异彩，各种 Text2Image 项目层出不穷，花了三分钟时间做了一组机甲图，确实非常惊艳 ……</summary></entry><entry><title type="html">不要船开远了，就忘了为什么启航</title><link href="https://www.mikecaptain.com/2022/08/11/captain-alibaba/" rel="alternate" type="text/html" title="不要船开远了，就忘了为什么启航" /><published>2022-08-11T15:53:57+00:00</published><updated>2022-08-11T15:53:57+00:00</updated><id>https://www.mikecaptain.com/2022/08/11/captain-alibaba</id><content type="html" xml:base="https://www.mikecaptain.com/2022/08/11/captain-alibaba/">&lt;h3 id=&quot;写在前面&quot;&gt;写在前面&lt;/h3&gt;
&lt;p&gt;偶然翻到 2020.06.11 刚来到阿里时写的一篇内容（我是 2020 年的 6 月 4 日我入职阿里巴巴集团），是有关于来阿里的期待、对这家公司的一些粗浅初步的理解。此时再翻来看看，最大的感触就是，提醒自己勿忘初心。&lt;/p&gt;

&lt;p&gt;在不涉及到公司数据安全及商业机密问题的前提下，稍做了一些删改，发布在这里作为一个回顾。本次穿插了一些图片，当时写的时候还没有这些照片。本文内容包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;很多人是带着梦想来阿里的，那么我的梦想是什么呢？&lt;/li&gt;
  &lt;li&gt;最喜欢新六脉的哪句话？为什么？&lt;/li&gt;
  &lt;li&gt;关于阿里企业价值观：为什么要接受这套价值观？&lt;/li&gt;
  &lt;li&gt;价值观的本质意义（极度务实视角）是什么？&lt;/li&gt;
  &lt;li&gt;Landing 的 SOP&lt;/li&gt;
  &lt;li&gt;问问自己，来到阿里，如果初期我可能需要做一点改变，那会是什么？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2020 年平安夜 · 百年湖畔 87 期合影&lt;/p&gt;

&lt;h3 id=&quot;很多人是带着梦想来阿里的那么我的梦想是什么呢&quot;&gt;很多人是带着梦想来阿里的，那么我的梦想是什么呢？&lt;/h3&gt;

&lt;p&gt;Christensen 在《创新者的窘境》中提到：每一次技术更迭，都需要破坏性创新，而破坏性创新在前一次技术更迭的胜出者内部是很难生长出来的。阿里诞生以来，不断地创造第二增长曲线：阿里巴巴、淘宝、支付宝、天猫、阿里云、钉钉 …… 这让我非常好奇。其中很多产品穿越多个时间周期，期间不断创造内生二次曲线。&lt;/p&gt;

&lt;p&gt;但是阿里也一样错失了很多，微信、美团、拼多多、抖/快…… 等等很多产品诞生在了其他公司，还有某些产品在不断的科技更迭中自身生长出了第二曲线。&lt;/p&gt;

&lt;p&gt;因此我来阿里的梦想也非常明确：&lt;strong&gt;参与或创造一次（甚至多次）第二曲线，可以是新产品，也可以是原有产品内生的。在这个过程中获得个人成长、个人价值。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一直以来，我有三个最想实现或得到的东西：LOVE、CREATION、FREEDOM。随着生活与工作的前行，对这三者的理解，在不断加深。在这个问题里，我想应该是讨论”CREATION”。&lt;/p&gt;

&lt;p&gt;CREATION 上，我的梦想的范式，大概是从自己中学时代就确立了，在某一次人类社会变革浪潮中，扮演有一定权重的角色。这里面有几个变量：&lt;strong&gt;什么领域（F）的变革；什么规模（S）的变革；多大的权重（W）；什么角色（R）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;F 这个变量，我在中学及大学时代逐渐明确，是以相对普适的产品形式输出结果并对社会变革产生积极作用。后来越来越明确为科技与商业结合的领域。&lt;/p&gt;

&lt;p&gt;S、W 这两个变量，自然是越大越好。因此我会希望能够构建尽可能大的机会，或者参与到尽可能大的机会中。R 希望是有强烈 Ownership 的身份。&lt;/p&gt;

&lt;p&gt;因此过去几年我选择了创业。创业就像冲浪，你抓住一次浪并完成漂亮的动作，就是一次不算失败的创业。但是如果一个浪没抓住，你去追它是没意义的，而应该等待下一个浪。我认为在未来 5~10 年内难以出现规模能大到令我足够兴奋的科技浪潮。大浪潮中属于创业者的大机会很多，而中小浪潮的大机会基本只属于大平台，那么为了在壮年期做获得我的 CREATION，我选择了加入阿里这样的大平台。&lt;/p&gt;

&lt;p&gt;在最后做决定以及初来阿里的那个人生转折点，作为老阿里人的曲洋老师对我说的一句话，深深地鼓励了我，他说：”带着创业气质，把这里当你的舞台折腾！”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2020 年双十一 · 淘宝 KO&lt;/p&gt;

&lt;h3 id=&quot;最喜欢新六脉的哪句话为什么&quot;&gt;最喜欢新六脉的哪句话？为什么？&lt;/h3&gt;

&lt;p&gt;最喜欢的是“因为信任所以简单”。&lt;/p&gt;

&lt;p&gt;我一直认为人最重要的两个元特质是”真实”和“谦逊”，由”真实”可以塑造自我（对内）、构建信任（对外），后者可以带来清晰的边界，继而实现人与人之间高效的互动（这种互动包括各种人际关系在内，如婚姻、合伙、共事、合作等等）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;事物（虚实皆可）呈现在人的认知中，会得到三方面的投影：facts、opinion、feeling。如果我们足够真实，当我们需要把这三方面呈现给他人时，双方就能顺畅建立信任。信任的结果，就对应到这三方面：彼此之间建立共识（facts）、求同存异（opinion）、尊重感受（feeling），这就是”简单”。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;另外一句是鼓励自己勇于绽放的一条：「此次此刻，非我莫属」。&lt;/p&gt;

&lt;p&gt;激情、自信、积极…… 通常行为统一表现为“勇于绽放自己”，绽放有表达（语言）与投身（行为）两种表现形式。更进一步推进就是”此次此刻，非我莫属”的阿里价值观。&lt;/p&gt;

&lt;p&gt;低调、稳重、谦逊，其实与“此次此刻，非我莫属“，并不矛盾。这点是我来到阿里后，发现自己在过去这些年的创业中已经不知不觉改变了，从 Introvert 逐渐变成了 Extrovert 的人，而且从曾经 social 中消耗能量，逐渐变为我现在可以感知到获得能量。这种变化，是我最近来阿里才确认发生的，此前因为自己创业者的身份没有察觉这种变化的发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-3.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2021 年秋 · 径山之行&lt;/p&gt;

&lt;h3 id=&quot;关于阿里企业价值观为什么要接受这套价值观&quot;&gt;关于阿里企业价值观：为什么要接受这套价值观？&lt;/h3&gt;

&lt;p&gt;马老师和老逍都提到这个：我们是寻找同路人，而不是教育别人。这其实非常明晰地解释了为什么阿里要构建一个毛细血管网络一样的政委体系。基于这种用人理念，政委体系不敢说是最优解，但一定是优解（而且是否有更优解的论证没有意义）。&lt;/p&gt;

&lt;p&gt;对于个人，我的理解是要做两件事：&lt;strong&gt;1）构建自己的价值观体系（初始化）；2）寻找价值观契合的公司（做匹配）。这两点里，没有任何地方提到”你要改变价值观为了契合你所在的公司”。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;而企业价值观呢，其实可以分两部分看待：普世价值观、独特价值观。前者因为是普世的，所以到了哪个公司这种价值观都对，这点老逍也提了，比如“客户第一”。后者是个性化的，但不存在孰高孰低，就像一个人内向还是外向，你不能说哪个是错的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-4.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2021 年双十一 · 天天特卖团队&lt;/p&gt;

&lt;h3 id=&quot;价值观的本质意义极度务实视角是什么&quot;&gt;价值观的本质意义（极度务实视角）是什么？&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;在充分考虑价值观适配使命、愿景基础上，价值观本身的意义，在和风细雨时（即企业价值观与其他价值判断相 match 时），是看不到的。但在暴风骤雨时（即企业价值观与其他价值判断相冲突时），就能显示其实实在在的作用了。&lt;/strong&gt;我认为包括三类，前两个是阿里整体视角，第三个是阿里内部：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;经济体内，阿里与其他生态位的冲突或损益关系，如曾经的美蘑口一役。&lt;/li&gt;
  &lt;li&gt;经济体内，其他的生态位之间的冲突或损益关系，如曾经的十月围城。&lt;/li&gt;
  &lt;li&gt;阿里人的行为价值判断，如最近的钉钉代考事件、过往的各类廉政事件。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-5.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2021 年冬 · 淘宝天猫合并前合影&lt;/p&gt;

&lt;h3 id=&quot;landing的sop&quot;&gt;Landing 的 SOP&lt;/h3&gt;

&lt;p&gt;大家都说 landing 充满挑战，马老师其实给出了 landing 的 SOP 三部曲：&lt;strong&gt;一起打过仗、一起创过新、一起度过难。三个经历都 close 才算 smooth landing。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;集团人才策略层面、HR 实操层面、Leader 层面、，对于新人 landing 能做到什么程度的保障，其实每个新人感受到的不尽相同：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;集团层面，始终是在构建更好的新人 landing 环境的，这符合自身价值，这能打下很好的底子。&lt;/li&gt;
  &lt;li&gt;实操层面，包括面试阶段对候选人的价值观判断、预期管理，面试及入职后公司文化及人才体系的事实呈现、内化吸收和长期解惑。&lt;/li&gt;
  &lt;li&gt;Leader 层面，这是新人体感最强烈的部分，也是最重要的部分。尽管拥抱变化，但首先 Leader 需要给出尽可能最全面的考虑，其次是对候选人的预期管理。好的 Leader 会给候选人提供合理的着陆点、多个降落伞、缓冲垫，完成 smooth landing。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2020-06-11-captain-alibaba-6.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注：2021 年夏 · 出差厦漳泉&lt;/p&gt;

&lt;h3 id=&quot;问问自己来到阿里如果初期我可能需要做一点改变那会是什么&quot;&gt;问问自己，来到阿里，如果初期我可能需要做一点改变，那会是什么？&lt;/h3&gt;

&lt;p&gt;曾经个人的激情与动力，常来自于“增长”。常说&lt;strong&gt;高增长掩盖一切&lt;/strong&gt;，所以未来在阿里如果不能如创业般快速获得反馈得到积极结果，并且大平台中必然要接受大量关联方共同参与项目而导致的效率降低，因此我要逐渐改变自己，重新适应这种环境下的激情与动力获得方式。&lt;/p&gt;

&lt;p&gt;另一方面，作为创业公司的负责人，工作中鲜有因为内部原因而无法推进的事情，但是扮演肩部或腰部角色时，需要接受头部决策的一定程度不可控，这是我需要作出的适应与改变。关于这一点，我在几个月前就已经在做预期管理和心态调整，我认为以创业者的强适应性，这可能并不会是问题，但是我习惯于保持谨慎的乐观来面对自己。&lt;/p&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="thinking" /><category term="思考" /><summary type="html">2020 年的 6 月 4 日我入职阿里巴巴集团，7 天后的 6 月 11 日我写下了这篇文章。偶然翻到了当时这篇文章，遂转录于此，提醒自己勿忘初心。在不涉及到公司数据安全及商业机密问题的前提下，稍做了一些删改，发布在这里作为一个回顾。本次穿插了一些图片，当时写的时候还没有这些照片。本文内容包括：很多人是带着梦想来阿里的，那么我的梦想是什么呢？最喜欢新六脉的哪句话？为什么？关于阿里企业价值观：为什么要接受这套价值观？价值观的本质意义（极度务实视角）是什么？Landing 的 SOP；问问自己，来到阿里，如果初期我可能需要做一点改变，那会是什么？</summary></entry><entry><title type="html">麦克船长的 Jekyll 快速教程</title><link href="https://www.mikecaptain.com/2021/12/23/captains-jeckyll-learning/" rel="alternate" type="text/html" title="麦克船长的 Jekyll 快速教程" /><published>2021-12-23T19:43:02+00:00</published><updated>2021-12-23T19:43:02+00:00</updated><id>https://www.mikecaptain.com/2021/12/23/captains-jeckyll-learning</id><content type="html" xml:base="https://www.mikecaptain.com/2021/12/23/captains-jeckyll-learning/">&lt;ul&gt;
  &lt;li&gt;作者：麦克船长（钟超）&lt;/li&gt;
  &lt;li&gt;微信：sinosuperman&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;写在前面&quot;&gt;写在前面&lt;/h3&gt;

&lt;p&gt;Jekyll 是一个用 Ruby 实现的、使用 Liquid 模板引擎的静态网站生成器，它可以通过 Markdown 或者 HTML 等文件生成完整的静态网站。它特别适用于博客或者文章类的网站，因为可以自动生成博客的首页、分类页、标签页等等。因为使用 Liquid 引擎所以能在页面中使用变量、循环、条件语句等等，非常方便。虽然基于 Ruby 实现但使用起来并不需要掌握 Ruby，只需要了解一些基本的语法即可。&lt;/p&gt;

&lt;h3 id=&quot;part-1基本特点&quot;&gt;Part 1、基本特点&lt;/h3&gt;

&lt;h4 id=&quot;一基本语法&quot;&gt;一、基本语法&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;变量：用双大括号表示变量 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;麦克船长的技术、产品与商业博客&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;过滤器：可以使用过滤器对变量进行操作，例如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;麦克船长的技术、产品与商业博客&lt;/code&gt; 表示把网站的标题转换为大写。&lt;/li&gt;
  &lt;li&gt;支持循环与分支结构：比如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;for-endfor&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;if-elsif-else-endif&lt;/code&gt; ：可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fo-endfor&lt;/code&gt; 循环遍历列表或集合，例如 `````` 表示遍历网站的所有页面。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;二典型-jekyll-项目结构及重要文件介绍&quot;&gt;二、典型 Jekyll 项目结构及重要文件介绍&lt;/h4&gt;

&lt;h5 id=&quot;1配置文件-_configyml&quot;&gt;1、配置文件 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;首先看到下作为一个网站的基础设置，这里要特别注意不要遗漏 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;encoding: utf-8&lt;/code&gt; 这一条。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Site settings&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;utf-8&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;麦克船长的技术、产品与商业博客&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;麦克船长对于技术、产品、商业等领域的分享|AI,A.I.,NLP,神经网络,人工智能,自然语言处理,BERT,GPT,ChatGPT,OpenAI,阿里巴巴,P9,运营,淘宝,天猫,总监,高管&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://www.mikecaptain.com&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;author&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Your&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Name&quot;&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;https://www.mikecaptian.com&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后是 Markdown 引擎的设置，及其高亮语法 Rouge 部分。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Markdown and highlighter&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kramdown&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;highlighter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rouge&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;kramdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GFM&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;syntax_highlighter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rouge&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;一些要用到的插件也要设置进来，本博客只用到了基础插件两个。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Plugins&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll-paginate&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll-sitemap&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;另外构建项目的一些关键设置，比如文章放在哪里、如何进行分页（每页多少条文章）等等作为一个静态博客网站的 build 类设置都在此。&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build settings&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;baseurl&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Change this to your relative path (ex: /blog/), or leave just a /&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;destination&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./_site&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;permalink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/:title&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;paginate&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;paginate_path&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/page:num/&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;posts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;permalink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/:year/:month/:day/:title/&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;directory&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;_posts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;2布局文件_layouts-目录下的文件规则&quot;&gt;2、布局文件：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layouts&lt;/code&gt; 目录下的文件规则&lt;/h5&gt;

&lt;p&gt;Jekyll 的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layouts&lt;/code&gt; 目录包含了你的 Jekyll 站点中所使用的页面布局。每个页面布局是一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HTML&lt;/code&gt;模板，定义了你的站点中页面的框架和外观。你可以通过在你的文章或页面的头部添加一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;layout&lt;/code&gt; 字段来指定使用哪个布局来渲染该页面。&lt;/p&gt;

&lt;p&gt;布局文件通常包含用于渲染页面的常见元素，例如头部、尾部和侧边栏。你可以在布局文件中使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;include&lt;/code&gt; 语句来插入你的站点的其他文件，例如 header.html 和 footer.html 文件。这样，你就可以在一个地方维护站点的头部和尾部，而不必在每个页面中都进行更新。&lt;/p&gt;

&lt;h5 id=&quot;3页面文件及其头部&quot;&gt;3、页面文件及其头部&lt;/h5&gt;

&lt;p&gt;在一个页面的开头，用如下语法表示页面头部：&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;page&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;permalink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/categories/&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Categories&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;每个页面文件的头部都会有layout，并与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layouts&lt;/code&gt; 目录下的某个文件对应。&lt;/p&gt;

&lt;h3 id=&quot;part-2jekyll-中的全局变量&quot;&gt;Part 2、Jekyll 中的全局变量&lt;/h3&gt;

&lt;p&gt;Jekyll 中有许多全局变量可供使用，它们可以在模板中调用。这些变量提供了有关网站，页面，文章和其他内容的信息，可用于在模板中进行条件判断或显示信息。以下是 Jekyll 中常用的一些全局变量：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site&lt;/code&gt;：包含有关网站的信息，如网站标题，描述，域名等。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt;：包含有关当前页面的信息，如标题，内容，布局等。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;post&lt;/code&gt;：包含有关当前文章的信息，如标题，作者，日期等。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;content&lt;/code&gt;：包含当前页面或文章的内容。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paginator&lt;/code&gt;：包含有关分页的信息，如当前页码，总页数等。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tags&lt;/code&gt;：包含有关网站的所有标签的信息。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;related_posts&lt;/code&gt;：包含与当前文章有关的文章的信息。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些变量可以在模板中使用，比如：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;h1&amp;gt;&lt;/span&gt;{{ page.title }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;{{ site.description }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;ul&amp;gt;&lt;/span&gt;
  {{ for category in site.categories %}
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;li&amp;gt;&lt;/span&gt;{{ category }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/li&amp;gt;&lt;/span&gt;
  {{ endfor %}
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/ul&amp;gt;&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jekyll 还支持自定义全局变量，可以在配置文件 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 中添加任意的键值对，然后就可以在模板文件中使用这些变量了。例如，你可以在配置文件中添加如下内容：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;my_custom_variable&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Hello&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;World&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后就可以在模板文件中使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.my_custom_variable&lt;/code&gt; 访问这个自定义变量了。&lt;/p&gt;

&lt;h4 id=&quot;一site变量&quot;&gt;一、site变量&lt;/h4&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site&lt;/code&gt; 的数据结构里包含了所构建的网站的各种基本信息和结构。&lt;/p&gt;

&lt;h5 id=&quot;1sitecategories&quot;&gt;1、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.categories&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.categories&lt;/code&gt; 是一个 array，每个元素取出它的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;first&lt;/code&gt; 就是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;category&lt;/code&gt; 的名字，如下使用：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;2sitepages&quot;&gt;2、site.pages&lt;/h5&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.pages&lt;/code&gt; 是一个包含所有页面的数组，不仅包括根目录下的页面，还包括所有子目录下的页面。因此，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.pages&lt;/code&gt; 中包含的是整个网站中所有的页面。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{{ for page in site.pages %}
	{{ page.title }}
{{ endfor %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;3其他常用属性&quot;&gt;3、其他常用属性&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.title&lt;/code&gt;：是网站的标题。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.related_posts&lt;/code&gt;：相关文章的列表。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.data&lt;/code&gt;：从 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_data&lt;/code&gt; 目录加载的数据。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.static_files&lt;/code&gt;：静态文件的列表。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;site.collections&lt;/code&gt;：自定义集合的列表。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;二page-变量&quot;&gt;二、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt; 变量&lt;/h4&gt;

&lt;p&gt;在 Jekyll 中，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt; 变量表示单独页面的数据。它是一个包含多个属性的对象，可以用来存储页面的信息并在模板中使用。一些常见的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt; 变量属性包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;layout&lt;/code&gt;：表示页面使用的布局模板的名称。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;title&lt;/code&gt;：表示页面的标题。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;date&lt;/code&gt;：表示页面的发布日期。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categories&lt;/code&gt;：表示页面所属的分类列表。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tags&lt;/code&gt;：表示页面所属的标签列表。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;content&lt;/code&gt;：表示页面的内容（用 Markdown 格式书写）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在模板中，可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{{ page.属性名 }}&lt;/code&gt; 的方式来访问 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt; 变量的属性。例如，如果想在模板中输出页面的标题，可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{{ page.title }}&lt;/code&gt;。此外，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;page&lt;/code&gt; 变量还有其他属性，如 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;permalink&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;excerpt&lt;/code&gt;、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;url&lt;/code&gt; 等，可以根据需要调用。&lt;/p&gt;

&lt;h3 id=&quot;part-3控制结构&quot;&gt;Part 3、控制结构&lt;/h3&gt;

&lt;h4 id=&quot;1if-else-分支结构&quot;&gt;1、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;if-else&lt;/code&gt; 分支结构&lt;/h4&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{{ if tmp_var == &quot;type1&quot; %}
{{ elsif tmp_var == &quot;type2&quot; %}
{{ elsif tmp_var == &quot;type3&quot; %}
{{ elsif tmp_var == &quot;type4&quot; %}
{{ else tmp_var == &quot;type5&quot; %}
{{ endif %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;2for-endfor-循环结构&quot;&gt;2、&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;for-endfor&lt;/code&gt; 循环结构&lt;/h4&gt;

&lt;p&gt;不带条件判断的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;for&lt;/code&gt; 循环如下：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{{ for post in paginator.posts %}
	&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Your other sentences --&amp;gt;&lt;/span&gt;
{{ endfor %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;带条件循环的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;for&lt;/code&gt; 用 Jekyll 里的「过滤器」来实现：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{{ for page in site.pages | where: &quot;dir&quot;, &quot;categories&quot; %}
	{{ page.title }}
{{ endfor %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;3jekyll-支持的其他结构包括&quot;&gt;3、Jekyll 支持的其他结构包括：&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;case&lt;/code&gt; 用于在多个可能的条件中执行代码的结构。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;capture&lt;/code&gt; 用于捕获输出的结构。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cycle&lt;/code&gt; 用于循环一组字符串的结构。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;include&lt;/code&gt; 用于包含其他文件的结构。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unless&lt;/code&gt; 用于在不满足指定条件时执行代码的结构。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;while&lt;/code&gt; 用于在满足指定条件时执行代码的结构。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;参考&quot;&gt;参考：&lt;/h3&gt;

&lt;p&gt;1、&lt;a href=&quot;https://learn.cloudcannon.com/jekyll/list-posts-by-category/&quot;&gt;https://learn.cloudcannon.com/jekyll/list-posts-by-category/&lt;/a&gt;
2、&lt;a href=&quot;https://jekyllrb.com/docs/&quot;&gt;https://jekyllrb.com/docs/&lt;/a&gt;&lt;/p&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="web" /><category term="Jekyll" /><category term="Web" /><category term="前端" /><summary type="html">Jekyll 是一个用 Ruby 实现的、使用 Liquid 模板引擎的静态网站生成器，它可以通过 Markdown 或者 HTML 等文件生成完整的静态网站。它特别适用于博客或者文章类的网站，因为可以自动生成博客的首页、分类页、标签页等等。因为使用 Liquid 引擎所以能在页面中使用变量、循环、条件语句等等，非常方便。虽然基于 Ruby 实现但使用起来并不需要掌握 Ruby，只需要了解一些基本的语法即可 ……</summary></entry><entry><title type="html">如何使用 Jekyll 基于 Github Pages 搭建个人博客</title><link href="https://www.mikecaptain.com/2021/12/21/build-github-pages-with-jekyll/" rel="alternate" type="text/html" title="如何使用 Jekyll 基于 Github Pages 搭建个人博客" /><published>2021-12-21T15:53:57+00:00</published><updated>2021-12-21T15:53:57+00:00</updated><id>https://www.mikecaptain.com/2021/12/21/build-github-pages-with-jekyll</id><content type="html" xml:base="https://www.mikecaptain.com/2021/12/21/build-github-pages-with-jekyll/">&lt;p&gt;&lt;strong&gt;本文目录&lt;/strong&gt;&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#写在前面&quot; id=&quot;markdown-toc-写在前面&quot;&gt;写在前面&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#1github上的准备&quot; id=&quot;markdown-toc-1github上的准备&quot;&gt;1、GitHub 上的准备&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2了解ruby和jekyll&quot; id=&quot;markdown-toc-2了解ruby和jekyll&quot;&gt;2、了解 Ruby 和 Jekyll&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#3了解gem&quot; id=&quot;markdown-toc-3了解gem&quot;&gt;3、了解 Gem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#4安装homebrew&quot; id=&quot;markdown-toc-4安装homebrew&quot;&gt;4、安装 Homebrew&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#5用homebrew安装ruby&quot; id=&quot;markdown-toc-5用homebrew安装ruby&quot;&gt;5、用 Homebrew 安装 Ruby&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#6安装jekyll和bundler&quot; id=&quot;markdown-toc-6安装jekyll和bundler&quot;&gt;6、安装 Jekyll 和 Bundler&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#7使用bundle管理包依赖关系&quot; id=&quot;markdown-toc-7使用bundle管理包依赖关系&quot;&gt;7、使用 bundle 管理包依赖关系&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#8本地启动一下看看&quot; id=&quot;markdown-toc-8本地启动一下看看&quot;&gt;8、本地启动一下看看&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#9用jekyll创建一个项目&quot; id=&quot;markdown-toc-9用jekyll创建一个项目&quot;&gt;9、用 Jekyll 创建一个项目&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#10修改gemfile文件&quot; id=&quot;markdown-toc-10修改gemfile文件&quot;&gt;10、修改 Gemfile 文件&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#11配置githubpages&quot; id=&quot;markdown-toc-11配置githubpages&quot;&gt;11、配置 Github Pages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#12配置一个jekylltheme&quot; id=&quot;markdown-toc-12配置一个jekylltheme&quot;&gt;12、配置一个 Jekyll Theme&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#13设置自定义域名&quot; id=&quot;markdown-toc-13设置自定义域名&quot;&gt;13、设置自定义域名&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#14用-rouge-实现代码高亮&quot; id=&quot;markdown-toc-14用-rouge-实现代码高亮&quot;&gt;14、用 rouge 实现代码高亮&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#15一些扩展问题&quot; id=&quot;markdown-toc-15一些扩展问题&quot;&gt;15、一些扩展问题&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#q1我想在网站的首页的每一篇文章标题下显示一个指定的摘要而不是自动从文章内容开头截取的应该如何实现呢&quot; id=&quot;markdown-toc-q1我想在网站的首页的每一篇文章标题下显示一个指定的摘要而不是自动从文章内容开头截取的应该如何实现呢&quot;&gt;Q1：我想在网站的首页的每一篇文章标题下，显示一个指定的摘要，而不是自动从文章内容开头截取的，应该如何实现呢？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q2如何支持对每一个分类都可以显示一个该分类下的所有文章的页面&quot; id=&quot;markdown-toc-q2如何支持对每一个分类都可以显示一个该分类下的所有文章的页面&quot;&gt;Q2：如何支持对每一个分类都可以显示一个该分类下的所有文章的页面？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q3如何为每篇文章添加一个目录&quot; id=&quot;markdown-toc-q3如何为每篇文章添加一个目录&quot;&gt;Q3：如何为每篇文章添加一个目录&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q4如何在-jekyll-中支持-katex&quot; id=&quot;markdown-toc-q4如何在-jekyll-中支持-katex&quot;&gt;Q4：如何在 Jekyll 中支持 KaTeX&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#在-githubio-上&quot; id=&quot;markdown-toc-在-githubio-上&quot;&gt;在 GitHub.io 上&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#本问题参考&quot; id=&quot;markdown-toc-本问题参考&quot;&gt;本问题参考：&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#如果不在-githubio-上则还需要额外工作&quot; id=&quot;markdown-toc-如果不在-githubio-上则还需要额外工作&quot;&gt;如果不在 GitHub.io 上，则还需要额外工作&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#使用示例&quot; id=&quot;markdown-toc-使用示例&quot;&gt;使用示例&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q5jekyll-中如何支持-graphviz-&quot; id=&quot;markdown-toc-q5jekyll-中如何支持-graphviz-&quot;&gt;Q5：Jekyll 中如何支持 Graphviz ？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#本地-jekyll-先运行起来-graphviz&quot; id=&quot;markdown-toc-本地-jekyll-先运行起来-graphviz&quot;&gt;本地 Jekyll 先运行起来 Graphviz&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#github-pages-上正常显示-graphviz&quot; id=&quot;markdown-toc-github-pages-上正常显示-graphviz&quot;&gt;Github Pages 上正常显示 Graphviz&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#本问题参考-1&quot; id=&quot;markdown-toc-本问题参考-1&quot;&gt;本问题参考：&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#q6如何显示--或者--&quot; id=&quot;markdown-toc-q6如何显示--或者--&quot;&gt;Q6：如何显示 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{%&lt;/code&gt; 或者 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{{&lt;/code&gt; ？&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;写在前面&quot;&gt;写在前面&lt;/h3&gt;

&lt;p&gt;GitHub Pages 是 GitHub 提供的免费托管静态网站的服务。使用 GitHub Pages 搭建博客，然后使用 Jekyll 生成的静态网站文件上传到该仓库。花 10 分钟时间，通过本文让你快速地实现了一个免费、简单、快速、安全、支持版本控制、支持自定义域名的独立域名博客。这样实现的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;免费&lt;/strong&gt;：GitHub Pages 允许用户免费使用其托管静态网站。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;简单&lt;/strong&gt;：Jekyll 是一个轻量级的静态网站生成器，它使用简单的 Markdown 格式写文章，不需要数据库或者后端语言的支持。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;快速&lt;/strong&gt;：由于 Jekyll 生成的网站是静态的，所以可以通过 CDN 加速访问速度。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;安全&lt;/strong&gt;：由于 Jekyll 生成的网站是静态的，所以不存在脚本攻击、SQL 注入等安全问题。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;版本控制&lt;/strong&gt;：GitHub 提供了强大的版本控制功能，你可以使用 Git 记录每一次修改，方便查看和回滚。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;自定义域名&lt;/strong&gt;：你可以在仓库的设置页面中自定义域名，让你的博客更专业和个性化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用 Jekyll 和 GitHub Pages 搭建博客，你可以快速、简单、免费地拥有一个个人博客，并且可以享受到较高的安全性、版本控制和自定义域名的优势。&lt;/p&gt;

&lt;p&gt;本文涉及到 macOS 命令行的一点点基础，以及 git 版本控制软件、Web 前端的一点点基础，但是船长会尽量浅显地写在本文，避免太多其他依赖。&lt;/p&gt;

&lt;h3 id=&quot;1github上的准备&quot;&gt;1、GitHub 上的准备&lt;/h3&gt;

&lt;p&gt;在 Github 上创建一个新的仓库，命名为「账户名.github.io」。然后将仓库拉取到本地：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git clone https://github.com/username/username.github.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;创建一些 web 文件后再推到 Github 上就可以了：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git add &lt;span class=&quot;nt&quot;&gt;--all&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Initial commit&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git push &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; origin main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2了解ruby和jekyll&quot;&gt;2、了解 Ruby 和 Jekyll&lt;/h3&gt;

&lt;p&gt;Ruby 目前业界的主要应用都在 Web 开发领域，有不少框架，比如 Ruby on Rails、Sinatra、Padrino. 我们这里要用到的 Jekyll 是用 Ruby 实现的一个构建静态网站的工具，用 HTML 和 Markdown 作为源码，再通过布局和模板生成网页文件。&lt;/p&gt;

&lt;p&gt;Jekyll 特别适合构建博客，支持标签、分类、搜索，并支持自定义模板和布局。&lt;/p&gt;

&lt;h3 id=&quot;3了解gem&quot;&gt;3、了解 Gem&lt;/h3&gt;

&lt;p&gt;Gem 是 Ruby 常用的一个管理库的工具，类似于 Pip 是 Python 常用的一个管理库的工具。&lt;/p&gt;

&lt;p&gt;为 Gem 配置国内的源，这样访问速度更快：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem sources --add https://mirrors.tuna.tsinghua.edu.cn/rubygems/ --remove https://rubygems.org/
gem sources -l
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4安装homebrew&quot;&gt;4、安装 Homebrew&lt;/h3&gt;

&lt;p&gt;Homebrew 是一个专门为 macOS 设计的开源软件包管理工具，熟悉 Linux 的朋友可以把 Homebrew 理解成 macOS 的 apt-get。先安装 Homebrew：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;/bin/bash &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-fsSL&lt;/span&gt; https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;为了让 Homebrew 在国内安装快一些，可以替换下镜像源：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;以上用的是阿里云的源，也可以用网易的源：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;export HOMEBREW_BOTTLE_DOMAIN=http://mirrors.163.com/homebrew/bottles&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Homebrew 安装、卸载软件的命令都很简单，brew install wget和brew uninstall wget。&lt;/p&gt;

&lt;h3 id=&quot;5用homebrew安装ruby&quot;&gt;5、用 Homebrew 安装 Ruby&lt;/h3&gt;

&lt;p&gt;用 Homebrew 安装 chruby 和 ruby-install&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;brew &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;chruby ruby-install xz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安装 Ruby 的最新版本：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ruby-install ruby
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这时候提示如下问题：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; Updating ruby versions ...
&lt;span class=&quot;o&quot;&gt;!!!&lt;/span&gt; Failed to download https://raw.githubusercontent.com/postmodern/ruby-versions/master/ruby/versions.txt &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
to /Users/captain/.cache/ruby-install/ruby/versions.txt!
&lt;span class=&quot;o&quot;&gt;!!!&lt;/span&gt; Failed to download ruby versions!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;因为 raw.githubusercontent.com 在国内是被 blocked，所以用https://www.ipaddress.com查一下 IP 地址，然后修改下/etc/hosts：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ echo &quot;185.199.111.133 raw.githubusercontent.com&quot; &amp;gt;&amp;gt; /etc/hosts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后再运行ruby-install ruby就可以正常安装了，这个过程会非常的慢，安装完成后，配置 zsh 脚本的 .zshrc 文件以便后续可以使用 chruby：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;source &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;brew &lt;span class=&quot;nt&quot;&gt;--prefix&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/opt/chruby/share/chruby/chruby.sh&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.zshrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;source &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;brew &lt;span class=&quot;nt&quot;&gt;--prefix&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/opt/chruby/share/chruby/auto.sh&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.zshrc
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;chruby ruby-3.1.2&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.zshrc &lt;span class=&quot;c&quot;&gt;# run &apos;chruby&apos; to see actual version&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;再看下 Ruby 版本对不对：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ruby &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jekyll 官网要求 Ruby 版本大于 3.1.2p20.&lt;/p&gt;

&lt;h3 id=&quot;6安装jekyll和bundler&quot;&gt;6、安装 Jekyll 和 Bundler&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;jekyll bundler
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面顺便安装了 Bundler，Bundler 是 Ruby 常用的管理项目依赖关系的工具，类似于 virtualenv 之于 Python，可以简化项目的包依赖管理，帮你维护一份 Gemfile 文件，里面包含了所有依赖关系。这个工具的名字叫 Bundler，使用的时候都是用这个词的动词 bundle 命令。&lt;/p&gt;

&lt;h3 id=&quot;7使用bundle管理包依赖关系&quot;&gt;7、使用 bundle 管理包依赖关系&lt;/h3&gt;

&lt;p&gt;创建 Gemfile 文件，Gemfile 是 Ruby 项目的依赖包管理文件：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;https://rubygems.org&apos;&lt;/span&gt;
gem &lt;span class=&quot;s1&quot;&gt;&apos;nokogiri&apos;&lt;/span&gt;
gem &lt;span class=&quot;s1&quot;&gt;&apos;rack&apos;&lt;/span&gt;, &lt;span class=&quot;s1&quot;&gt;&apos;~&amp;gt; 2.2.4&apos;&lt;/span&gt;
gem &lt;span class=&quot;s1&quot;&gt;&apos;rspec&apos;&lt;/span&gt;
gem &lt;span class=&quot;s1&quot;&gt;&apos;jekyll&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后安装依赖包，这里默认会根据运行命令时所在的目录的 Gemfile 来安装：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bundle &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Gemfile.lock 是 Gemfile 的锁定版本，记录了当前项目所使用的所有依赖包的版本信息。下面把这两个文件都加入到 Git 版本控制中。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git add Gemfile Gemfile.lock
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;8本地启动一下看看&quot;&gt;8、本地启动一下看看&lt;/h3&gt;

&lt;p&gt;先用 bundle 如下命令来启动：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动日志如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Configuration file: none
            Source: /Users/captain/Workspace/poechant.github.io
       Destination: /Users/captain/Workspace/poechant.github.io/_site
 Incremental build: disabled. Enable with --incremental
      Generating... 
                    done in 0.014 seconds.
 Auto-regeneration: enabled for &apos;/Users/captain/Workspace/poechant.github.io&apos;
    Server address: http://127.0.0.1:4000
  Server running... press ctrl-c to stop.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后打开浏览器输入http://localhost:4000看看效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-21-build-github-pages-with-jekyll-1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这就说明 Jekyll 本地配置已经成功了。然后把当前的版本同步到 Git 上：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git pull &lt;span class=&quot;nt&quot;&gt;--no-rebase&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git push &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; origin main
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;9用jekyll创建一个项目&quot;&gt;9、用 Jekyll 创建一个项目&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll new CaptainMikeBlog
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;CaptainMikeBlog
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;启动日志如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Configuration file: /Users/captain/Workspace/poechant.github.io/CaptainMikeBlog/_config.yml
            Source: /Users/captain/Workspace/poechant.github.io/CaptainMikeBlog
       Destination: /Users/captain/Workspace/poechant.github.io/CaptainMikeBlog/_site
 Incremental build: disabled. Enable with --incremental
      Generating... 
       Jekyll Feed: Generating feed for posts
                    done in 0.365 seconds.
 Auto-regeneration: enabled for &apos;/Users/captain/Workspace/poechant.github.io/CaptainMikeBlog&apos;
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;再打开浏览器输入http://localhost:4000看看效果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/src/2022-12-21-build-github-pages-with-jekyll-2.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;10修改gemfile文件&quot;&gt;10、修改 Gemfile 文件&lt;/h3&gt;

&lt;p&gt;注释掉gem ”jekyll”开头的这一行，修改# gem ”github-pages”开头的这一行为：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gem &lt;span class=&quot;s2&quot;&gt;&quot;github-pages&quot;&lt;/span&gt;, &lt;span class=&quot;s2&quot;&gt;&quot;~&amp;gt; GITHUB-PAGES-VERSION&quot;&lt;/span&gt;, group: :jekyll_plugins
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中的GITHUB-PAGES-VERSION改为具体的版本号，版本号参考https://pages.github.com/versions/，我写本文的时候github-pages最新版本号是227。关闭 Gemfile 文件然后命令行运行如下命令：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bundle install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;再本地启动服务器测试：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;jekyll server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;得到如下提示：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;You have already activated i18n 1.12.0, but your Gemfile requires i18n 0.9.5.
Prepending &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;bundle &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt; to your &lt;span class=&quot;nb&quot;&gt;command &lt;/span&gt;may solve this. &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;Gem::LoadError&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;参考https://github.com/Homebrew/brew.sh/issues/845这个 issue 后如下解决：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bundle add webrick
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;bundle &lt;span class=&quot;nb&quot;&gt;exec &lt;/span&gt;jekyll serve
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这里注意jekyll server和bundle exec jekyll serve两个的区别是前者基本本地 Jekyll 版本启动服务，后者基于目录下的 Gemfile 文件启动服务，所以我们要用后者。&lt;/p&gt;

&lt;h3 id=&quot;11配置githubpages&quot;&gt;11、配置 Github Pages&lt;/h3&gt;

&lt;p&gt;在 Github 的仓库页面进入「Settings - Code and Automation - Pages - Build and Deploy」，选择「Deploy from a branch」，然后选择你设定的分支。再选发布源的文件夹，这里我设置为根目录。然后「保存」。再修改 _config.yml 文件：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;baseurl: &quot;&quot;
url: &quot;http://your-username.github.io&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;将本地代码push到 Github 仓库中，在浏览器访问your-username.github.io即可，有时候可能要等几分钟。&lt;/p&gt;

&lt;h3 id=&quot;12配置一个jekylltheme&quot;&gt;12、配置一个 Jekyll Theme&lt;/h3&gt;

&lt;p&gt;可以在http://jekyllthemes.org/这个网站上找一下喜欢的 theme，下载后将如下文件都 copy 到你项目目录下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;_includes
_layouts
_sass
css
js
img
404.markdown
index.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;不同主题会有所不同，这里只列个大概。&lt;/p&gt;

&lt;h3 id=&quot;13设置自定义域名&quot;&gt;13、设置自定义域名&lt;/h3&gt;

&lt;p&gt;添加四条 A 记录，记录值如下：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;185.199.108.153
185.199.109.153
185.199.110.153
185.199.111.153
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;添加 CNAME，主机记录为www，记录值为your-username.github.io。然后在「Github 你的仓库里 - Settings - Pages - Custom Domain」填写你刚使用的域名，并把Enforce HTTPS打上勾。&lt;/p&gt;

&lt;p&gt;一旦解析成功，Github 上会自动多一个 CNAME 文件。把你最新的代码都 push 到 Github 仓库上，稍等片刻就可以从你自己的域名访问 Github Pages 搭建的博客啦。&lt;/p&gt;

&lt;h3 id=&quot;14用-rouge-实现代码高亮&quot;&gt;14、用 rouge 实现代码高亮&lt;/h3&gt;

&lt;p&gt;我们用支持 Markdown 内代码语法高亮的 Rouge 来实现，首先安装 Rouge：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem install kramdom rouge
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后配置 _config.yml 文件：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kramdown&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;highlighter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rouge&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;kramdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GFM&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;syntax_highlighter&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;rouge&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后用 rouge 创建 syntax.css 文件：&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rougify style github &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; css/syntax.css
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_include/head.html&lt;/code&gt; 文件中添加：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stylesheet&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/css/syntax.css&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;15一些扩展问题&quot;&gt;15、一些扩展问题&lt;/h3&gt;

&lt;h4 id=&quot;q1我想在网站的首页的每一篇文章标题下显示一个指定的摘要而不是自动从文章内容开头截取的应该如何实现呢&quot;&gt;Q1：我想在网站的首页的每一篇文章标题下，显示一个指定的摘要，而不是自动从文章内容开头截取的，应该如何实现呢？&lt;/h4&gt;

&lt;p&gt;在 Jekyll 中，你可以在每篇文章的 front matter 中设置摘要字段。例如，你可以在文章的 front matter 中添加一个 excerpt 字段，然后在该字段中填入你想要在首页显示的摘要内容。&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;这是一篇文章&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;excerpt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;这是文章的摘要&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;

这是文章的正文内容
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后，在你的首页模板中，你可以使用``输出文章的摘要。例如：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;ul&amp;gt;&lt;/span&gt;
  {% for post in paginator.posts %}
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;li&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;h2&amp;gt;&amp;lt;a&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{{ post.url }}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;{{ post.title }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/a&amp;gt;&amp;lt;/h2&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;{{ post.excerpt }}&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/li&amp;gt;&lt;/span&gt;
  {% endfor %}
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/ul&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样，在首页显示文章列表时，每篇文章就会带上它的摘要内容。&lt;/p&gt;

&lt;p&gt;注意，如果文章的 excerpt 字段没有设置，那么在首页显示时就不会有摘要内容。因此，建议在发布新文章时务必检查 excerpt 字段是否已经设置。&lt;/p&gt;

&lt;h4 id=&quot;q2如何支持对每一个分类都可以显示一个该分类下的所有文章的页面&quot;&gt;Q2：如何支持对每一个分类都可以显示一个该分类下的所有文章的页面？&lt;/h4&gt;

&lt;p&gt;有很多种办法，但是这里我讲一个比较简单且容易维护的方法，不过也有其弊端。首先在&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layouts&lt;/code&gt;目录下创建一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;category.html&lt;/code&gt;文件：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
layout: default
---

&lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;container&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;br&amp;gt;&lt;/span&gt;
    {% if site.categories[page.category] %}
      {% for post in site.categories[page.category] %}
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;a&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{% if site.baseurl == &quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;/&quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;%}{{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;post.url&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}{%&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;%}{{&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;post.url&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;prepend:&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;site.baseurl&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}}{%&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;endif&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;%}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            {%if post.header %}{{ post.header }}{% else %}{{ post.title }}{% endif %}
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt;
      {% endfor %}
    {% else %}
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;br&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;p&amp;gt;&lt;/span&gt;No posts for this category. If you have something in mind, check &lt;span class=&quot;nt&quot;&gt;&amp;lt;a&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/write&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Write For Us&lt;span class=&quot;nt&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt;page.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
    {% endif %}
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样就有了一个可以显示某个 category 下的所有 posts 的布局文件了。然后修改&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;文件：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;_categories&apos;&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在根目录创建一个&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categories&lt;/code&gt;目录，并在里面对每个 category 分别创建一个 html 文件，文件名即 category 的名字。但这个文件特别的简单，就是只需要写一个头部，例如我的「AI」分类的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ai.html&lt;/code&gt;如下：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;layout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;category&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;人工智能&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;This is the description.&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;permalink&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/category/ai&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ai&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;category_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;tech&lt;/span&gt;
&lt;span class=&quot;nn&quot;&gt;---&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;那么之后每次创建文件时，在头部写&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;category&lt;/code&gt;一定要与这些&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;categories&lt;/code&gt;中的&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;html&lt;/code&gt;文件对应起来。&lt;/p&gt;

&lt;h4 id=&quot;q3如何为每篇文章添加一个目录&quot;&gt;Q3：如何为每篇文章添加一个目录&lt;/h4&gt;

&lt;p&gt;这个是 Markdown 可以解决的，并不涉及 Jekyll，对于 Jekyll 的 Markdown 引擎可以用如下极其简单的方式实现：&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; TOC
{:toc}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;q4如何在-jekyll-中支持-katex&quot;&gt;Q4：如何在 Jekyll 中支持 KaTeX&lt;/h4&gt;

&lt;p&gt;Katex 是一个开源的 JavaScript 库，能够在浏览器端快速渲染 LaTeX 格式的数学公式。&lt;/p&gt;

&lt;h5 id=&quot;在-githubio-上&quot;&gt;在 GitHub.io 上&lt;/h5&gt;

&lt;p&gt;先修改 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;kramdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;math_engine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;katex&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;然后修改 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_includes/head.html&lt;/code&gt; 文件，在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;head&amp;gt;&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;/head&amp;gt;&lt;/code&gt; 中间：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!--KaTeX--&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;link&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;rel=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stylesheet&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;integrity=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;crossorigin=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anonymous&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;defer&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;integrity=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;crossorigin=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anonymous&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;script &lt;/span&gt;&lt;span class=&quot;na&quot;&gt;defer&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;src=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;integrity=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;crossorigin=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;anonymous&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;addEventListener&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;DOMContentLoaded&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;renderMathInElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;c1&quot;&gt;// ...options...&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;本问题参考&quot;&gt;本问题参考：&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.xuningyang.com/blog/2021-01-11-katex-with-jekyll/&quot;&gt;https://www.xuningyang.com/blog/2021-01-11-katex-with-jekyll/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;如果不在-githubio-上则还需要额外工作&quot;&gt;如果不在 GitHub.io 上，则还需要额外工作&lt;/h5&gt;

&lt;p&gt;以上方式只适合于 GitHub.io 的网站，如果是自己搭建的网站用 Jekyll 则要自己安装，如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;kramdom-math-katex

gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;katex
gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;execjs

gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;therubyracer
gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;therubyrhino
gem &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;duktape
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;使用示例&quot;&gt;使用示例&lt;/h5&gt;

&lt;p&gt;以如下方式输入输入如下内容：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% raw %}
$$ \sum_{i=1}^{n} a_i $$
{% endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;就会得到一个数学公式：&lt;/p&gt;

\[\sum_{i=1}^{n} a_i\]

&lt;h4 id=&quot;q5jekyll-中如何支持-graphviz-&quot;&gt;Q5：Jekyll 中如何支持 Graphviz ？&lt;/h4&gt;

&lt;h4 id=&quot;本地-jekyll-先运行起来-graphviz&quot;&gt;本地 Jekyll 先运行起来 Graphviz&lt;/h4&gt;

&lt;p&gt;这要依赖 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll-graphviz&lt;/code&gt;，修改 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Gemfile&lt;/code&gt; 增加一句：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;group :jekyll_plugins &lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;gem &lt;span class=&quot;s2&quot;&gt;&quot;jekyll-graphviz&quot;&lt;/span&gt;
end
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;再修改 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 配置文件：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;plugins&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;jekyll-graphviz&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;再在本地安装 graphviz，可以通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda install graphviz&lt;/code&gt; 或者 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;brew install graphviz&lt;/code&gt;。然后 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle install&lt;/code&gt; 再 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bundle exec jekyll serve&lt;/code&gt; 在本地下一段看看效果：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-graphviz&quot;&gt;{% graph some graph title %}
digraph G {
    a -&amp;gt; b
    b -&amp;gt; c
    c -&amp;gt; a
}
{% endgraph %}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果看到如下效果，就说明你都配置成功了：&lt;/p&gt;

&lt;div class=&quot;graphviz-wrapper&quot;&gt;

&lt;!-- Generated by graphviz version 2.43.0 (0)
 --&gt;
&lt;!-- Title: G Pages: 1 --&gt;
&lt;svg role=&quot;img&quot; aria-label=&quot;some graph title&quot; width=&quot;89pt&quot; height=&quot;188pt&quot; viewBox=&quot;0.00 0.00 89.00 188.00&quot;&gt;
&lt;title&gt;some graph title&lt;/title&gt;
&lt;desc&gt;
digraph G {
    a -&amp;gt; b
    b -&amp;gt; c
    c -&amp;gt; a
}
&lt;/desc&gt;

&lt;g id=&quot;graph0&quot; class=&quot;graph&quot; transform=&quot;scale(1 1) rotate(0) translate(4 184)&quot;&gt;
&lt;title&gt;G&lt;/title&gt;
&lt;polygon fill=&quot;white&quot; stroke=&quot;transparent&quot; points=&quot;-4,4 -4,-184 85,-184 85,4 -4,4&quot; /&gt;
&lt;!-- a --&gt;
&lt;g id=&quot;node1&quot; class=&quot;node&quot;&gt;
&lt;title&gt;a&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;54&quot; cy=&quot;-162&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;54&quot; y=&quot;-158.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;a&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b --&gt;
&lt;g id=&quot;node2&quot; class=&quot;node&quot;&gt;
&lt;title&gt;b&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;27&quot; cy=&quot;-90&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;27&quot; y=&quot;-86.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;b&lt;/text&gt;
&lt;/g&gt;
&lt;!-- a&amp;#45;&amp;gt;b --&gt;
&lt;g id=&quot;edge1&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;a&amp;#45;&amp;gt;b&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03&quot; /&gt;
&lt;/g&gt;
&lt;!-- c --&gt;
&lt;g id=&quot;node3&quot; class=&quot;node&quot;&gt;
&lt;title&gt;c&lt;/title&gt;
&lt;ellipse fill=&quot;none&quot; stroke=&quot;black&quot; cx=&quot;54&quot; cy=&quot;-18&quot; rx=&quot;27&quot; ry=&quot;18&quot; /&gt;
&lt;text text-anchor=&quot;middle&quot; x=&quot;54&quot; y=&quot;-14.3&quot; font-family=&quot;Times,serif&quot; font-size=&quot;14.00&quot;&gt;c&lt;/text&gt;
&lt;/g&gt;
&lt;!-- b&amp;#45;&amp;gt;c --&gt;
&lt;g id=&quot;edge2&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;b&amp;#45;&amp;gt;c&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55&quot; /&gt;
&lt;/g&gt;
&lt;!-- c&amp;#45;&amp;gt;a --&gt;
&lt;g id=&quot;edge3&quot; class=&quot;edge&quot;&gt;
&lt;title&gt;c&amp;#45;&amp;gt;a&lt;/title&gt;
&lt;path fill=&quot;none&quot; stroke=&quot;black&quot; d=&quot;M57.65,-36.09C59.68,-46.43 61.98,-59.91 63,-72 64.34,-87.94 64.34,-92.06 63,-108 62.28,-116.5 60.93,-125.69 59.49,-133.99&quot; /&gt;
&lt;polygon fill=&quot;black&quot; stroke=&quot;black&quot; points=&quot;56.03,-133.44 57.65,-143.91 62.91,-134.71 56.03,-133.44&quot; /&gt;
&lt;/g&gt;
&lt;/g&gt;
&lt;/svg&gt;
&lt;/div&gt;

&lt;h4 id=&quot;github-pages-上正常显示-graphviz&quot;&gt;Github Pages 上正常显示 Graphviz&lt;/h4&gt;

&lt;p&gt;因为 GitHub Pages 默认并不支持 Graphviz 插件，所以还需要如下处理：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在 Github 上创建一个分支，可以叫做 gh-pages&lt;/li&gt;
  &lt;li&gt;配置 Github Pages 的生成来自分支 gh-pages 并且选择目录为 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&lt;/code&gt; 根目录&lt;/li&gt;
  &lt;li&gt;在本地项目中创建一个文件 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.github/workflows/gh-pages.yml&lt;/code&gt;，内容如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Build and deploy Jekyll site to GitHub Pages&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;branches&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;master&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;jobs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;jekyll&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;runs-on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ubuntu-latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;📂 setup&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;actions/checkout@v2&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Setup Graphviz&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ts-graphviz/setup-graphviz@v1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;💎 setup ruby&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ruby/setup-ruby@v1&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;ruby-version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3.0.2&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;🔨 install dependencies &amp;amp; build site&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;limjh16/jekyll-action-ts@v2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;NODE_ENV&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;production&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;enable_cache&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;🚀 deploy&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;uses&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;peaceiris/actions-gh-pages@v3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;with&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;github_token&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;$&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;publish_dir&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;./_site&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;publish_branch&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;gh-pages&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;cname&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;www.mikecaptain.com&lt;/span&gt;
          &lt;span class=&quot;na&quot;&gt;enable_jekyll&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果你遇到了生成的网站中所有 URL 都带着 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pages/username&lt;/code&gt;，那么这个问题修改 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 即可：&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;baseurl&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Change this to your relative path (ex: /blog/), or leave just a /&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;本问题参考-1&quot;&gt;本问题参考：&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/DerekStride/jekyll-graphviz&quot;&gt;https://github.com/DerekStride/jekyll-graphviz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;q6如何显示--或者--&quot;&gt;Q6：如何显示 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{%&lt;/code&gt; 或者 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{{&lt;/code&gt; ？&lt;/h4&gt;

&lt;p&gt;其实也是一个字符转义的问题，我们直接面对一个在 StackOverflow 上会被问的终极 Jekyll 中 Markdown 转义问题（与 Liquid Template Tags 冲突的问题），如何实现显示 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% raw %}&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% endraw %}&lt;/code&gt; 呢？方法如下：&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% raw %}{%{% endraw %} raw %}
{% raw %}{%{% endraw %} endraw %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如上，就是用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% raw %}&lt;/code&gt; 和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{% endraw %}&lt;/code&gt; 把 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{%&lt;/code&gt; 包起来，但是 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%}&lt;/code&gt; 不用包。应该讲的很清楚了吧。&lt;/p&gt;

&lt;h3 id=&quot;参考&quot;&gt;参考&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://bundler.io&quot;&gt;https://bundler.io&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jekyllrb.com/docs/&quot;&gt;https://jekyllrb.com/docs/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87225594&quot;&gt;https://zhuanlan.zhihu.com/p/87225594&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://chat.openai.com/chat&quot;&gt;https://chat.openai.com/chat&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/creating-a-github-pages-site-with-jekyll&quot;&gt;https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/creating-a-github-pages-site-with-jekyll&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.github.com/zh/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site&quot;&gt;https://docs.github.com/zh/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/dyutibarma/monochrome&quot;&gt;https://github.com/dyutibarma/monochrome&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.github.com/zh/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-a-subdomain&quot;&gt;https://docs.github.com/zh/pages/configuring-a-custom-domain-for-your-github-pages-site/managing-a-custom-domain-for-your-github-pages-site#configuring-a-subdomain&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.seanbuscay.com/blog/jekyll-toc-markdown/&quot;&gt;http://www.seanbuscay.com/blog/jekyll-toc-markdown/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Poechant</name><email>zhongchao.ustc@gmail.com</email></author><category term="web" /><category term="Jekyll" /><category term="Github Pages" /><category term="前端" /><summary type="html">GitHub Pages 是 GitHub 提供的免费托管静态网站的服务。使用 GitHub Pages 搭建博客，然后使用 Jekyll 生成的静态网站文件上传到该仓库。花 10 分钟时间，通过本文让你快速地实现了一个免费、简单、快速、安全、支持版本控制、支持自定义域名的独立域名博客 ……</summary></entry></feed>