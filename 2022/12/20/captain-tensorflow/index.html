<!DOCTYPE html>
<html>

<head>
	<!-- Meta -->
	<meta charset="UTF-8"/>
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
	<meta name="generator" content="Jekyll">

	<title>麦克船长 TensorFlow 技术笔记</title>
  	<meta name="description" content="麦克船长对于技术、产品、商业等领域的分享|AI,A.I.,NLP,神经网络,人工智能,自然语言处理,BERT,GPT,ChatGPT,OpenAI,阿里巴巴,P9,运营,淘宝,天猫,总监,高管">

	<!-- CSS & fonts -->
	<link rel="stylesheet" href="/css/main.css">

	<!-- RSS -->
	<link href="/atom.xml" type="application/atom+xml" rel="alternate" title="ATOM Feed" />

  	<!-- Favicon -->
 	 <link rel="shortcut icon" type="image/png" href="/img/favicon.png">

 	 <!-- Syntax highlighter -->
  	<link rel="stylesheet" href="/css/syntax.css" />

  	<!--KaTeX-->
  	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
  	<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
  	<script>
  		document.addEventListener("DOMContentLoaded", function() {
  			renderMathInElement(document.body, {
  				// ...options...
  			});
  		});
  	</script>

  	
  	<!-- KaTeX -->
  	<link rel="stylesheet" href="/assets/plugins/katex.0.11.1/katex.min.css">
  	

  	
  		<script async src="https://www.googletagmanager.com/gtag/js?id=G-CH4708X4R5"></script>
  		<script>
    		window.dataLayer = window.dataLayer || [];
    		function gtag(){dataLayer.push(arguments);}
    		gtag('js', new Date());

    		gtag('config', 'G-CH4708X4R5');
  		</script>
	


</head>

<body>
	<div id="wrap">
	  	
	  	<!-- Navigation -->
	  	<nav id="nav">
	<div id="nav-list">
		<a href="/">Home</a>

		<!-- Nav pages -->
	  <!-- 
	    
	  
	    
	      <a href="/about/" title="关于我">关于我</a>
	    
	  
	    
	  
	    
	  
	    
	      <a href="/booklist/" title="读书行路">读书行路</a>
	    
	  
	    
	  
	    
	  
	    
	  
	    
	      <a href="/categories/" title="Categories">Categories</a>
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	  
	    
	   -->

	  <!-- Tech category pages -->






  <a href="/category/ai" title="人工智能">人工智能</a>











  <a href="/category/energy" title="能源">能源</a>









  <a href="/category/rt_tech" title="实时技术">实时技术</a>





  <a href="/category/web" title="前端">前端</a>














<!-- Non-tech category pages -->












  <a href="/category/business" title="商业">商业</a>



  <a href="/category/design" title="设计">设计</a>













  <a href="/category/thinking" title="思考与生活">思考与生活</a>















	  
        
      
        
          <a href="/about/" title="关于我">关于我</a>
        
      
        
      
        
      
        
          <a href="/booklist/" title="读书行路">读书行路</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    <!-- Nav links -->
	  <!-- <a href="https://github.com/thereviewindex/monochrome/archive/master.zip">Download</a>
<a href="https://github.com/thereviewindex/monochrome">Project on Github</a> -->

	</div>
  
  <!-- Nav footer -->
	
	  <footer>
	
	<span>version 1.0.0</span>

</footer>
	

</nav>

    
    <!-- Icon menu -->
	  <a id="nav-menu">
	  	<div id="menu"></div>
	  </a>

      <!-- Header -->
      
        <header id="header" class="parent justify-spaceBetween">
  <div class="inner w100 relative">
    <span class="f-left">  
      <a href="/">
        <h1>
          <span>Mike</span>Captain
        </h1>
      </a>
    </span>
    <span id="nav-links" class="absolute right bottom">

      <!-- Tech category pages -->






  <a href="/category/ai" title="人工智能">人工智能</a>











  <a href="/category/energy" title="能源">能源</a>









  <a href="/category/rt_tech" title="实时技术">实时技术</a>





  <a href="/category/web" title="前端">前端</a>














<!-- Non-tech category pages -->












  <a href="/category/business" title="商业">商业</a>



  <a href="/category/design" title="设计">设计</a>













  <a href="/category/thinking" title="思考与生活">思考与生活</a>















      &nbsp;&nbsp;&nbsp;丨&nbsp;

      <!-- Nav pages -->
      
        
      
        
          <a href="/about/" title="关于我">关于我</a>
        
      
        
      
        
      
        
          <a href="/booklist/" title="读书行路">读书行路</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
      
      <!-- Nav links -->
      <!-- <a href="https://github.com/thereviewindex/monochrome/archive/master.zip">Download</a>
<a href="https://github.com/thereviewindex/monochrome">Project on Github</a> -->

    </span>
  </div>
</header>




      

    <!-- Main content -->
	  <div id="container">
		  
		<main>

			<article id="post-page">
	<h2>麦克船长 TensorFlow 技术笔记</h2>		
	<time datetime="2022-12-20T19:45:31+00:00" class="by-line">20 Dec 2022, 杭州 | 麦克船长 | 总计 3510 字</time>
	<div class="content">
		<p><strong>本文目录</strong></p>
<ul id="markdown-toc">
  <li><a href="#一tf" id="markdown-toc-一tf">一、tf</a>    <ul>
      <li><a href="#tfarg_max" id="markdown-toc-tfarg_max"><code class="language-plaintext highlighter-rouge">tf.arg_max</code></a></li>
      <li><a href="#tfabs-求张量所有元素的绝对值" id="markdown-toc-tfabs-求张量所有元素的绝对值"><code class="language-plaintext highlighter-rouge">tf.abs</code> 求张量所有元素的绝对值</a></li>
      <li><a href="#tfone_hot" id="markdown-toc-tfone_hot"><code class="language-plaintext highlighter-rouge">tf.one_hot</code></a></li>
      <li><a href="#tfones_like" id="markdown-toc-tfones_like"><code class="language-plaintext highlighter-rouge">tf.ones_like</code></a></li>
      <li><a href="#tfsign-求张量所有元素的符号函数" id="markdown-toc-tfsign-求张量所有元素的符号函数"><code class="language-plaintext highlighter-rouge">tf.sign</code> 求张量所有元素的符号函数</a></li>
      <li><a href="#tfreduce_sum" id="markdown-toc-tfreduce_sum"><code class="language-plaintext highlighter-rouge">tf.reduce_sum</code></a></li>
      <li><a href="#tftile" id="markdown-toc-tftile"><code class="language-plaintext highlighter-rouge">tf.tile</code></a></li>
      <li><a href="#tftranspose" id="markdown-toc-tftranspose"><code class="language-plaintext highlighter-rouge">tf.transpose</code></a></li>
      <li><a href="#tfwhere" id="markdown-toc-tfwhere"><code class="language-plaintext highlighter-rouge">tf.where</code></a></li>
    </ul>
  </li>
  <li><a href="#二tfnn" id="markdown-toc-二tfnn">二、<code class="language-plaintext highlighter-rouge">tf.nn</code></a>    <ul>
      <li><a href="#tfnnmoments" id="markdown-toc-tfnnmoments"><code class="language-plaintext highlighter-rouge">tf.nn.moments</code></a></li>
    </ul>
  </li>
  <li><a href="#三tflayer" id="markdown-toc-三tflayer">三、<code class="language-plaintext highlighter-rouge">tf.layer</code></a>    <ul>
      <li><a href="#tflayersdense" id="markdown-toc-tflayersdense"><code class="language-plaintext highlighter-rouge">tf.layers.dense</code></a></li>
    </ul>
  </li>
</ul>

<h4 id="一tf">一、tf</h4>

<h5 id="tfarg_max"><code class="language-plaintext highlighter-rouge">tf.arg_max</code></h5>

<p><code class="language-plaintext highlighter-rouge">tf.arg_max</code> 是 TensorFlow 中的一个函数，用于返回一个张量中最大值的位置。</p>

<p>这个函数接收两个参数：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input</code>：需要求最大值位置的张量</li>
  <li><code class="language-plaintext highlighter-rouge">dimension</code>：指定求最大值位置的维度。如果 <code class="language-plaintext highlighter-rouge">dimension = -1</code>，则表示在最后一维求最大值位置；如果 <code class="language-plaintext highlighter-rouge">dimension = 0</code>，则表示在第一维求最大值位置。</li>
</ul>

<p>返回值是一个整数张量，表示最大值位置。</p>

<h5 id="tfabs-求张量所有元素的绝对值"><code class="language-plaintext highlighter-rouge">tf.abs</code> 求张量所有元素的绝对值</h5>

<p><code class="language-plaintext highlighter-rouge">tf.abs</code> 这个函数用来求给定张量中所有元素的绝对值，它会返回一个和输入张量类型相同，但元素值都是绝对值的新张量。例如，<code class="language-plaintext highlighter-rouge">tf.abs([-1, -2, 3])</code> 会返回 <code class="language-plaintext highlighter-rouge">[1, 2, 3]</code>。</p>

<h5 id="tfone_hot"><code class="language-plaintext highlighter-rouge">tf.one_hot</code></h5>

<h5 id="tfones_like"><code class="language-plaintext highlighter-rouge">tf.ones_like</code></h5>

<p><code class="language-plaintext highlighter-rouge">tf.ones_like</code> 函数的作用是根据给定的张量创建一个新的全部元素为 <code class="language-plaintext highlighter-rouge">1</code> 的张量。这个新张量的形状和类型与给定的张量相同。</p>

<p>例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div></div>

<p>输出结果为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span><span class="p">]]</span>
</code></pre></div></div>

<p>即 <code class="language-plaintext highlighter-rouge">b</code> 是一个全部元素都是 <code class="language-plaintext highlighter-rouge">1</code> 的矩阵，形状和类型和 <code class="language-plaintext highlighter-rouge">a</code> 相同。</p>

<h5 id="tfsign-求张量所有元素的符号函数"><code class="language-plaintext highlighter-rouge">tf.sign</code> 求张量所有元素的符号函数</h5>

<p><code class="language-plaintext highlighter-rouge">tf.sign</code>：这个函数用来求给定张量中所有元素的符号，它会返回一个和输入张量类型相同，但元素值为 1, 0 或 -1 的新张量。对于正数，返回 1，对于 0，返回0，对于负数，返回 -1。例如，<code class="language-plaintext highlighter-rouge">tf.sign([-1, -2, 3])</code> 会返回 [-1, -1, 1]。</p>

<h5 id="tfreduce_sum"><code class="language-plaintext highlighter-rouge">tf.reduce_sum</code></h5>

<p><code class="language-plaintext highlighter-rouge">tf.reduce_sum</code> 函数是 TensorFlow 中的数学运算函数之一，用于沿着指定的维度对张量进行求和运算，所以是先「reduce」维度，再「sum」被消掉这个维度上的数值和。它接受三个参数：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">input_tensor</code>：一个待求和的张量。</li>
  <li><code class="language-plaintext highlighter-rouge">axis</code>：一个整数或者整数列表，表示沿着哪些维度求和。如果没有指定，则默认对所有元素求和。<code class="language-plaintext highlighter-rouge">axis=-1</code> 表示最后一个维度，<code class="language-plaintext highlighter-rouge">axis=-2</code> 表示倒数第二个维度。</li>
  <li><code class="language-plaintext highlighter-rouge">keepdims</code>：一个布尔值，表示是否保留被求和的维度。</li>
</ul>

<p>最终输出是一个降了一阶的张量，降哪一阶取决于参数 <code class="language-plaintext highlighter-rouge">axis</code>。下面是一个代码示例，比如有一个张量 <code class="language-plaintext highlighter-rouge">a</code>，形状为 (2, 3, 4)，如果我们使用 <code class="language-plaintext highlighter-rouge">tf.reduce_sum(a, axis=1)</code>，结果会是一个新的张量，形状为 (2, 4)，每个元素的值都是对应维度上的和。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</code></pre></div></div>

<p>输出结果为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span>
<span class="p">[[</span><span class="mi">15</span> <span class="mi">18</span> <span class="mi">21</span> <span class="mi">24</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">15</span> <span class="mi">18</span> <span class="mi">21</span> <span class="mi">24</span><span class="p">]],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div></div>

<p>我们可以看出，这个例子中，原始矩阵 <code class="language-plaintext highlighter-rouge">a</code> 是 <code class="language-plaintext highlighter-rouge">2 x 3 x 4</code> 的三维张量，我们对它求和的时候使用了 <code class="language-plaintext highlighter-rouge">axis = 1</code>，所以将第二维上的所有数相加，得到了一个新的 2 x 4 的矩阵。</p>

<h5 id="tftile"><code class="language-plaintext highlighter-rouge">tf.tile</code></h5>

<p>tf.tile 函数用于重复一个张量，其中参数是需要重复的张量和重复次数。例如：</p>

<p>a = tf.constant([1, 2, 3])
b = tf.tile(a, [2])</p>

<p>此时 b 的值就是 [1, 2, 3, 1, 2, 3]。另一个例子：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<p>此时 b 的值就是 [[1, 2, 1, 2, 1, 2], [3, 4, 3, 4, 3, 4], [1, 2, 1, 2, 1, 2], [3, 4, 3, 4, 3, 4]]。可以看到在第一维重复了 2 次，在第二维重复了 3 次。还可以使用多维重复，例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="c1"># Output: [[[1, 2, 3, 1, 2, 3], [1, 2, 3, 1, 2, 3]], [[1, 2, 3, 1, 2, 3], [1, 2, 3, 1, 2, 3]]]
</span></code></pre></div></div>

<h5 id="tftranspose"><code class="language-plaintext highlighter-rouge">tf.transpose</code></h5>

<p><code class="language-plaintext highlighter-rouge">tf.transpose</code> 是 TensorFlow 中的一个函数，用于对一个 Tensor 进行转置操作。转置操作是指将一个矩阵中的行和列互换位置。在 TensorFlow 中，<code class="language-plaintext highlighter-rouge">tf.transpose</code> 函数接受两个参数：</p>

<p>第一个参数为需要转置的 <code class="language-plaintext highlighter-rouge">Tensor</code>。
第二个参数为一个整型数组，表示转置后 <code class="language-plaintext highlighter-rouge">Tensor</code> 的维度排列顺序。
例如，对于一个 <code class="language-plaintext highlighter-rouge">3 x 4</code> 的 <code class="language-plaintext highlighter-rouge">Tensor</code>，如果想要将其行列转置，则可以使用如下语句：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">original_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="n">transposed_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">original_tensor</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>这样 <code class="language-plaintext highlighter-rouge">transposed_tensor</code> 就是一个 <code class="language-plaintext highlighter-rouge">4 x 3</code> 的 <code class="language-plaintext highlighter-rouge">Tensor</code> 了。值得关注的是，<code class="language-plaintext highlighter-rouge">transpose</code> 不止对矩阵可以转置，也可以对高维的张量进行转置操作。</p>

<p><code class="language-plaintext highlighter-rouge">outputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1]))</code> 这句话中的 <code class="language-plaintext highlighter-rouge">tf.transpose(K_, [0, 2, 1])</code> 意思是调换 <code class="language-plaintext highlighter-rouge">K_</code> 的第 0 维和第 2 维的位置，也就是对 <code class="language-plaintext highlighter-rouge">K_</code> 做矩阵转置操作。那么这句话的整体意思是对 <code class="language-plaintext highlighter-rouge">Q_</code> 和 <code class="language-plaintext highlighter-rouge">K_</code> 进行矩阵乘法运算，结果的维度为 <code class="language-plaintext highlighter-rouge">(h*N, T_q, T_k)</code>。</p>

<h5 id="tfwhere"><code class="language-plaintext highlighter-rouge">tf.where</code></h5>

<p><code class="language-plaintext highlighter-rouge">tf.where(condition, x=None, y=None)</code> 函数会根据 <code class="language-plaintext highlighter-rouge">condition</code> 中的元素值，从 <code class="language-plaintext highlighter-rouge">x</code> 和 <code class="language-plaintext highlighter-rouge">y</code> 中选择元素。当 <code class="language-plaintext highlighter-rouge">condition</code> 中的元素值为 <code class="language-plaintext highlighter-rouge">True</code> 时，从 <code class="language-plaintext highlighter-rouge">x</code> 中选择元素，否则从 <code class="language-plaintext highlighter-rouge">y</code> 中选择元素。<code class="language-plaintext highlighter-rouge">x</code> 和 <code class="language-plaintext highlighter-rouge">y</code> 的形状必须相同。</p>

<p>例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">condition</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">tf</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># Output: [1, 5, 3]
</span></code></pre></div></div>

<p>在这个例子中，<code class="language-plaintext highlighter-rouge">condition</code> 数组为 <code class="language-plaintext highlighter-rouge">[True, False, True]</code>，所以从 <code class="language-plaintext highlighter-rouge">x</code> 数组中选择第一个和第三个元素，从 <code class="language-plaintext highlighter-rouge">y</code> 数组中选择第二个元素。</p>

<h4 id="二tfnn">二、<code class="language-plaintext highlighter-rouge">tf.nn</code></h4>

<h5 id="tfnnmoments"><code class="language-plaintext highlighter-rouge">tf.nn.moments</code></h5>

<h4 id="三tflayer">三、<code class="language-plaintext highlighter-rouge">tf.layer</code></h4>

<h5 id="tflayersdense"><code class="language-plaintext highlighter-rouge">tf.layers.dense</code></h5>

<p>用来构建一个全连接层(fully connected layer)。这个层会将输入数据映射到输出结果，输入数据可以是一个二维张量，输出结果是一个二维张量。</p>

<ul>
  <li>在这个函数中可以传入两个参数，第一个是输入数据，第二个是输出结果中维度的大小。</li>
  <li>这个层会自动创建一个权重矩阵 <code class="language-plaintext highlighter-rouge">W</code> 和偏置向量 <code class="language-plaintext highlighter-rouge">b</code>，将输入数据乘上 <code class="language-plaintext highlighter-rouge">W</code> 并加上 <code class="language-plaintext highlighter-rouge">b</code>，得到输出结果。</li>
  <li>如果输入数据是 <code class="language-plaintext highlighter-rouge">nm</code> 的矩阵，输出结果是 <code class="language-plaintext highlighter-rouge">nk</code> 的矩阵，则权重矩阵 <code class="language-plaintext highlighter-rouge">W</code> 是 <code class="language-plaintext highlighter-rouge">m*k</code> 的矩阵，偏置向量 <code class="language-plaintext highlighter-rouge">b</code> 是 <code class="language-plaintext highlighter-rouge">k</code> 维向量。</li>
</ul>

<p>在这里，<code class="language-plaintext highlighter-rouge">self.logits = tf.layers.dense(self.dec, len(en2idx))</code> 中 <code class="language-plaintext highlighter-rouge">self.dec</code> 为输入数据，<code class="language-plaintext highlighter-rouge">len(en2idx)</code> 为输出结果的维度，这里的输出维度就是类别数。</p>

	</div>
</article>



	  </main>
		
		  <!-- Pagination links -->
      

	  </div>
	    
	    <!-- Footer -->
	    <footer>
	<span>
		-<br/><br/>
		船长还不会游泳 at 微信公众号/微博<br/>
		@麦克船长 at 即刻/知乎/小宇宙/掘金/小红书/微信读书<br/>
		@船长模玩 at Bilibili<br/>
		Copyright © 2011-2023, MikeCaptain.com
	</span>
</footer>


	    <!-- Script -->
      <script src="/js/main.js"></script>	


	</div>
</body>
</html>
