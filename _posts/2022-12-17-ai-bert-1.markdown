---
layout: post
title:  你可能已经听说 GPT-3，但是你也不能不知道 BERT —— 跟我一起用 BERT 跑个小用例
date:   2022-12-17 23:08:01 +0800
categories: ai
tags: [BERT, AI, 人工智能]
description: 2018 年 Google 发布了 BERT 模型后迅速席卷 NLP 领域，这家伙可是比 ChatGPT 背后的 GPT 还要早的。本文简单介绍了 BERT 后主要是希望大家都手试一下，所以文中提到了一个小的中文模型供大家练手，以及一个小用例。
excerpt: 2018 年 Google 发布了 BERT 模型后迅速席卷 NLP 领域，这家伙可是比 ChatGPT 背后的 GPT 还要早的。本文简单介绍了 BERT 后主要是希望大家都手试一下，所以文中提到了一个小的中文模型供大家练手，以及一个小用例。
---

### 一、关于 BERT 的一些背景

2018 年 Google 发布 BERT 后迅速在 NLP 领域引起广泛关注。BERT（Bidirectional Encoder Representations from Transformers）是一种自然语言处理（NLP）的深度学习模型，它可以进行语言模型预测、序列标注和问答等任务。BERT 采用双向的 Transformer 编码器架构，使用了大量的数据和计算资源进行训练，因此具有较强的泛化能力。

BERT 的训练方法是通过让模型对给定的输入文本进行自监督学习，即使用未标记的语料进行训练。BERT 可以在很多 NLP 任务中获得较好的性能，并且由于其双向的编码方式，能够更好地理解语境信息。

BERT 的训练需要大量的计算资源，因此它常常被用来作为解决 NLP 问题的预训练模型，可以用来初始化其他模型的权重，使得这些模型能够更快速地收敛。

### 二、开始一个 BERT 的动手小试验

为了让 conda 使用 Python 3.7，你可以按照这些步骤来操作。

#### 1、安装 Anaconda 来为部署 BERT 做环境准备

先了解几个概念：Anaconda 是一个软件包管理系统，其中包含了 conda 和许多其他的工具。Conda 是 Anaconda 中的一个组件，用于安装和管理软件包。
我们需要用 conda 创建一个环境，在这个环境里去启用我们想要使用的 BERT 所需要的各种依赖。

更新 conda 到最新版本：

```shell
conda update -n base conda
```

使用 Python 3.7 创建一个新的环境：

```shell
conda create -n py37 python=3.7
```

激活这个新环境：

```shell
conda activate py37
```

验证正在使用的是正确版本的 Python

```shell
python --version
```

另外你可能还会用到的 conda 命令有：

```shell
# 你之后一定会需要 deactivate 一个环境，命令如下：
conda deactivate py37

# 查看 conda 当前安装的所有库
conda list
```

#### 2、安装 BERT 所需要的各种依赖

```shell
conda install tensorflow==1.14.0
```

验证 tensorflow 是否安装正确：

```python
import tensorflow as tf
print(tf.__version__)
```

#### 3、下载一个预训练（Pre-Train）过的 BERT 模型

官方的模型在这里浏览：https://github.com/google-research/bert#pre-trained-models

也有一些中文的模型，以下是 ChatGPT 推荐的三个：

* BERT-Base, Chinese：这是 Google 官方提供的中文 BERT 模型，在中文 NLP 任务中表现良好。你可以从 这里下载这个模型。
* ERNIE：这是由中科院自然语言所提供的中文 BERT 模型，包含了额外的语义信息。你可以从 这里下载这个模型。
* RoBERTa-wwm-ext：这是由清华大学自然语言处理实验室提供的中文 BERT 模型，在多种中文 NLP 任务中表现良好。你可以从 这里下载这个模型。

4、安装 BERT 的服务端和客户端

这里我们使用 bert-as-service，bert-as-service 是一种将 BERT 模型部署为服务的方式。该工具使用 TensorFlow Serving 来运行 BERT 模型，并允许通过 REST API 进行调用。根据 bert-as-service 的文档，它已经在 TensorFlow 1.14.0 上测试过。

在你激活的环境里，安装 `bert-as-service`：

```shell
# 安装服务端和客户端
# 更多关于 bert-serving-server 的信息可以参考：https://bert-serving.readthedocs.io/en/latest/index.html
conda install bert-serving-server bert-serving-client 
验证 bert-as-service 是否安装成功
bert-serving-start -h
```

#### 5、启动 BERT 服务端

```shell
# 命令行下启动BERT服务
# -num_worker 表示启动几个worker服务，即可以处理几个并发请求，超过这个数字的请求将会在LBS（负载均衡器）中排队等待
bert-serving-start -model_dir /模型/的/绝对/路径 -num_worker=4
```

#### 6、在 PyCharm 中使用 Conda 的环境

在 PyCharm 中启用 Interpreter 为 Anaconda，macOS 上具体地是在「Preference - Project - Python Interpreter - Add Interpreter - Add Local Interpreter - Conda Environment」。

接下来还有一项重要的步骤就是选择该 project 要加载包文件的路径。如果不进行这一步，那该 project 还是从系统环境变量中的路径来搜索你要加载的包，这样在你用 Anaconda 新建的这个环境中所特有的包就会出现无法加载的问题。单击菜单栏 Run 选择 Edit Configuration。在Environment variables中添加一个新的 Path。新的路径为你用 Anaconda 新建的环境的文件夹中的`「/Users/captain/opt/anaconda3/bin/python」`。

配置 PyCharm 这里参考：https://docs.anaconda.com/anaconda/user-guide/tasks/pycharm/

#### 7、编写程序实现 BERT 客户端

这里有一些客户端例子可以参考：https://blog.csdn.net/qq_18256855/article/details/123860126

```python
from bert_serving.client import BertClient
import numpy as np

# 定义类
class BertModel:
    def __init__(self):
        try:
            self.bert_client = BertClient(ip='127.0.0.1', port=5555, port_out=5556)  # 创建客户端对象
            # 注意：可以参考API，查看其它参数的设置
            # 127.0.0.1 表示本机IP，也可以用localhost
        except:
            raise Exception("cannot create BertClient")

    def close_bert(self):
        self.bert_client.close()  # 关闭服务

    def sentence_embedding(self, text):
        '''对输入文本进行embedding
          Args:
            text: str, 输入文本
          Returns:
            text_vector: float, 返回一个列表，包含text的embedding编码值
        '''
        text_vector = self.bert_client.encode([text])[0]
        return text_vector  # 获取输出结果

    def caculate_similarity(self, vec_1, vec_2):
        '''根据两个语句的vector，计算它们的相似性
          Args:
            vec_1: float, 语句1的vector
            vec_2: float, 语句2的vector
          Returns:
            sim_value: float, 返回相似性的计算值
        '''
        # 根据cosine的计算公式
        v1 = np.mat(vec_1)
        v2 = np.mat(vec_2)
        a = float(v1 * v2.T)
        b = np.linalg.norm(v1) * np.linalg.norm(v2)
        cosine = a / b
        return cosine


if __name__ == "__main__":
    # 创建bert对象
    bert = BertModel()
    while True:
        # --- 输入语句 ----
        input_a = input('请输入语句1: ')

        if input_a == "N" or input_a == "n":
            bert.close_bert()  # 关闭服务
            break

        input_b = input('请输入语句2: ')

        # --- 对输入语句进行embedding ---

        a_vec = bert.sentence_embedding(input_a)
        print('a_vec shape : ', a_vec.shape)

        b_vec = bert.sentence_embedding(input_b)
        print('b_vec shape : ', b_vec.shape)

        # 计算两个语句的相似性
        cos = bert.caculate_similarity(a_vec, b_vec)
        print('cosine value : ', cos)

        print('\n\n')

        # 如果相似性值大于0.85，则输出相似，否则，输出不同
        if cos > 0.85:
            print("2个语句的含义相似")
        else:
            print("不相似")
```

在使用 `bert-serving-client` 连接 `bert-serving-server` 时，你需要确保 `bert-serving-server` 使用的模型和 `bert-serving-client` 使用的模型是匹配的，否则会出现错误。

程序正常运行后，将要求你输入两句话，然后 BERT 计算两句话的相似性。

```shell
请输入语句1: 
请输入语句2: 
```

两句输入好确认后，得到如下形式的结果：

```
a_vec shape :  (768,)
b_vec shape :  (768,)
cosine value :  0.8691698561422959
```

其实这个小试验蛮没意思的，而且准确性也比较令人质疑。